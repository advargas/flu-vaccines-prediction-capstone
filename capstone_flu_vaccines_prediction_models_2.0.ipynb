{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f81b4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##Dataset final\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c64453",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training_features=pd.read_csv(\"training_set_features_eda_notnulls.csv\")\n",
    "y_training_features=pd.read_csv(\"training_set_labels.csv\")\n",
    "#Los id no los necesitaremos al entrenar el modelo\n",
    "x_training_features.drop([\"Unnamed: 0.1\",\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "#Tomando en cuenta los features que están más correlacionados, se eliminarán behavioral_outside_home\n",
    "# y doctor_recc_h1n1, tomando en cuenta tambien que tienen una menor correlación con las variables \n",
    "#targets frente a los features con los que se correlacionan.\n",
    "x_training_features.drop([\"behavioral_outside_home\",\"doctor_recc_h1n1\"], axis=1, inplace=True)\n",
    "\n",
    "#Ahora solo necesitamos de las variables targets eliminar la columna que no necesitamos: los id\n",
    "y_training_features.drop(\"respondent_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4098cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "l_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "list_labels_encoders = [\"age_group\",\"education\"]\n",
    "list_dummies=[\"race\",\"sex\",\"marital_status\",\"rent_or_own\",\"employment_status\",\"census_msa\"]\n",
    "\n",
    "# Se aplica label encoder a las variables ordinales\n",
    "x_training_features[\"age_group\"]=l_encoder.fit_transform(x_training_features[\"age_group\"]) \n",
    "x_training_features[\"education\"]=l_encoder.fit_transform(x_training_features[\"education\"]) \n",
    "\n",
    "#se aplica one hot enocoder usando pandas: \"Dummies\"\n",
    "x_training_features=pd.get_dummies(x_training_features, columns=list_dummies, prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979d27a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h1n1_concern', 'h1n1_knowledge', 'behavioral_antiviral_meds',\n",
       "       'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "       'behavioral_large_gatherings', 'behavioral_touch_face',\n",
       "       'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months',\n",
       "       'health_worker', 'health_insurance', 'opinion_h1n1_vacc_effective',\n",
       "       'opinion_h1n1_risk', 'opinion_h1n1_sick_from_vacc',\n",
       "       'opinion_seas_vacc_effective', 'opinion_seas_risk',\n",
       "       'opinion_seas_sick_from_vacc', 'age_group', 'education',\n",
       "       'household_adults', 'household_children', 'race_Black', 'race_Hispanic',\n",
       "       'race_White', 'sex_Female', 'marital_status_Married',\n",
       "       'rent_or_own_Rent', 'employment_status_Employed',\n",
       "       'employment_status_Not in Labor Force',\n",
       "       'census_msa_MSA, Not Principle  City',\n",
       "       'census_msa_MSA, Principle City'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para evitar colinealidad debido a los dummies, se eliminará 1 columna por cada variable\n",
    "#las columnas generadas por one hot encoder \"dummies\" que se eliminarán son:\n",
    "list_dummies_drop=['race_Other or Multiple','sex_Male', \\\n",
    "            'marital_status_Not Married','rent_or_own_Own','employment_status_Unemployed', \\\n",
    "            'census_msa_Non-MSA']\n",
    "x_training_features.drop(list_dummies_drop,axis=1, inplace=True)\n",
    "x_training_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d23f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1n1_concern   , Cantidad de outliers:  0\n",
      "h1n1_knowledge   , Cantidad de outliers:  0\n",
      "behavioral_antiviral_meds   , Cantidad de outliers:  1301\n",
      "behavioral_avoidance   , Cantidad de outliers:  0\n",
      "behavioral_face_mask   , Cantidad de outliers:  1841\n",
      "behavioral_wash_hands   , Cantidad de outliers:  4650\n",
      "behavioral_large_gatherings   , Cantidad de outliers:  0\n",
      "behavioral_touch_face   , Cantidad de outliers:  0\n",
      "doctor_recc_seasonal   , Cantidad de outliers:  0\n",
      "chronic_med_condition   , Cantidad de outliers:  0\n",
      "child_under_6_months   , Cantidad de outliers:  2138\n",
      "health_worker   , Cantidad de outliers:  2899\n",
      "health_insurance   , Cantidad de outliers:  0\n",
      "opinion_h1n1_vacc_effective   , Cantidad de outliers:  0\n",
      "opinion_h1n1_risk   , Cantidad de outliers:  0\n",
      "opinion_h1n1_sick_from_vacc   , Cantidad de outliers:  0\n",
      "opinion_seas_vacc_effective   , Cantidad de outliers:  3427\n",
      "opinion_seas_risk   , Cantidad de outliers:  0\n",
      "opinion_seas_sick_from_vacc   , Cantidad de outliers:  6573\n",
      "age_group   , Cantidad de outliers:  0\n",
      "education   , Cantidad de outliers:  0\n",
      "household_adults   , Cantidad de outliers:  1125\n",
      "household_children   , Cantidad de outliers:  1747\n",
      "race_Black   , Cantidad de outliers:  2118\n",
      "race_Hispanic   , Cantidad de outliers:  1755\n",
      "race_White   , Cantidad de outliers:  5485\n",
      "sex_Female   , Cantidad de outliers:  0\n",
      "marital_status_Married   , Cantidad de outliers:  0\n",
      "rent_or_own_Rent   , Cantidad de outliers:  5929\n",
      "employment_status_Employed   , Cantidad de outliers:  0\n",
      "employment_status_Not in Labor Force   , Cantidad de outliers:  0\n",
      "census_msa_MSA, Not Principle  City   , Cantidad de outliers:  0\n",
      "census_msa_MSA, Principle City   , Cantidad de outliers:  0\n"
     ]
    }
   ],
   "source": [
    "#Analizando presencia de valores atípicos\n",
    "def find_outliers(df):\n",
    "    outliers = {}\n",
    "    for columna in df.columns:\n",
    "        # Calcular el primer y tercer cuartil\n",
    "        Q1 = df[columna].quantile(0.25)\n",
    "        Q3 = df[columna].quantile(0.75)\n",
    "        # Calcular el rango intercuartílico (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # Definir los límites para detectar outliers\n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        # Encontrar los índices de los outliers\n",
    "        outliers[columna] = df[(df[columna] < limite_inferior) | (df[columna] > limite_superior)].index.tolist()\n",
    "        print(columna, \"  , Cantidad de outliers: \", len(outliers[columna]))\n",
    "    return outliers\n",
    "\n",
    "    \n",
    "outliers_per_feature = find_outliers(x_training_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa20c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1n1_concern   , Cantidad de outliers:  0\n",
      "h1n1_knowledge   , Cantidad de outliers:  0\n",
      "behavioral_antiviral_meds   , Cantidad de outliers:  803\n",
      "behavioral_avoidance   , Cantidad de outliers:  0\n",
      "behavioral_face_mask   , Cantidad de outliers:  1161\n",
      "behavioral_wash_hands   , Cantidad de outliers:  3825\n",
      "behavioral_large_gatherings   , Cantidad de outliers:  0\n",
      "behavioral_touch_face   , Cantidad de outliers:  0\n",
      "doctor_recc_seasonal   , Cantidad de outliers:  0\n",
      "chronic_med_condition   , Cantidad de outliers:  0\n",
      "child_under_6_months   , Cantidad de outliers:  1487\n",
      "health_worker   , Cantidad de outliers:  2199\n",
      "health_insurance   , Cantidad de outliers:  0\n",
      "opinion_h1n1_vacc_effective   , Cantidad de outliers:  0\n",
      "opinion_h1n1_risk   , Cantidad de outliers:  0\n",
      "opinion_h1n1_sick_from_vacc   , Cantidad de outliers:  3808\n",
      "opinion_seas_vacc_effective   , Cantidad de outliers:  2521\n",
      "opinion_seas_risk   , Cantidad de outliers:  0\n",
      "opinion_seas_sick_from_vacc   , Cantidad de outliers:  0\n",
      "age_group   , Cantidad de outliers:  0\n",
      "education   , Cantidad de outliers:  0\n",
      "household_adults   , Cantidad de outliers:  807\n",
      "household_children   , Cantidad de outliers:  1237\n",
      "race_Black   , Cantidad de outliers:  1421\n",
      "race_Hispanic   , Cantidad de outliers:  1020\n",
      "race_White   , Cantidad de outliers:  3607\n",
      "sex_Female   , Cantidad de outliers:  0\n",
      "marital_status_Married   , Cantidad de outliers:  0\n",
      "rent_or_own_Rent   , Cantidad de outliers:  4109\n",
      "employment_status_Employed   , Cantidad de outliers:  0\n",
      "employment_status_Not in Labor Force   , Cantidad de outliers:  0\n",
      "census_msa_MSA, Not Principle  City   , Cantidad de outliers:  0\n",
      "census_msa_MSA, Principle City   , Cantidad de outliers:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se realizarán dos dataframes, uno con los outliers y el otro sin ellos\n",
    "#eliminando valores atipicos de la variable con más atipicos: opinion_seas_sick_from_vacc\n",
    "#se espera posteriormente ver la posibilidad de mejora en el score de lo modelos al disminuir\n",
    "#la cantidad de outliers\n",
    "x_training_features_no_outliers = \\\n",
    "x_training_features.drop(outliers_per_feature[\"opinion_seas_sick_from_vacc\"],axis=0)\n",
    "find_outliers(x_training_features_no_outliers)\n",
    "x_training_features_no_outliers.shape #20134 es la longitud\n",
    "\n",
    "#los índices donde estaban los valores atípicos se utilizan para eliminarlos también \n",
    "#en el dataframe de la variable target\n",
    "y_training_features_no_outliers = \\\n",
    "y_training_features.drop(outliers_per_feature[\"opinion_seas_sick_from_vacc\"],axis=0)\n",
    "\n",
    "#verificando que los dataframes tienen el mismo tamaño\n",
    "x_training_features_no_outliers.shape[0] == y_training_features_no_outliers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a7b34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df con menos outliers:  (20134, 33)\n",
      "df con outliers:  (26707, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"df con menos outliers: \",x_training_features_no_outliers.shape)\n",
    "print(\"df con outliers: \",x_training_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f865d3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 26703 26704 26705]\n",
      "  Test:  index=[    4     8    12 ... 26696 26701 26706]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     4 ... 26704 26705 26706]\n",
      "  Test:  index=[    2     3     5 ... 26699 26700 26702]\n",
      "Fold 2:\n",
      "  Train: index=[    2     3     4 ... 26702 26705 26706]\n",
      "  Test:  index=[    0     1     9 ... 26693 26703 26704]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 26704 26705 26706]\n",
      "  Test:  index=[    6    11    13 ... 26691 26695 26697]\n",
      "Fold 4:\n",
      "  Train: index=[    0     1     2 ... 26703 26704 26706]\n",
      "  Test:  index=[    7    14    23 ... 26681 26692 26705]\n"
     ]
    }
   ],
   "source": [
    "########################separando el train y test dataframe###############################\n",
    "# ESTO SOLO SE HACE A MODO EJEMPLO, YA QUE LUEGO STRATIFIEDKFOLD SE APLICA DE MANERA CONJUNTA\n",
    "#CON GRIDSERACH CV, ESTO SOLO PARA PRÓPOSITOS DE VERIFICAR SI ayuda a garantizar que cada fold \n",
    "#tenga una representación equitativa de todas las clases, evitando así la posibilidad de que un \n",
    "#fold tenga muy pocos ejemplos de una clase en particular.\n",
    "\n",
    "\n",
    "#Ya que tenemos dos variables targets, haremos este proceso para cada una\n",
    "y1=np.array(y_training_features['h1n1_vaccine'])\n",
    "y2=np.array(y_training_features['seasonal_vaccine'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "############################## h1n1_vaccine ######################################\n",
    "#splitting into 5 folds\n",
    "skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=1234)\n",
    "train_list_index, test_list_index=[],[]\n",
    "for i,(train_index, test_index) in enumerate(skf.split(x_training_features, y1)):\n",
    " print(f\"Fold {i}:\")\n",
    " print(f\"  Train: index={train_index}\")\n",
    " print(f\"  Test:  index={test_index}\")\n",
    " train_list_index.append(train_index) #saving the indexes od the 5 folds\n",
    " test_list_index.append(test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7673d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 26702 26705 26706]\n",
      "  Test:  index=[    5     9    14 ... 26700 26703 26704]\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     3 ... 26704 26705 26706]\n",
      "  Test:  index=[    2    12    13 ... 26685 26694 26698]\n",
      "Fold 2:\n",
      "  Train: index=[    0     2     3 ... 26704 26705 26706]\n",
      "  Test:  index=[    1     8    10 ... 26695 26699 26702]\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 26702 26703 26704]\n",
      "  Test:  index=[    4    15    29 ... 26690 26705 26706]\n",
      "Fold 4:\n",
      "  Train: index=[    1     2     4 ... 26704 26705 26706]\n",
      "  Test:  index=[    0     3     6 ... 26687 26696 26701]\n"
     ]
    }
   ],
   "source": [
    "############################## seasonal_vaccine ######################################\n",
    "#splitting into 5 folds\n",
    "skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=1234)\n",
    "train_list_index_2, test_list_index_2=[],[]\n",
    "for i,(train_index, test_index) in enumerate(skf.split(x_training_features, y2)):\n",
    " print(f\"Fold {i}:\")\n",
    " print(f\"  Train: index={train_index}\")\n",
    " print(f\"  Test:  index={test_index}\")\n",
    " train_list_index_2.append(train_index) #saving the indexes od the 5 folds\n",
    " test_list_index_2.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ced4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando Standard Scaler to the 5 folds\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "################################# h1n1_vaccine #######################################\n",
    "x_train,x_test,y_train,y_test=[],[],[],[]\n",
    "sc=StandardScaler()\n",
    "\n",
    "for i in range(0, len(train_list_index)):\n",
    " x_train.append(sc.fit_transform(x_training_features.iloc[train_list_index[i]]))\n",
    " x_test.append(sc.transform(x_training_features.iloc[test_list_index[i]]))\n",
    " #target variable without standard scaler\n",
    " y_train.append(y_training_features.iloc[train_list_index[i]])\n",
    " y_test.append(y_training_features.iloc[test_list_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b98d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando Standard Scaler to the 5 folds\n",
    "################################# seasonal_vaccine #######################################\n",
    "x_train_2,x_test_2,y_train_2,y_test_2=[],[],[],[]\n",
    "sc=StandardScaler()\n",
    "\n",
    "for i in range(0, len(train_list_index)):\n",
    " x_train_2.append(sc.fit_transform(x_training_features.iloc[train_list_index_2[i]]))\n",
    " x_test_2.append(sc.transform(x_training_features.iloc[test_list_index_2[i]]))\n",
    " #target variable without standard scaler\n",
    " y_train_2.append(y_training_features.iloc[train_list_index_2[i]])\n",
    " y_test_2.append(y_training_features.iloc[test_list_index_2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c39e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################INICIO DE DEFINICIÓN DE PARÁMETROS DE LOS MODELOS CON GRID SERCH CV#####################\n",
    "#se harán dos modelos, uno para cada variable target\n",
    "\n",
    "############################# y1=H1N1 variable target################################\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import logspace\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definir tus datos x_train y y_train\n",
    "\n",
    "lambdas = logspace(-11, -2, 10)\n",
    "C_ = [0.01, 0.1, 1, 10]  # How many errors can admit SVM\n",
    "gamma_ = [0.01, 0.1, 1, 10]  # How curved the decision boundaries will be\n",
    "alpha_ = [0.01, 0.1, 1, 10]  # Naive Bayes\n",
    "\n",
    "# Explanation of alpha hyperparameter:\n",
    "# Consider W* word not present in the training set\n",
    "# P(W*|Y=1) = P(W*,Y=1)/P(Y=1)\n",
    "#  = Number of training points such that w* word present and Y=1 / Number of training points where Y=1\n",
    "#  = 0/Number of training points where Y=1\n",
    "# So to get rid of this problem we do Laplace smoothing. we add alpha to numerator and denominator field.\n",
    "# = 0 + alpha / Number of training points where Y=1 + (Number of class labels in cl\n",
    "\n",
    "estimators = [\n",
    "    ('ridge', RidgeClassifierCV()),\n",
    "    ('tree', DecisionTreeClassifier(splitter=\"best\")),\n",
    "    ('svm', SVC()),\n",
    "    ('nv', BernoulliNB())\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"ridge\": {\"ridge__alphas\": lambdas},\n",
    "    \"tree\": {\"tree__max_depth\": [5, 7, 10], \"tree__ccp_alpha\": [0.1, 0.25, 0.5], \"tree__max_features\": [10, 15, 20]},\n",
    "    \"svm\": {\"svm__C\": C_, \"svm__gamma\": gamma_, \"svm__kernel\": [\"rbf\", \"linear\"]},\n",
    "    \"nv\": {\"nv__alpha\": alpha_}\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "best_score = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1234)\n",
    "\n",
    "for est_name, est in estimators:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        (est_name, est)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=params[est_name], scoring=\"roc_auc\", cv=skf, verbose=4, n_jobs=-1)\n",
    "    grid.fit(x_training_features, y1)\n",
    "    best_params[est_name] = grid.best_params_\n",
    "    best_score.append(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the best model\n",
    "lead_board = pd.DataFrame({'model':list(best_params.keys()),\n",
    "                           'params':list(best_params.values()),\n",
    "                           'score':best_score})\n",
    "l_board =lead_board.sort_values(by=\"score\", ascending=False)\n",
    "#l_board.to_csv(\"lead_board_h1n1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca486e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "############################# y2=seasonal variable target################################\n",
    "\n",
    "\n",
    "lambdas = logspace(-11, -2, 10)\n",
    "C_ = [0.01, 0.1, 1, 10]  # How many errors can admit SVM\n",
    "gamma_ = [0.01, 0.1, 1, 10]  # How curved the decision boundaries will be\n",
    "alpha_ = [0.01, 0.1, 1, 10]  # Naive Bayes\n",
    "\n",
    "# Explanation of alpha hyperparameter:\n",
    "# Consider W* word not present in the training set\n",
    "# P(W*|Y=1) = P(W*,Y=1)/P(Y=1)\n",
    "#  = Number of training points such that w* word present and Y=1 / Number of training points where Y=1\n",
    "#  = 0/Number of training points where Y=1\n",
    "# So to get rid of this problem we do Laplace smoothing. we add alpha to numerator and denominator field.\n",
    "# = 0 + alpha / Number of training points where Y=1 + (Number of class labels in cl\n",
    "\n",
    "estimators = [\n",
    "    ('ridge', RidgeClassifierCV()),\n",
    "    ('tree', DecisionTreeClassifier(splitter=\"best\")),\n",
    "    ('svm', SVC()),\n",
    "    ('nv', BernoulliNB())\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"ridge\": {\"ridge__alphas\": lambdas},\n",
    "    \"tree\": {\"tree__max_depth\": [5, 7, 10], \"tree__ccp_alpha\": [0.1, 0.25, 0.5], \"tree__max_features\": [10, 15, 20]},\n",
    "    \"svm\": {\"svm__C\": C_, \"svm__gamma\": gamma_, \"svm__kernel\": [\"rbf\", \"linear\"]},\n",
    "    \"nv\": {\"nv__alpha\": alpha_}\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "best_score = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1234)\n",
    "\n",
    "for est_name, est in estimators:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        (est_name, est)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=params[est_name], scoring=\"roc_auc\", cv=skf, verbose=4, n_jobs=-1)\n",
    "    grid.fit(x_training_features, y2)\n",
    "    best_params[est_name] = grid.best_params_\n",
    "    best_score.append(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bed6e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the best model\n",
    "lead_board_2 = pd.DataFrame({'model':list(best_params.keys()),\n",
    "                           'params':list(best_params.values()),\n",
    "                           'score':best_score})\n",
    "l_board_2 =lead_board_2.sort_values(by=\"score\", ascending=False)\n",
    "#l_board_2.to_csv(\"lead_board_seasonal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2de5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel...</td>\n",
       "      <td>0.854143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'ridge__alphas': 1e-08}</td>\n",
       "      <td>0.847609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nv</td>\n",
       "      <td>{'nv__alpha': 0.01}</td>\n",
       "      <td>0.818433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>{'tree__ccp_alpha': 0.1, 'tree__max_depth': 5,...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model                                             params     score\n",
       "2    svm  {'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel...  0.854143\n",
       "0  ridge                           {'ridge__alphas': 1e-08}  0.847609\n",
       "3     nv                                {'nv__alpha': 0.01}  0.818433\n",
       "1   tree  {'tree__ccp_alpha': 0.1, 'tree__max_depth': 5,...  0.500000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_board_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b2c409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm__C': 1, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=lead_board_2.loc[2]\n",
    "a[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb162c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "############################# y1=H1N1 variable target################################\n",
    "###APLICANDO DE NUEVO GRID SEARCH CV, PERO AHORA SOLO PARA AFINAR (SOLO VARIANDO \n",
    "#LOs HIPERPARÁMETROS DE REGRESIÓN).\n",
    "#Y VERIFICAR SI SE PUEDE APLICAR EL MISMO MODELO PARA AMBAS VARIABLES TARGETS\n",
    "\n",
    "C_ = [0.1]  # How many errors can admit SVM\n",
    "gamma_ = [0.001]  # How curved the decision boundaries will be\n",
    "lambdas = [0.001, 1e-08]\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('ridge', RidgeClassifierCV()),\n",
    "    ('svm', SVC())\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"ridge\": {\"ridge__alphas\": lambdas},\n",
    "    \"svm\": {\"svm__C\": C_, \"svm__gamma\": gamma_, \"svm__kernel\": [\"rbf\"]}\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "best_score = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for est_name, est in estimators:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        (est_name, est)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=params[est_name], scoring=\"roc_auc\", cv=skf, verbose=4, n_jobs=-1)\n",
    "    grid.fit(x_training_features, y1)\n",
    "    best_params[est_name] = grid.best_params_\n",
    "    best_score.append(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8628027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the best model\n",
    "lead_board_3 = pd.DataFrame({'model':list(best_params.keys()),\n",
    "                           'params':list(best_params.values()),\n",
    "                           'score':best_score})\n",
    "l_board_3 =lead_board_3.sort_values(by=\"score\", ascending=False)\n",
    "#l_board_3.to_csv(\"svm_board_h1n1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98e271ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'ridge__alphas': 0.001}</td>\n",
       "      <td>0.847579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'svm__C': 0.1, 'svm__gamma': 0.001, 'svm__ker...</td>\n",
       "      <td>0.844966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model                                             params     score\n",
       "0  ridge                           {'ridge__alphas': 0.001}  0.847579\n",
       "1    svm  {'svm__C': 0.1, 'svm__gamma': 0.001, 'svm__ker...  0.844966"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_board_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83dc974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "############################# y2=seasonal variable target################################\n",
    "###APLICANDO DE NUEVO GRID SEARCH CV, PERO AHORA SOLO PARA AFINAR (SOLO VARIANDO \n",
    "#LOs HIPERPARÁMETROS DE REGRESIÓN).\n",
    "#Y VERIFICAR SI SE PUEDE APLICAR EL MISMO MODELO PARA AMBAS VARIABLES TARGETS\n",
    "\n",
    "\n",
    "C_ = [0.1]  # How many errors can admit SVM\n",
    "gamma_ = [0.001]  # How curved the decision boundaries will be\n",
    "lambdas = [0.001, 1e-08]\n",
    "# Explanation of alpha hyperparameter:\n",
    "# Consider W* word not present in the training set\n",
    "# P(W*|Y=1) = P(W*,Y=1)/P(Y=1)\n",
    "#  = Number of training points such that w* word present and Y=1 / Number of training points where Y=1\n",
    "#  = 0/Number of training points where Y=1\n",
    "# So to get rid of this problem we do Laplace smoothing. we add alpha to numerator and denominator field.\n",
    "# = 0 + alpha / Number of training points where Y=1 + (Number of class labels in cl\n",
    "\n",
    "estimators = [\n",
    "    ('ridge', RidgeClassifierCV()),\n",
    "    ('svm', SVC())\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"ridge\": {\"ridge__alphas\": lambdas},\n",
    "    \"svm\": {\"svm__C\": C_, \"svm__gamma\": gamma_, \"svm__kernel\": [\"rbf\"]}\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "best_score = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "for est_name, est in estimators:\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        (est_name, est)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=params[est_name], scoring=\"roc_auc\", cv=skf, verbose=4, n_jobs=-1)\n",
    "    grid.fit(x_training_features, y2)\n",
    "    best_params[est_name] = grid.best_params_\n",
    "    best_score.append(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6909aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the best model\n",
    "lead_board_4 = pd.DataFrame({'model':list(best_params.keys()),\n",
    "                           'params':list(best_params.values()),\n",
    "                           'score':best_score})\n",
    "l_board_4 =lead_board_4.sort_values(by=\"score\", ascending=False)\n",
    "#l_board_4.to_csv(\"svm_board_seasonal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72714bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>{'svm__C': 0.1, 'svm__gamma': 0.001, 'svm__ker...</td>\n",
       "      <td>0.821622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>{'ridge__alphas': 0.001}</td>\n",
       "      <td>0.820940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model                                             params     score\n",
       "1    svm  {'svm__C': 0.1, 'svm__gamma': 0.001, 'svm__ker...  0.821622\n",
       "0  ridge                           {'ridge__alphas': 0.001}  0.820940"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_board_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SE OBSERVA QUE PARA H1N1 VARIABLE TARGET ES MEJOR ridge\t{'ridge__alphas': 0.001}\n",
    "#SE OBSERVA QUE PARA SEASONAL VARIABLE TARGET ES MEJOR svm\t{'svm__C': 0.1, 'svm__gamma': 0.001,}\n",
    "#POR ENDE SE DETERMINA USAR DIFERENTES MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f4e83e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#######Determinando el mejor learning rate previo ha aplicar adaboost, usando h1n1 target#### \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define los valores de learning_rate a probar\n",
    "param_grid = {'clf__learning_rate': [0.1, 0.2]}\n",
    "\n",
    "# Crea un estimador AdaBoostClassifier con LogisticRegression y SVC como clasificadores base\n",
    "logistic_base = LogisticRegression(C=0.001, solver='lbfgs', max_iter=1000)\n",
    "svm_base = SVC(C=0.1, gamma=0.001, probability=True)\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=logistic_base, n_estimators=100)\n",
    "\n",
    "# Crea un pipeline con StandardScaler y el clasificador\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# Realiza la búsqueda en rejilla con StratifiedKFold y roc_auc como métrica\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=stratified_kfold, scoring='roc_auc')\n",
    "grid_search.fit(x_training_features, y1)\n",
    "\n",
    "# El mejor valor de learning_rate\n",
    "best_learning_rate = grid_search.best_params_['clf__learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "776d4936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_learning_rate\n",
    "#es 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "daced6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC scores: [0.8188670235992246, 0.7870681232977553, 0.8001378403089836, 0.7914018362691435, 0.7767416382302605]\n",
      "Mean ROC AUC: 0.7948432923410735\n"
     ]
    }
   ],
   "source": [
    "###########################Aplicación de adaboost, usando h1n1 target###############\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define tu learning_rate\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Crea un estimador AdaBoostClassifier con LogisticRegression y SVC como clasificadores base\n",
    "logistic_base = LogisticRegression(C=0.001, solver='lbfgs', max_iter=1000)\n",
    "svm_base = SVC(C=0.1, gamma=0.001, probability=True)\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=logistic_base, n_estimators=100, learning_rate=learning_rate)\n",
    "\n",
    "# Crea un pipeline con StandardScaler y el clasificador\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Define StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# Inicializa una lista para almacenar los resultados de ROC AUC\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Itera sobre los diferentes pliegues (folds)\n",
    "for train_index, test_index in stratified_kfold.split(x_training_features, y1):\n",
    "    x_train_fold, x_test_fold = x_training_features.iloc[train_index], x_training_features.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y1[train_index], y1[test_index]\n",
    "    \n",
    "    # Entrena el modelo\n",
    "    pipeline.fit(x_train_fold, y_train_fold)\n",
    "    \n",
    "    # Calcula las probabilidades\n",
    "    y_pred_proba = pipeline.predict_proba(x_test_fold)[:, 1]\n",
    "    \n",
    "    # Calcula y almacena el ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred_proba)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Imprime los resultados de ROC AUC\n",
    "print(f'ROC AUC scores: {roc_auc_scores}')\n",
    "print(f'Mean ROC AUC: {sum(roc_auc_scores) / len(roc_auc_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47881745",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'learning_rate' for estimator Pipeline(steps=[('clf', GradientBoostingClassifier(random_state=1234))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21176\\969461147.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Realiza la búsqueda en rejilla con StratifiedKFold y roc_auc como métrica\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratified_kfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Obtiene el mejor modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     )\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"steps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[1;34m(self, attr, **params)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[0mlocal_valid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    206\u001b[0m                     \u001b[1;34mf\"Invalid parameter {key!r} for estimator {self}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[1;34mf\"Valid parameters are: {local_valid_params!r}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'learning_rate' for estimator Pipeline(steps=[('clf', GradientBoostingClassifier(random_state=1234))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "\n",
    "#Se intenta aplicar GradientBoostingClassifier:\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Crea un estimador GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=1234,learning_rate=0.1)\n",
    "\n",
    "# Define los hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Define el pipeline solo con StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', gb_clf)\n",
    "])\n",
    "\n",
    "# Define StratifiedKFold\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "# Realiza la búsqueda en rejilla con StratifiedKFold y roc_auc como métrica\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=stratified_kfold, scoring='roc_auc')\n",
    "grid_search.fit(x_training_features.values, y1)\n",
    "\n",
    "# Obtiene el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Obtén las probabilidades (asegúrate de que x_test esté en el mismo formato que x_training_features)\n",
    "x_test_scaled = grid_search.best_estimator_.named_steps['scaler'].transform(x_test)\n",
    "y_pred_proba = best_model.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "# Calcula el ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ROC AUC en test: {roc_auc}')\n",
    "\n",
    "# Los mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Los mejores hiperparámetros son: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d435415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################preparando el dataset a predecir##################################\n",
    "df_test_original=pd.read_csv(\"test_set_features.csv\")\n",
    "col=pd.read_csv(\"training_set_features_eda_notnulls.csv\").columns.tolist()\n",
    "col=col[2:]\n",
    "df_test_original=df_test_original[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be55754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "211680 fits failed out of a total of 423360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "104698 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'friedman_mse', 'squared_error'}. Got 'mae' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "106982 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of GradientBoostingClassifier must be a str among {'squared_error', 'friedman_mse'}. Got 'mae' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78754634 0.78754634 0.78754634 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814992324109784\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 0.1, 'min_samples_split': 0.13636363636363638, 'n_estimators': 10, 'subsample': 1.0}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correct_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21176\\3310247145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcorrect_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mtestX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'correct_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters, cv=stratified_kfold, n_jobs=-1)\n",
    "\n",
    "clf.fit(x_training_features.values, y1)\n",
    "print(clf.score(x_training_features.values, y1))\n",
    "print(clf.best_params_)\n",
    "\n",
    "correct_test = correct_data(test)\n",
    "testX = correct_test[predictor].values\n",
    "result = clf.predict(testX)\n",
    "\n",
    "test[\"Survived\"] = result\n",
    "result = test[[\"PassengerId\", \"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85290767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Definir los hiperparámetros\n",
    "parametros = {\n",
    "    'criterion': 'friedman_mse',\n",
    "    'learning_rate': 0.2,\n",
    "    'loss': 'deviance',\n",
    "    'max_depth': 5,\n",
    "    'max_features': 'log2',\n",
    "    'min_samples_leaf': 0.1,\n",
    "    'min_samples_split': 0.13636363636363638,\n",
    "    'n_estimators': 10,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Crear el clasificador\n",
    "clf = GradientBoostingClassifier(**parametros)\n",
    "\n",
    "# Definir los datos X e y (supongo que ya los tienes cargados)\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Listas para almacenar resultados\n",
    "roc_auc_scores = []\n",
    "predicted_probs = []\n",
    "\n",
    "# Iterar sobre las divisiones\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = x_training_features_no_outliers.iloc[train_index], x_training_features_no_outliers.iloc[test_index]\n",
    "    y_train, y_test = y1[train_index], y1[test_index]\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir probabilidades\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    predicted_probs.extend(y_prob)\n",
    "    \n",
    "    # Calcular ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Calcular el promedio de ROC AUC\n",
    "avg_roc_auc = np.mean(roc_auc_scores)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f'ROC AUC promedio: {avg_roc_auc}')\n",
    "\n",
    "# Imprimir las probabilidades continuas\n",
    "print('Probabilidades Continuas:')\n",
    "print(predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed90f9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC promedio: 0.7988071601158585\n",
      "Probabilidades Continuas:\n",
      "[0.10855914636968257, 0.22639488509944347, 0.2605869111340902, 0.11350486523980349, 0.11632327744997886, 0.07363345254293997, 0.3700224536115688, 0.21317466511290656, 0.07983482905230721, 0.38434342248812003, 0.0770341701559317, 0.12020597041002386, 0.2519568981800296, 0.3665605076213983, 0.24825113768956542, 0.40067486371352434, 0.3781128150019116, 0.0969625766969754, 0.3172949967115278, 0.11185730211535756, 0.0838133281559056, 0.16813875155645266, 0.19579048405972518, 0.10426964647007231, 0.28652120819710536, 0.1892633358184119, 0.33409518715447556, 0.3760933665566361, 0.20807084266447032, 0.20689758075092832, 0.437115062331493, 0.16928281200550657, 0.192639859891671, 0.1382086408667483, 0.19349441896171904, 0.09872873887501092, 0.22557558951594964, 0.11378586424139396, 0.23816334655724353, 0.20954824618899978, 0.17099707396081948, 0.35074693837748727, 0.07796570572593228, 0.18888951056058206, 0.19899936403092333, 0.24127095087057238, 0.4701262209608483, 0.1295784556663618, 0.284595006853098, 0.10964021578024205, 0.07253315829106098, 0.10304051109875706, 0.12643566574987, 0.20774163132376577, 0.22175318935797736, 0.19519394766091613, 0.16874444256700846, 0.2331428144067868, 0.18767498452250805, 0.18054878342924185, 0.23173480597221913, 0.32056504994387874, 0.07513208173572697, 0.10641995073173569, 0.09620242388808699, 0.3619715034663451, 0.23298797628237872, 0.49465515843344404, 0.09939325090384073, 0.07127787079139983, 0.17786582273522022, 0.11260772244866422, 0.45363662071777916, 0.17860219845981265, 0.1339084564055725, 0.18225164650137962, 0.11078743043992645, 0.08202208242487677, 0.2496489554127296, 0.09648387633214614, 0.08781341134121534, 0.14522909271708234, 0.42357198478259817, 0.10874505691673017, 0.2697017760591665, 0.0846330841032446, 0.12032823077447735, 0.20115692865224707, 0.2372635092440066, 0.11029548946141703, 0.11166078949074865, 0.31635453061616015, 0.3082113772838753, 0.1753744268250629, 0.16302766767040228, 0.2944905755544633, 0.494743475332184, 0.197348769963173, 0.2646052729772388, 0.40872835359098936, 0.1395559550596091, 0.28739122785167037, 0.06752339097436257, 0.10960434096550631, 0.4944441499684963, 0.32329597259254267, 0.1504005961426399, 0.20027952374022098, 0.09140908586808842, 0.3662688159664709, 0.10061958383642808, 0.47081232544410684, 0.14525633746689823, 0.06418475106837643, 0.10479590147851231, 0.26946880029037507, 0.08408495596302036, 0.37928193415294476, 0.1150786869885289, 0.37621886618302863, 0.20757227854001264, 0.18008439460288034, 0.23461212064184717, 0.36458627839153096, 0.25762622192656137, 0.46298264551873997, 0.09694610498226156, 0.3539968315239569, 0.16089118590583917, 0.14308209222108714, 0.24133427466448037, 0.14445842893081534, 0.11256327240889132, 0.2524999064752725, 0.1727097907874699, 0.07392179002796131, 0.10727895980065791, 0.2166567321998061, 0.22047232434797617, 0.11036817253520927, 0.28979180964235063, 0.2746605325547069, 0.4944441499684963, 0.11873008173396882, 0.20174300999415182, 0.1777628767538925, 0.09729058474757897, 0.2681259676791698, 0.19289775777031146, 0.13719651376436987, 0.10441432801027381, 0.2063756340025621, 0.23936219679450513, 0.11056358019813482, 0.4306046438632438, 0.06696598881845976, 0.14004698984478842, 0.24749719348548288, 0.08371279811596578, 0.07233164068136477, 0.09010027963529295, 0.35906919305253904, 0.1818308333715495, 0.09626933373134915, 0.4447148976328462, 0.19731609656631446, 0.3372209381163028, 0.34969514258385775, 0.14382555993730883, 0.22520152559158244, 0.18934308210051368, 0.11416194432192127, 0.08637659106188822, 0.22388071809947532, 0.3552179687414109, 0.326507188140101, 0.21297415658867028, 0.2612605933800702, 0.19804428130296495, 0.26005914969772714, 0.09393679141139136, 0.3395542962609493, 0.11796921499042441, 0.3520153462682133, 0.09658466405097295, 0.06537794162428118, 0.4309932514792643, 0.2724715807295456, 0.3189130081180351, 0.23098888186946112, 0.2674010028224507, 0.14646747278390487, 0.3791616252465466, 0.3937765165987954, 0.09699470528068962, 0.392227379835565, 0.19977669656699534, 0.06308813254005485, 0.35072213980885364, 0.17811004134887376, 0.21087098724893183, 0.2728837592108085, 0.09946523262897342, 0.08122410467729388, 0.16360115485971716, 0.1784461286635101, 0.10573397930731404, 0.06550905699247413, 0.10829999510540005, 0.3937765165987954, 0.07279317753343499, 0.18479770242710697, 0.3205184782740033, 0.19351477652339338, 0.307848627805474, 0.17164284027300522, 0.07129469311488539, 0.3127087176580501, 0.18166383750231968, 0.07988584628024367, 0.19964204955809442, 0.06902181303081124, 0.30816576740184537, 0.08347696110734046, 0.1315321769682183, 0.16211358318594946, 0.2146668337190831, 0.1464920552159599, 0.1864749192306635, 0.0949778432418597, 0.11829023312099889, 0.28197970631299296, 0.09555026582993482, 0.39948107444727454, 0.14914427577164605, 0.15692415875123758, 0.10287976285584903, 0.164118949245081, 0.4944441499684963, 0.4635942964463554, 0.2512955311009077, 0.20363836777043398, 0.24982325193663762, 0.27648266142597155, 0.13743657692945685, 0.09576013459323804, 0.18656593387261683, 0.32618530802425155, 0.3903630064855182, 0.15072803934905363, 0.1296268840907146, 0.11246106305152835, 0.23564818264368725, 0.3865074138798915, 0.11331250934238708, 0.19704864893361793, 0.20078995349826878, 0.10185070534659085, 0.11195737026560676, 0.16742486647069846, 0.3740623774562916, 0.2048083483000476, 0.4309932514792643, 0.22052305786588378, 0.13659696625020196, 0.22440582607701717, 0.15072803934905363, 0.20165905291115924, 0.08371842367453702, 0.08825488911163198, 0.3232947785786817, 0.11619978177391144, 0.15900296359950258, 0.22520152559158244, 0.380215341586946, 0.11036045067089109, 0.48124392540161726, 0.28272797705967884, 0.10510940698468921, 0.10841188998163964, 0.3008451140321799, 0.43970374717959215, 0.11976676392969816, 0.08018136905161935, 0.09206991722866083, 0.08051707072624692, 0.12540884483467551, 0.27594237843105207, 0.11217580296837833, 0.2721654417197026, 0.2707180207650026, 0.17653712204384733, 0.2670601999139999, 0.11612857505442485, 0.1746121151639943, 0.37158274953024234, 0.09620242388808699, 0.22824189403489742, 0.2115673692427089, 0.18336668077259544, 0.20088929787981946, 0.4593725187980618, 0.17220053944503438, 0.22639479682644503, 0.10100049863706673, 0.19506717547682856, 0.08169226317001532, 0.21286930482294264, 0.17927523957081595, 0.48124392540161726, 0.10678881498764617, 0.27236052977524544, 0.21161873145204443, 0.20471445175059447, 0.20559132601231672, 0.19339032622551325, 0.4254773938639894, 0.23098888186946112, 0.15996807103092217, 0.23195159481933783, 0.3168373990529773, 0.27178577476265714, 0.13683505540505425, 0.10159435852165603, 0.14558196875475002, 0.12196473404818103, 0.07682848742026907, 0.3239323149272551, 0.30110783502335087, 0.2742920710431603, 0.26323338558848597, 0.3803330423550672, 0.0949778432418597, 0.23775646037324238, 0.07129469311488539, 0.1321703290845371, 0.2038440017048499, 0.12974860024557777, 0.20847967499514847, 0.20715339209753209, 0.11130679785244313, 0.08666884903541063, 0.307801329534936, 0.2354902070813459, 0.13906538822120404, 0.4523756734326721, 0.2630571617269905, 0.11383543946336454, 0.34042925613654457, 0.2533169197453393, 0.32640354787502, 0.2121713774168028, 0.15582090538414117, 0.22885187030885387, 0.08049372861751973, 0.1939392774143637, 0.12385420169045283, 0.40872835359098936, 0.32946995823307773, 0.08174192559842935, 0.10231673043934245, 0.18863398331529202, 0.4732068381507385, 0.2781155138731833, 0.20574132121904332, 0.5700375387374911, 0.3435248851769663, 0.3735658953638011, 0.186367152985916, 0.14282445144024467, 0.1970337546903418, 0.11246301344699297, 0.25241904159750994, 0.22037872187523122, 0.07109228674090069, 0.25726387254170957, 0.17276286262297533, 0.10139532810376287, 0.1301312777349305, 0.11078743043992645, 0.08265576776974988, 0.10165341279556807, 0.11009419401899032, 0.21459221987919802, 0.06907533605703244, 0.20043797355845808, 0.10518867470998824, 0.20054020962792904, 0.2106281688934806, 0.12977947556841796, 0.20663132062206688, 0.2924982605518671, 0.13899340719074263, 0.15669320419722854, 0.19349358449463433, 0.16683015898336034, 0.49049742031931487, 0.24210631289961806, 0.2612584717688391, 0.12528816498508127, 0.09361727325511664, 0.20847259457349324, 0.1116933608065611, 0.22244571690011758, 0.06777410601659759, 0.06530283926892815, 0.2857365521527766, 0.16552057623126398, 0.2500119688204374, 0.19672454548888968, 0.4357490794610577, 0.1402120587681765, 0.18940141777016437, 0.2253634158636702, 0.08475395407977053, 0.1097841111478148, 0.10051509562911888, 0.3007470140212993, 0.14646747278390487, 0.2832040684098619, 0.10673455904493423, 0.2074093691836328, 0.26536268978346866, 0.1881139624529953, 0.3540045672164656, 0.19815448946470093, 0.19185435163959488, 0.10839650986915395, 0.10219211167627146, 0.35285779076272966, 0.18405188443142945, 0.18493165027382677, 0.18341464613753683, 0.2795288637985644, 0.20670442854982304, 0.4946781521716061, 0.38771647915159835, 0.2003419741645008, 0.13389805914837552, 0.3501071683226308, 0.2230268610558184, 0.34825176026039556, 0.2050765489668709, 0.1978106647933598, 0.07542385454646813, 0.2540589833268555, 0.20074701280148802, 0.06540777228907375, 0.08913884749443302, 0.2453764748899259, 0.1546858623203112, 0.3647020663771187, 0.34040915040231384, 0.10672663817655312, 0.10671260555854456, 0.49049742031931487, 0.28172137995182206, 0.09511643993291921, 0.4475551332435703, 0.22585483162398595, 0.07489801027880852, 0.3832494578378236, 0.22815523961663986, 0.07301766733371637, 0.22137285844631263, 0.24914969307335963, 0.09202206804357917, 0.17991976839922283, 0.13065131888456008, 0.123656845455453, 0.0888834097932776, 0.3606827071816362, 0.2663459016367942, 0.18159591114639637, 0.17164373098438157, 0.20715821472106366, 0.09806692314775495, 0.4269540368451598, 0.3786412782414327, 0.2751336784881768, 0.20663132062206688, 0.41091687654438064, 0.24754404303192912, 0.06302876433508216, 0.28904117866443496, 0.13690722987272544, 0.24540718787030089, 0.12939418933816027, 0.25407580449963196, 0.12485101224325931, 0.11531436603147185, 0.17500917495338814, 0.19245009415766987, 0.13176667325296, 0.18572436643070572, 0.12076380185332325, 0.2354902070813459, 0.36455283490767704, 0.2527663415264365, 0.39583969977458017, 0.20010100449905854, 0.09132507791911343, 0.3914364117276333, 0.18263995756579304, 0.5411452125907731, 0.09658466405097295, 0.3070265492341203, 0.4193954791980937, 0.39328947582864293, 0.30784790379287025, 0.09757895466460727, 0.2103286800017686, 0.11078743043992645, 0.19348025771130342, 0.06073205690058943, 0.2548664365341808, 0.3801969894781728, 0.1771426603604003, 0.24238065018965452, 0.16529014826691057, 0.16348910319051266, 0.3796421180830727, 0.17139524606796225, 0.13472274076811575, 0.22265374041558483, 0.06300138824433184, 0.2729582198868009, 0.17370991344697728, 0.3266114210492053, 0.2244130093122951, 0.37134976066105496, 0.2569225628987913, 0.09845381853655501, 0.07523417074606803, 0.340713237698451, 0.10122471633158613, 0.12940173816453976, 0.2814622228464216, 0.3451150816584305, 0.08825488911163198, 0.19475009901981247, 0.16826582726009243, 0.2526672480120316, 0.205723747805579, 0.08501493806304458, 0.19507301086725037, 0.27105048138154075, 0.16417982997604583, 0.23017751053510205, 0.12693316112365147, 0.19214571754474, 0.47081232544410684, 0.23728833524693665, 0.14314406385067427, 0.4186641265250125, 0.11105748514623145, 0.09214461878784752, 0.10399406577488195, 0.17498442375429907, 0.2201415316682779, 0.43949579319862797, 0.15965104223872337, 0.1324353755273092, 0.378767108547247, 0.3190045736993002, 0.07105487406097315, 0.3633988980660847, 0.38040325185140306, 0.29056310926865775, 0.18690117586102295, 0.29725478502662706, 0.22792943945437047, 0.08959013405883522, 0.331084313025555, 0.2354902070813459, 0.09007263392156106, 0.12520951985613127, 0.17210621940591478, 0.19215284909685423, 0.4635942964463554, 0.06856968105470042, 0.10573022134284786, 0.07649020234155463, 0.3153657077393197, 0.13530106970167788, 0.12851379401628657, 0.1734189501155224, 0.3055442813310258, 0.1542968744932912, 0.09702212061767183, 0.2976528625835526, 0.2646052729772388, 0.5180441018701378, 0.07683517374017756, 0.46144405800630206, 0.15868949843403027, 0.09548331959061428, 0.21328712174001557, 0.19427825082044692, 0.13925291149343288, 0.23403814535566125, 0.2924526138739734, 0.11210341641923359, 0.210238472603721, 0.18523102697323793, 0.13572316672612308, 0.1804691243276742, 0.22094690706638231, 0.2534022833613953, 0.13745051933266955, 0.2256912243152258, 0.359819307147896, 0.08185221899698229, 0.46454689739101174, 0.35984786172473826, 0.24234519083257147, 0.07406775822053675, 0.083154065969355, 0.14382555993730883, 0.2807887973597066, 0.1982961163836567, 0.09368347913877062, 0.4005785383535863, 0.4166161908424612, 0.10299195235043143, 0.308382665320093, 0.2496489554127296, 0.34072452483893745, 0.07078795089556612, 0.2860650181149105, 0.28303119676997945, 0.10453974227955773, 0.10977204317653959, 0.1398290586565694, 0.3887500264002243, 0.16657857030644765, 0.23537166758251657, 0.10110881371858993, 0.29229342093583, 0.32211759067534174, 0.09664242710295015, 0.1159046035291225, 0.20937804020119755, 0.1112621669603166, 0.29777762218446485, 0.15168339019706084, 0.14414059527297077, 0.17197572409029535, 0.20743903038819717, 0.1382317944184413, 0.15018921140381328, 0.21297860235323948, 0.2232140497555318, 0.16420976021023231, 0.11586140579629053, 0.41458799155409676, 0.0827009171360251, 0.14785479166652601, 0.46040890425171366, 0.15434456852252249, 0.20663132062206688, 0.12335188710170863, 0.06300138824433184, 0.15634204119315898, 0.11343688799184243, 0.09942387691177679, 0.09437452744687332, 0.28739122785167037, 0.16466432365338585, 0.46144405800630206, 0.28009817913046886, 0.17251488766606882, 0.13728719553704724, 0.07558878085724456, 0.18647736374746446, 0.18684091185797838, 0.27407856358245064, 0.15353384644049559, 0.2214493885410657, 0.12576988939485917, 0.24540718787030089, 0.3786380783022389, 0.15060502906837947, 0.11036045067089109, 0.07933951904188578, 0.3786412782414327, 0.19035737447526477, 0.22791719290804283, 0.23343908027075966, 0.10535243797781982, 0.1813048406021256, 0.12341841772018679, 0.07526643538532277, 0.17047809260065855, 0.23202371064312563, 0.13234904178343246, 0.07525652104327031, 0.3911678633434662, 0.2781155138731833, 0.12792442750235078, 0.06539165391261834, 0.10829999510540005, 0.07143020004669193, 0.2039440695778647, 0.22874611763730635, 0.10829238948638889, 0.14521146187901446, 0.09865975599054193, 0.2485361741805298, 0.17083924905743186, 0.39645260327804205, 0.09390189881667886, 0.1330735903988573, 0.2780694045236485, 0.12825390409377338, 0.1157536277103237, 0.2650785410821421, 0.10185631427932693, 0.08355569609127204, 0.2069561678429816, 0.10960434096550631, 0.22186696639367046, 0.2764795590751044, 0.08355569609127204, 0.4577421826022559, 0.19036326659264885, 0.27087877480078715, 0.24387256794175735, 0.2761860768084757, 0.41619986353673494, 0.08992597370487548, 0.20655128793127805, 0.442462711341335, 0.10065379978590712, 0.10990828246677005, 0.29451981492833856, 0.2232887645776271, 0.09151593191190556, 0.27298673585815686, 0.24506389930711311, 0.10273819316662659, 0.1287913580638064, 0.11344523074222952, 0.4269540368451598, 0.12876698146886806, 0.11003215226403067, 0.1084879614909312, 0.2230268610558184, 0.5183290502675701, 0.1235547823499783, 0.11167487642739943, 0.2047730424045647, 0.22520152559158244, 0.15212110039832918, 0.10319685746056628, 0.08964557114243688, 0.32618530802425155, 0.2480328239210627, 0.2217976930342692, 0.10791983996254749, 0.10310850572644642, 0.10852410963556564, 0.16588388030560539, 0.15916524772593743, 0.08347696110734046, 0.25422152986666696, 0.08739539986698809, 0.5239222838932264, 0.31738357725205907, 0.29747383204135414, 0.4382020428105253, 0.33445127591675666, 0.09166335172678518, 0.17632929828724475, 0.1262835793374292, 0.18974697282509193, 0.3000439871801452, 0.1940060246301193, 0.29291770518223176, 0.18903460306926537, 0.15329179830445877, 0.23534907065464125, 0.176982611936122, 0.09840852551629715, 0.2145547857337999, 0.2591623745643008, 0.15996634964706022, 0.31736090116599047, 0.11623585123871662, 0.41097483505905713, 0.11596086984123022, 0.2431301343637699, 0.09845381853655501, 0.3780921398848556, 0.16692097181969992, 0.06570438775827307, 0.35371917988505847, 0.09952230817995955, 0.17712424974931357, 0.216106585910105, 0.43907988137766757, 0.1700371969781132, 0.41091687654438064, 0.33663393540866143, 0.16516384166397663, 0.3398227045711749, 0.36126851311231484, 0.08739539986698809, 0.36611033464136944, 0.10005097133684511, 0.2010348222304756, 0.4593725187980618, 0.2697017760591665, 0.39645260327804205, 0.5239222838932264, 0.25438259213463416, 0.3801969894781728, 0.08903822696278844, 0.19491544568877067, 0.20663132062206688, 0.08806113568393577, 0.14183412496966932, 0.10399406577488195, 0.20663132062206688, 0.1561178051836001, 0.11783720225298094, 0.24906918171945436, 0.1090986969412893, 0.1842006272853377, 0.11224631478739748, 0.1122989041971205, 0.4732068381507385, 0.24731056003446297, 0.10917577181845563, 0.15883498362518036, 0.25872293358218634, 0.24097362912848, 0.39583969977458017, 0.12191874057251591, 0.08174192559842935, 0.08166517987149323, 0.21411192716711472, 0.344585248692441, 0.0725145803242768, 0.23880107193714317, 0.40266338020250275, 0.09235317451332468, 0.15057537630101137, 0.11164158705032463, 0.24540718787030089, 0.40177869031265484, 0.2577693148592708, 0.13224019085509914, 0.08470907181882945, 0.5549314685543599, 0.25097649810926637, 0.16992485867236357, 0.21874030247794984, 0.255022874006193, 0.11029548946141703, 0.1637789449680231, 0.09555026582993482, 0.1927573166536329, 0.3837998143748069, 0.31315378939009597, 0.24552976562383344, 0.10133405755763956, 0.15534854839432066, 0.13294599862140075, 0.06837193405319258, 0.3015233533023229, 0.31769719831031756, 0.41526460200358767, 0.3059765936759497, 0.19475732795785414, 0.3632235988799158, 0.17286110776641464, 0.2890930403679973, 0.24540718787030089, 0.202783320915588, 0.4635942964463554, 0.27183133026596695, 0.08524572201801134, 0.22215668376565845, 0.18177100958331074, 0.24032266677624428, 0.37010633848443425, 0.30474078446694486, 0.17179250122204534, 0.1072092793917592, 0.1870475448680141, 0.21082518564163408, 0.1889156495039921, 0.3128862117840931, 0.3552577770426915, 0.1258979985049822, 0.16813875155645266, 0.16062085650131513, 0.1101994259788876, 0.26812398009090926, 0.21619631149337573, 0.21548615920086692, 0.1779944593595325, 0.09658466405097295, 0.0987186244542507, 0.2702824189570654, 0.17238325290153186, 0.11519268277650858, 0.26705093009153724, 0.06073205690058943, 0.09611443245880968, 0.11078743043992645, 0.31726929878074284, 0.13389172463599427, 0.21036850532698104, 0.25097649810926637, 0.18499588680769835, 0.3590062623466837, 0.13038774944643716, 0.24319779410938377, 0.10110881371858993, 0.12102638546752038, 0.17878576055640477, 0.07408649755274496, 0.3508602997374271, 0.06687547793446871, 0.11968708733114279, 0.1089311843094703, 0.0837004073950204, 0.36886114291474636, 0.2437626626761545, 0.180068145454195, 0.12215330179608509, 0.4635942964463554, 0.310803290456337, 0.24024860403336806, 0.47081232544410684, 0.1367275579395774, 0.4357490794610577, 0.09103484088004127, 0.17975595505999067, 0.2477144280969435, 0.23210394887759545, 0.11847275272622682, 0.08334016609230102, 0.494743475332184, 0.07968867368279473, 0.09098009191968712, 0.1399441201138631, 0.11802097664634369, 0.35377340978110916, 0.3402466515077308, 0.45363662071777916, 0.22814400376254715, 0.19245009415766987, 0.2065165724415169, 0.11961840634121232, 0.18925984086791267, 0.4523756734326721, 0.12671741778137852, 0.3045708957347333, 0.16947207341807408, 0.1543421082012817, 0.22646717893254326, 0.5239222838932264, 0.14280562569378177, 0.09658466405097295, 0.2133981930366337, 0.11607037107210229, 0.12693316112365147, 0.45577105291252157, 0.13002820163182155, 0.08806113568393577, 0.14864876736506955, 0.2736477901314651, 0.2655198080040115, 0.08005010919984903, 0.14758556243885754, 0.09007263392156106, 0.1537669597892368, 0.2758523203337299, 0.13435154326371704, 0.11210341641923359, 0.21630848122878765, 0.23938832874820173, 0.22186696639367046, 0.3786380783022389, 0.272758526748089, 0.19964204955809442, 0.10553348228515527, 0.22567931255603563, 0.10960434096550631, 0.11044949010018483, 0.07518893699977446, 0.29808797878243, 0.1731927849229652, 0.24491977956876546, 0.30509520618117053, 0.19678349905570403, 0.10659765325985264, 0.1831906937634876, 0.07668853574944601, 0.15393963589662513, 0.2020272717571585, 0.18705161764139433, 0.21286930482294264, 0.12771259739324256, 0.30809229111323483, 0.30388243740463855, 0.13116147963551292, 0.16678804007291367, 0.1511574343315566, 0.20384228982377417, 0.15219899644392929, 0.2510769238411473, 0.07817256398964917, 0.15286694881452068, 0.2774701318188216, 0.12591484780465606, 0.3567144568340004, 0.3764075490541435, 0.1629373829813011, 0.1382317944184413, 0.17972138767905738, 0.07393335515652631, 0.0854977775713635, 0.0900280499988965, 0.23956930722527642, 0.40067486371352434, 0.20937804020119755, 0.3397589381390745, 0.1492897251778884, 0.4635942964463554, 0.1382317944184413, 0.18904410174197342, 0.11466477509954114, 0.2697312843948728, 0.18606894524347134, 0.30816576740184537, 0.2181342671110067, 0.21891174803485822, 0.33167281100158935, 0.185967814692706, 0.11195670624695336, 0.19915264277891778, 0.0700465184364869, 0.18125066667989173, 0.3487355306541218, 0.12188815260620961, 0.09856455724216809, 0.09658466405097295, 0.46144405800630206, 0.15018921140381328, 0.44325896861664005, 0.15708692264374532, 0.09444975364254456, 0.16082368460654622, 0.1719865827291698, 0.27771376676447157, 0.21953688266357285, 0.11195737026560676, 0.214466687114478, 0.17204519179510763, 0.12332040504232958, 0.24811036725042787, 0.07347549535329109, 0.297766779770072, 0.19491544568877067, 0.2231415657854666, 0.26502279398356443, 0.344585248692441, 0.08144177740190778, 0.24540718787030089, 0.32242931116737306, 0.3303266127830443, 0.11059597423191646, 0.11362249809565413, 0.5028446307030995, 0.0759828311353604, 0.22958645085406382, 0.4738064876739099, 0.18662681373377005, 0.3421882894918002, 0.11262843000320391, 0.20503939957502598, 0.15314637100842254, 0.17913075957207553, 0.19519394766091613, 0.08609925394060054, 0.5549314685543599, 0.3293471108725473, 0.07983090279495493, 0.2439441776264137, 0.36489310441023876, 0.40872835359098936, 0.13523042065717403, 0.09702212061767183, 0.2107596763344602, 0.1848252815923674, 0.3740750892621171, 0.10943314362596451, 0.11159572287579411, 0.21563374467851712, 0.07429945422661981, 0.35152881145794984, 0.498360595429511, 0.2069561678429816, 0.21962465046791954, 0.18605634132223683, 0.2565731716252968, 0.3833260959499392, 0.10006353688632762, 0.12297647071077013, 0.22317334340947095, 0.3762261110196187, 0.2210114734477418, 0.25954739083272316, 0.09366470120340381, 0.2086173013138388, 0.15217720027379256, 0.22520152559158244, 0.06935741516638566, 0.14267498801642425, 0.25333955272080344, 0.2348750684545932, 0.17547010599994675, 0.3558302591796095, 0.3469549023259439, 0.21588456584183832, 0.35164073323234624, 0.2589662478489806, 0.21411192716711472, 0.33382320984073155, 0.3682342831362671, 0.38676421652851456, 0.12584227339452508, 0.10257657680366812, 0.1078366298470295, 0.08800800197230849, 0.2599094280795486, 0.2020272717571585, 0.08995431659515768, 0.31249296587450937, 0.2923291177823477, 0.07074639568696141, 0.35936538084461955, 0.12363892758055502, 0.4414394285359859, 0.20067294246962436, 0.07687544058359072, 0.09595734940833978, 0.1084696426485392, 0.1089540518640767, 0.4309932514792643, 0.28484373843854643, 0.4471376251806086, 0.19772582859292157, 0.1225181059910072, 0.3417359867386339, 0.4306046438632438, 0.11610684428367045, 0.13659696625020196, 0.2721189441693736, 0.09865975599054193, 0.10304051109875706, 0.2180783202114097, 0.08442428380712629, 0.34318799366360014, 0.15647738252013124, 0.2175115523526129, 0.15353384644049559, 0.26428334299224454, 0.12135211756212275, 0.21743658256477308, 0.1940060246301193, 0.11351181038570525, 0.2857365521527766, 0.07486456461032948, 0.35338604414341895, 0.2584942691727551, 0.07363345254293997, 0.12283835318039962, 0.09778773883955105, 0.12769444467359053, 0.17887424280271247, 0.14693745495114827, 0.10868093041218328, 0.22651936672629053, 0.22981610791538348, 0.09856455724216809, 0.18037162387952096, 0.11713922439379379, 0.33486137129087473, 0.37979799787594815, 0.2646052729772388, 0.18189988229770238, 0.30866950586611347, 0.0856012458483661, 0.19519394766091613, 0.3671410207787601, 0.36080082476239944, 0.09333933810920544, 0.12584072896500254, 0.06687547793446871, 0.24955029827948044, 0.08364895238140588, 0.16608818515979126, 0.06899629990198752, 0.0833879755288064, 0.18749411122724188, 0.08367381984523385, 0.13204568813839349, 0.37859278923334133, 0.14145213650179303, 0.14250510121962642, 0.07523417074606803, 0.30956622182516613, 0.0888458687578359, 0.3058755389229672, 0.09159297120457373, 0.13266870896246166, 0.09326934227287194, 0.19025539503737446, 0.0674817322049431, 0.2095266104621608, 0.3190644406597915, 0.10256846962170206, 0.16683829789589885, 0.12653733037629133, 0.11029548946141703, 0.19670839932388792, 0.09180003941453026, 0.07159663254387956, 0.43403887553563336, 0.2670623516072505, 0.1583319096005836, 0.0888834097932776, 0.31431014056911794, 0.43464323699455903, 0.23134583103902978, 0.20615018687928208, 0.12459968393135534, 0.06073205690058943, 0.4584385605951401, 0.1578535292267406, 0.46544750345276004, 0.20392055533822143, 0.2298856316036818, 0.23173360831093504, 0.22214709342481062, 0.18966029714106833, 0.32382769297327246, 0.07726786002120126, 0.3489883551744778, 0.22169082986528876, 0.09548331959061428, 0.2387078664387562, 0.0969625766969754, 0.13964608624640368, 0.2638459275719732, 0.16647947074012084, 0.2831445380783609, 0.20661901583370423, 0.18874101217921782, 0.2043612457964287, 0.16196898985007552, 0.33231566761167386, 0.2812652753912411, 0.2417872435156888, 0.35072213980885364, 0.08487565184528283, 0.45919502317042765, 0.28045847681397157, 0.10458110810748274, 0.19520495771770258, 0.0854460456031219, 0.339722262371132, 0.08806113568393577, 0.350364866040375, 0.2852534020999316, 0.10060471828574218, 0.10373268255853997, 0.2599094280795486, 0.08151652577144894, 0.07233164068136477, 0.25375538590034036, 0.20054020962792904, 0.19519579983435237, 0.10464309954290658, 0.4324426395736516, 0.07538944401196648, 0.09548331959061428, 0.06053990262781506, 0.1235547823499783, 0.10841979587645502, 0.17210621940591478, 0.36865222435754824, 0.20088929787981946, 0.1880362520576558, 0.08174192559842935, 0.15426391464487726, 0.12098315207179042, 0.18979266705346223, 0.23377312826581148, 0.20656646398808468, 0.11745372807082298, 0.15402108255566832, 0.1475870457046651, 0.14529735649869374, 0.40415305570515314, 0.19328880231364992, 0.11704999595629244, 0.20308651871138658, 0.2331428144067868, 0.2126157088079419, 0.09197661673092535, 0.08629961349442514, 0.20168155903006255, 0.20723681385853812, 0.2724715807295456, 0.1532794474033019, 0.10223352428675402, 0.23454716985853774, 0.2436744185437406, 0.08323026287122309, 0.1147368985889716, 0.23808386019200092, 0.29036766018937504, 0.3865074138798915, 0.238433395463632, 0.09008228282461067, 0.11802097664634369, 0.24814483966881196, 0.07832231301091017, 0.11659080502563035, 0.3592937334767166, 0.3617225961237265, 0.21286930482294264, 0.06525637583806462, 0.1489342777871133, 0.25916845375293446, 0.18962394614510322, 0.30049507668275116, 0.12613859046578843, 0.2983889376174128, 0.35393913466933385, 0.163397880993793, 0.35677906972607476, 0.11771115582223082, 0.11132762627616255, 0.19767543806184026, 0.19978174470332768, 0.332780318690292, 0.2231415657854666, 0.1056676618930356, 0.1943381469440125, 0.2903235767356822, 0.10510940698468921, 0.21161512617779016, 0.17371166742843688, 0.2569521713599894, 0.19041564486680543, 0.16284368965546483, 0.1851565793022167, 0.08806113568393577, 0.3567144568340004, 0.06899629990198752, 0.10964632554251433, 0.22216874898445768, 0.19118383804945852, 0.45363662071777916, 0.3777272086076232, 0.294963103741391, 0.15937914755865396, 0.1478083773477641, 0.46056186611768957, 0.49275780074430847, 0.18461980509728715, 0.13897998387178082, 0.2106281688934806, 0.26397528707245893, 0.1135538565538449, 0.44415253762678053, 0.3502142450218003, 0.2566052735618574, 0.14866152689240045, 0.1082052578905603, 0.10368236026930853, 0.259758248757476, 0.0969625766969754, 0.24552976562383344, 0.14000030485046255, 0.16322861988918835, 0.10658675590473454, 0.26685094070335214, 0.09241819996787946, 0.20663132062206688, 0.09132422341430033, 0.35138389512385976, 0.26323338558848597, 0.2214805055330343, 0.144181006247277, 0.12102638546752038, 0.154941005213941, 0.06208980640758496, 0.24589371974224214, 0.16934747662972638, 0.3688115823276583, 0.20525637279907816, 0.1056676618930356, 0.42292283156900945, 0.27921431155421744, 0.07233164068136477, 0.1378379711500981, 0.2565731716252968, 0.18385503364605116, 0.2384507811336454, 0.2487865170896914, 0.11036045067089109, 0.1309348198119213, 0.0912500441740899, 0.3939345146147941, 0.21772350969572243, 0.3764075490541435, 0.5549314685543599, 0.2166487806637838, 0.09832885819847641, 0.36888712444685495, 0.18745276782074086, 0.22749397535747257, 0.3392498223686489, 0.0795606943674271, 0.264566598992448, 0.20280270430237218, 0.08817039380550587, 0.09886431262040651, 0.11907817243740915, 0.3162656463240687, 0.18008439460288034, 0.2091783995142556, 0.30723408114166345, 0.1490314811740831, 0.1780240737879929, 0.1378379711500981, 0.49275780074430847, 0.2728680317852613, 0.44415253762678053, 0.2403461551505365, 0.1785171500621867, 0.14203777214420352, 0.28030906342719536, 0.14314406385067427, 0.17917676509596525, 0.17761202058864278, 0.3546378837853316, 0.19824389890735974, 0.08081491674704817, 0.06541999613233886, 0.06731128901454048, 0.11793087553488725, 0.10813771837243186, 0.32776161748665944, 0.10829999510540005, 0.3059880127865185, 0.15018088795011567, 0.10343866420706235, 0.31693640429619463, 0.11394942095589063, 0.40654449471090237, 0.21619631149337573, 0.19986030573697944, 0.34882985164577307, 0.19281553372562368, 0.10845659224634609, 0.07030029080398612, 0.1050613298950451, 0.17884893830731485, 0.08343637919859691, 0.4535286389567853, 0.17563474363039994, 0.3371197264342377, 0.40067486371352434, 0.10458110810748274, 0.36224846198895, 0.16744260079877385, 0.15516537536334474, 0.28009817913046886, 0.23460491739196726, 0.17645592610235095, 0.07746796604042164, 0.259702959940223, 0.2716271941712482, 0.31643469010527836, 0.21121351148763395, 0.35398226376060965, 0.2211304523408176, 0.1108780628862626, 0.18955575201974387, 0.1139684357992528, 0.16875372703961053, 0.16229853768761635, 0.18025234418229558, 0.4627125376665781, 0.37896346706188383, 0.14119419574283226, 0.4840468968667951, 0.38672203676480815, 0.20609474956690257, 0.1537191760385771, 0.2670601999139999, 0.19443945569255522, 0.15981550018785856, 0.10829084321475511, 0.07963822832737762, 0.12387037529715468, 0.3643995358341851, 0.316301913863801, 0.512446074388722, 0.24540718787030089, 0.12800909340225755, 0.43464323699455903, 0.1777319525838392, 0.45335880192277067, 0.28515566844609674, 0.2876224367748015, 0.3682342831362671, 0.4840468968667951, 0.177969527082393, 0.10756521338345162, 0.20467633525297407, 0.09664242710295015, 0.1311227273665902, 0.11120289933216951, 0.14119419574283226, 0.16647947074012084, 0.4230433884968552, 0.10917600583472846, 0.3643995358341851, 0.15328714009289993, 0.1937738611549069, 0.23310487473595895, 0.3035299655766424, 0.40711415656912825, 0.06657395241553832, 0.10082954479999023, 0.10426382666180092, 0.15403980574193554, 0.19862496669129465, 0.2777362165511124, 0.14269597297128175, 0.09878054113665635, 0.20467633525297407, 0.1825691809902214, 0.15583773654680289, 0.12136406761668996, 0.1159046035291225, 0.4141558113019288, 0.11273333737914336, 0.20322151479667114, 0.07002756952821594, 0.11246106305152835, 0.13298352000459066, 0.33666384509952024, 0.35906919305253904, 0.2362170468475936, 0.21195578334489498, 0.1082052578905603, 0.07429945422661981, 0.2349842002408859, 0.38595071638781664, 0.250524355104142, 0.2649618794410299, 0.1302175258295744, 0.37340209492388926, 0.23646530994057455, 0.09546841728319264, 0.36761538469922, 0.21563374467851712, 0.31592474146396315, 0.10086262294150643, 0.08773012512941428, 0.11362249809565413, 0.18159591114639637, 0.11771115582223082, 0.09702212061767183, 0.11774359749414874, 0.1359827954836391, 0.31848063738082466, 0.18404634142130005, 0.23984829892251938, 0.1770154800874603, 0.3009173290154491, 0.494743475332184, 0.11269459121142046, 0.07964827949395577, 0.491906500682251, 0.12753016880202525, 0.12076382206479155, 0.14538310414617583, 0.08090203547311034, 0.19281553372562368, 0.22814400376254715, 0.07803553797839667, 0.09127109044707657, 0.08680407206076382, 0.1808129758027812, 0.15916524772593743, 0.5239222838932264, 0.21384545190120627, 0.36120066758490404, 0.34254856206437767, 0.22687474633725704, 0.2693362674839102, 0.4324465041869731, 0.23549079704175965, 0.2844749648690462, 0.14901274293561959, 0.18075730604796747, 0.21526253348369073, 0.21649773623022864, 0.18159591114639637, 0.10310169448027623, 0.28218024967209754, 0.074159598660021, 0.23993910118507283, 0.11029548946141703, 0.2179134381000662, 0.11119884278470249, 0.0948592235656538, 0.10133833580776856, 0.12970157118263442, 0.13294377022856116, 0.13072239865240043, 0.4036582298195554, 0.15234213199276622, 0.2548035164614123, 0.20852091949193313, 0.24783893167677337, 0.2510167643496839, 0.16953872318983906, 0.24032266677624428, 0.40981019933798046, 0.0959036383325236, 0.3007470140212993, 0.13911336005271993, 0.1663097962716043, 0.38056467670645266, 0.39905361356750174, 0.08489896606795169, 0.17307798985981687, 0.20966937705743, 0.46298264551873997, 0.11288572041753267, 0.15575812674066272, 0.1159046035291225, 0.12227779558316673, 0.2077497042874492, 0.17251488766606882, 0.41089685917674507, 0.1815523210052369, 0.11542915031373754, 0.10248424017048799, 0.34969514258385775, 0.13557416231279554, 0.2256912243152258, 0.07078795089556612, 0.24394638762929424, 0.2786611882376199, 0.0969625766969754, 0.14469896844220204, 0.07797807673049414, 0.49465515843344404, 0.08818760041221535, 0.4247094895577783, 0.08586301525046382, 0.11873835764947303, 0.09699470528068962, 0.5028866784036793, 0.09827019681995658, 0.08224326166303429, 0.21498436231386692, 0.25211650527707397, 0.2257076228821928, 0.27983515316846225, 0.1399441201138631, 0.16934747662972638, 0.17716601430997234, 0.06666526567299244, 0.23967872741062984, 0.1338994264605405, 0.3442936644899018, 0.20437948119098995, 0.12208163574722528, 0.08232086192360429, 0.30705302880123514, 0.09393679141139136, 0.16229853768761635, 0.1678497710088697, 0.465535409546139, 0.2213851288286831, 0.35377340978110916, 0.09954284190067497, 0.07450503438987768, 0.2608225079262041, 0.2685894529146755, 0.4809299714630433, 0.2659190135977007, 0.47081232544410684, 0.13008131108923318, 0.18600234307300798, 0.2922245132192001, 0.22168197815468543, 0.07718669798355614, 0.10837996365949747, 0.2032655000049159, 0.42268250381967865, 0.1399441201138631, 0.39166669513857916, 0.24145180872122352, 0.3542731363086482, 0.16916343885345617, 0.09916346613947336, 0.17550630085200475, 0.38381955589997196, 0.17286110776641464, 0.13242261796737656, 0.10510940698468921, 0.4736413009951711, 0.23579575154231808, 0.17731034820882657, 0.4193954791980937, 0.07938001022215706, 0.3516253625131718, 0.4523756734326721, 0.10203537487327549, 0.19098879208989472, 0.09217616719131559, 0.36277734414164764, 0.3041938122500779, 0.10505057112902129, 0.0979154081687329, 0.09996158904964439, 0.12112611744591344, 0.09638259486819135, 0.11421510622969301, 0.27497824478144517, 0.4535286389567853, 0.12205735552945936, 0.20284874866168803, 0.5183290502675701, 0.09865975599054193, 0.2608159225245248, 0.20320177286490382, 0.30474078446694486, 0.07786020518546542, 0.27968391548848126, 0.08873160494208596, 0.27302386577035487, 0.06550905699247413, 0.1082905025951151, 0.32811047720895287, 0.3418996748383289, 0.12207932170005316, 0.10250843365147656, 0.27422083719015516, 0.2595170804300687, 0.12366678792611042, 0.4229092529849751, 0.3312704618655979, 0.20663132062206688, 0.1820823474475673, 0.3911075056070905, 0.11642250282455634, 0.10110881371858993, 0.08124474766995043, 0.08988283336012741, 0.18233866704922, 0.1527361145357344, 0.2685894529146755, 0.3254770848351953, 0.16121228966925363, 0.1312641191682781, 0.1235547823499783, 0.1984258693454913, 0.2736839247278088, 0.1790800651042703, 0.20336277590096533, 0.10086080304111249, 0.26100938241124777, 0.47725014975552754, 0.43970374717959215, 0.25598091119534794, 0.10806687263428523, 0.3111206240509868, 0.07565682540664162, 0.390476399238465, 0.08574578673581028, 0.4340757989884914, 0.0860634868481291, 0.10934542245298659, 0.49049742031931487, 0.10671260555854456, 0.18767498452250805, 0.26003675330425097, 0.1951232291538173, 0.09658466405097295, 0.08767075093201798, 0.34935308433775836, 0.38675627575012683, 0.09207738051880626, 0.40598132932172526, 0.3900878299248684, 0.11006823009721459, 0.2860627730744927, 0.20820554175729816, 0.12584227339452508, 0.31513262103260964, 0.10714594965328691, 0.2106281688934806, 0.253907085829003, 0.10343866420706235, 0.1201097780906018, 0.2944905755544633, 0.08102526840095968, 0.1602007175159972, 0.21874030247794984, 0.23137281779296692, 0.44822342138805293, 0.5700375387374911, 0.15005021925907425, 0.30479941451918513, 0.1951232291538173, 0.21155151869607727, 0.2487755502828623, 0.14179024344916213, 0.41675383038235647, 0.2270724567553588, 0.24540718787030089, 0.13925328219835909, 0.1442870210332163, 0.1833155439715552, 0.1524225051317454, 0.2179912756412439, 0.16928281200550657, 0.20326188820725427, 0.10100049863706673, 0.1178069208042978, 0.12435675462123831, 0.41692535596905905, 0.24778517371809544, 0.2548908365832036, 0.24844695730236796, 0.13621988750548136, 0.18650136972026587, 0.15696177760442992, 0.1522593219616557, 0.1787740324339981, 0.08766483970810282, 0.20703845097951454, 0.5231028569024795, 0.12763757484911026, 0.08975221788280867, 0.07264829333636019, 0.17251488766606882, 0.1907631967056278, 0.19491544568877067, 0.41125295611304896, 0.11773463960010713, 0.09628199553915182, 0.20914077218385083, 0.1391543553333971, 0.13008131108923318, 0.1446562325330785, 0.11262843000320391, 0.2364967433081805, 0.12698446945718272, 0.13833887826770036, 0.3007470140212993, 0.16670881031932194, 0.20625500013224815, 0.20207756662475335, 0.07704799972025744, 0.15271894156963864, 0.07422654564552851, 0.3911075056070905, 0.20757227854001264, 0.23673192489379852, 0.46049152798525805, 0.3000924262725906, 0.13150348486555988, 0.21411192716711472, 0.11675771229841313, 0.17073326605557892, 0.21411192716711472, 0.12413982894174488, 0.3642412826335594, 0.17792171055847988, 0.26700343860644393, 0.1261359653367235, 0.21286930482294264, 0.11859481385764542, 0.4447148976328462, 0.31080169167776367, 0.11269459121142046, 0.3633557344623362, 0.43719921718894106, 0.350709580714783, 0.18658803981740166, 0.13690409366772655, 0.1896250349805132, 0.10458110810748274, 0.07913382533531248, 0.12487195312698791, 0.15576986424988645, 0.5493892126792724, 0.15291411022824128, 0.0977325537584475, 0.10156445765440435, 0.1512606419297513, 0.06489746594670372, 0.5493892126792724, 0.11530162671359652, 0.130232119832309, 0.26367478466427713, 0.20207994098924315, 0.2345741911146574, 0.16484465276343965, 0.10276631744967875, 0.1908500787238502, 0.3046591955762865, 0.3990782828498813, 0.26004687170842866, 0.38076506897615797, 0.1382317944184413, 0.21563374467851712, 0.07393335515652631, 0.12528092710337296, 0.25131168988412683, 0.18655549475108357, 0.2595170804300687, 0.13908768494736526, 0.12477962709436335, 0.21459445463384624, 0.3786380783022389, 0.11717124195903657, 0.3667980546346403, 0.195961890714812, 0.2595170804300687, 0.2699862326859021, 0.5100235976029414, 0.11029548946141703, 0.2165168581447053, 0.12449788633401282, 0.07523417074606803, 0.1819695593780241, 0.24446060628623917, 0.41459628908922347, 0.21141404973015662, 0.1135538565538449, 0.12056440221538564, 0.08702712358904739, 0.33362075194397145, 0.28612750675112286, 0.1640905592735886, 0.17150254570074971, 0.42163335059987245, 0.2860627730744927, 0.17852697562465972, 0.20855362231416408, 0.15881322925725314, 0.11036045067089109, 0.34490856799812314, 0.25972955786028246, 0.2681076386156252, 0.09783715122424418, 0.332671471689211, 0.20681223872339277, 0.26268644412016534, 0.11886268250309316, 0.09280169112019374, 0.1411265339824678, 0.15497370344581227, 0.13513805976954388, 0.24734382658377357, 0.19001059477943288, 0.10258551892455658, 0.1300179020838589, 0.10066101526456403, 0.24759324260214757, 0.16535543148923887, 0.15677823649001732, 0.15525089786003032, 0.267118328536109, 0.23938556237749367, 0.2797455564043549, 0.3087206458890742, 0.2271115935249036, 0.17740702813844994, 0.2096870480456893, 0.31012436093714746, 0.0854460456031219, 0.20970335066928406, 0.38344922129885395, 0.08059985739250926, 0.18966029714106833, 0.17779365392543436, 0.11452243675269923, 0.16608585980849366, 0.13073233953003793, 0.16602951902896287, 0.0913330882130889, 0.363520875485873, 0.11884954014136753, 0.16196898985007552, 0.11378281685198921, 0.19786100212698476, 0.06073205690058943, 0.12879973582501905, 0.42685157688274444, 0.17439066736193568, 0.2866246316301329, 0.494743475332184, 0.23957481075471218, 0.3643995358341851, 0.15353384644049559, 0.22761923909785484, 0.20382328689724286, 0.21106401520938387, 0.33287627425792693, 0.3264883982714738, 0.32407727005874754, 0.28415529478801704, 0.1735778673317683, 0.1130667895722976, 0.22095995656624354, 0.1522593219616557, 0.25375538590034036, 0.0912914962698009, 0.18380243635927426, 0.11944062389733347, 0.5078608823913536, 0.2524760257579493, 0.27262485701202793, 0.26911110240409114, 0.0709239879655079, 0.14314948672650943, 0.2646052729772388, 0.34490856799812314, 0.4593725187980618, 0.22130851310978644, 0.08898518202439509, 0.19025539503737446, 0.46144405800630206, 0.2797455564043549, 0.09257396532514865, 0.12314645695466622, 0.23202371064312563, 0.33035773121504014, 0.1521739165265494, 0.31016584282913906, 0.20031761800226272, 0.3781580815950701, 0.20305824717108295, 0.26726407657819, 0.17867716826306684, 0.3058636096667137, 0.1360730816577935, 0.1584680292584251, 0.19491544568877067, 0.14701032472556888, 0.1694440985439485, 0.1101345478190888, 0.36282446839783106, 0.20769860431371392, 0.09871381419233655, 0.10990828246677005, 0.16734224749357218, 0.17673190615994908, 0.13031816292884843, 0.17968890655126335, 0.2880082803885656, 0.41413378569115145, 0.1382317944184413, 0.19549679493254846, 0.10821801543547985, 0.07856391017490716, 0.30809229111323483, 0.19307219712194543, 0.18106179563996888, 0.06754171148495008, 0.1523367555807326, 0.20194102646761655, 0.12317302758830735, 0.15163644843035035, 0.23748935649747688, 0.10224700255991956, 0.08903822696278844, 0.12063350524882456, 0.06073205690058943, 0.4875422997250109, 0.3786380783022389, 0.21161873145204443, 0.0931090326229168, 0.10005097133684511, 0.18049702096374118, 0.06761591215442415, 0.13881704710252787, 0.10579657337503824, 0.22398717788717804, 0.13389847068812072, 0.1001703299115333, 0.12091319619494192, 0.09166855374426496, 0.18525645098043034, 0.2231415657854666, 0.0828430071402968, 0.2572218386627403, 0.1466897068682883, 0.09160267723557237, 0.06073205690058943, 0.10700284351410168, 0.0996264026689945, 0.3091667032668833, 0.20740400848024002, 0.30524002442761855, 0.23803428701174978, 0.4475551332435703, 0.19736276656363605, 0.179736533117397, 0.2106281688934806, 0.17589856295591388, 0.11195737026560676, 0.22081326577827556, 0.2035671755671454, 0.20573818730356927, 0.1759129107410892, 0.11552324699482168, 0.26004687170842866, 0.4577421826022559, 0.08962291741103873, 0.33607398492134977, 0.11029548946141703, 0.3261265997522686, 0.23629388597166082, 0.07411495920937676, 0.2753248122451255, 0.09346354306211313, 0.13192748773033802, 0.08817039380550587, 0.4187376388870804, 0.23615368890668365, 0.22262529425863703, 0.20485801963052155, 0.39462973124811035, 0.2484388933333876, 0.08015706283807252, 0.1411265339824678, 0.14492059641031793, 0.11774359749414874, 0.07950289817766276, 0.10827890951700378, 0.2697017760591665, 0.27215618847587975, 0.07555069587515055, 0.09702212061767183, 0.22896396622518253, 0.12136779465396794, 0.27784653958283817, 0.08059985739250926, 0.08224326166303429, 0.33948836120756926, 0.13927456311969708, 0.22063868155727703, 0.4398581691804453, 0.22710486241043357, 0.09846262064911744, 0.14758556243885754, 0.26183716002930185, 0.1809164016915, 0.17650316413325673, 0.260661521750023, 0.06081587943684408, 0.35612518062017806, 0.1694405942136591, 0.21040408647208264, 0.37984258431660234, 0.1261712276338749, 0.20157502333376928, 0.2142233110285095, 0.11262843000320391, 0.41675383038235647, 0.1803112492294745, 0.19491544568877067, 0.12693316112365147, 0.31530452368954126, 0.23694384835887797, 0.18166383750231968, 0.22208204753268654, 0.06496164224629872, 0.31359582864437086, 0.15302102668909257, 0.06073205690058943, 0.11262843000320391, 0.13249921676724338, 0.1611623202376445, 0.18166383750231968, 0.2544573302991445, 0.32561913185529423, 0.10965699022442746, 0.3698467592688715, 0.21413356585719695, 0.31336590094609673, 0.12886132556310484, 0.17935197060773508, 0.20547318861189842, 0.205723747805579, 0.10955022397247488, 0.3671748241263928, 0.19964204955809442, 0.2355223221472531, 0.12693316112365147, 0.21329597018808705, 0.10851642934629031, 0.1864749192306635, 0.08993698735337165, 0.47589655784484514, 0.20266553941489907, 0.0836230905793385, 0.20743903038819717, 0.4011961361168609, 0.2382507915284044, 0.09658466405097295, 0.10533058401747268, 0.061680074548951615, 0.43970374717959215, 0.19888160553314954, 0.09009627381848254, 0.14566431018494097, 0.10250843365147656, 0.06073205690058943, 0.22921634126722404, 0.34923121489942294, 0.4309932514792643, 0.28009817913046886, 0.22633525430384513, 0.17907945057186356, 0.08022097669047122, 0.15228441342653035, 0.08477541178947781, 0.27899317017979547, 0.13613008869144416, 0.11004128931343057, 0.12136406761668996, 0.14480458215187728, 0.07144832356194228, 0.22499965088658294, 0.08916954645935533, 0.093005821887208, 0.24566893951186286, 0.12920673039336086, 0.18666956242843613, 0.1657050976449586, 0.10700715832693969, 0.18286018229463694, 0.34935308433775836, 0.10749262258081793, 0.23453802452817332, 0.1423021547215237, 0.31365290355998365, 0.144500264782976, 0.16393903223761136, 0.09061400637525167, 0.3196717340237519, 0.21752021042929304, 0.22195983654726067, 0.2014705443231687, 0.40842350881032274, 0.22440624309453489, 0.341285984196491, 0.20054020962792904, 0.1400237953499306, 0.4840468968667951, 0.2249743062865074, 0.47372888551931136, 0.1399441201138631, 0.07049294700973595, 0.33445127591675666, 0.15219899644392929, 0.1588541551943454, 0.28045847681397157, 0.11968607647430479, 0.16420976021023231, 0.17451149120219955, 0.20168155903006255, 0.24517797645196435, 0.18952939930252663, 0.494743475332184, 0.40654181729830524, 0.1766645887980765, 0.37376370154321775, 0.1759129107410892, 0.11974386753173086, 0.19500334677191408, 0.3521395879856657, 0.1833155439715552, 0.0949778432418597, 0.2406071899687357, 0.11909250408221796, 0.3621297246925455, 0.4247094895577783, 0.30315891768095776, 0.1328901564413092, 0.0801023789009718, 0.23616672053997614, 0.14940527819564836, 0.23929031187563118, 0.09534191019023945, 0.12218669912349138, 0.2432176986296038, 0.24319663877904846, 0.3069819210863845, 0.1701134774202393, 0.47372888551931136, 0.3547389236262161, 0.18606894524347134, 0.3132363382943539, 0.15360668466988542, 0.35285779076272966, 0.14616850145043825, 0.37812518097733894, 0.11181474815571871, 0.09332937611936637, 0.07892811227243583, 0.28049058452623993, 0.20255472704187572, 0.13206268471469587, 0.34831130560561574, 0.1311227273665902, 0.5700375387374911, 0.08945027580291413, 0.06053990262781506, 0.1390349189740036, 0.3937765165987954, 0.5152502740336528, 0.09694002291117974, 0.20078995349826878, 0.22161997602850414, 0.3116066158289272, 0.11504446131519512, 0.1770154800874603, 0.2670623516072505, 0.2867350090781128, 0.18952939930252663, 0.15328407960658014, 0.2961370298327466, 0.392227379835565, 0.2132606231531103, 0.11795210408777108, 0.1899198925306548, 0.4859960578476146, 0.38657073987052576, 0.20449418222329724, 0.3886087424622438, 0.1892633358184119, 0.07393335515652631, 0.19582558809486691, 0.4447148976328462, 0.12133873785349186, 0.14539984121818128, 0.07363345254293997, 0.3189257294228312, 0.08475395407977053, 0.1866709779338321, 0.1521739165265494, 0.10463291427072176, 0.4577421826022559, 0.11744415927821436, 0.16735937513239424, 0.08111865552833028, 0.16062575483672406, 0.09658466405097295, 0.25816089162248307, 0.20280270430237218, 0.37812518097733894, 0.11724396706190492, 0.39870354204030173, 0.38339293219814763, 0.22856315642752098, 0.3545869338517839, 0.16880387383535733, 0.5021690208050609, 0.10716459112664312, 0.1823829310802718, 0.10358428169587275, 0.24780407687159062, 0.2964623353709508, 0.2354902070813459, 0.10384579097063047, 0.13430616276183055, 0.23453802452817332, 0.08127711584600752, 0.0923063430321151, 0.11795210408777108, 0.5392068968415761, 0.09806808763435793, 0.10110881371858993, 0.12272538979693005, 0.08856352937532769, 0.20336277590096533, 0.2938129496194284, 0.30164573840611203, 0.09702212061767183, 0.2208249891641983, 0.08771939775685539, 0.2878713157584114, 0.2119182256518692, 0.2062224637602308, 0.34042925613654457, 0.10128518315708004, 0.22707819430658105, 0.3843022976585149, 0.0969625766969754, 0.22594176110195985, 0.2418668474897728, 0.13705890800263537, 0.15525513376297032, 0.13711914660942418, 0.19073630805882133, 0.18507611581899414, 0.3760400016033942, 0.5084471529420252, 0.3312704618655979, 0.16711261336125086, 0.149911901344236, 0.133180231366789, 0.40598132932172526, 0.07133285894630553, 0.08236283045940773, 0.15659829234396408, 0.08573078572988127, 0.5028446307030995, 0.3562014439060637, 0.20594694188089382, 0.13472274076811575, 0.2347473383708434, 0.2125049347579527, 0.21452816247483095, 0.46298264551873997, 0.2394157824777198, 0.2860627730744927, 0.1597309152651284, 0.10924980006881264, 0.10745690701754994, 0.09519882703985492, 0.07159663254387956, 0.09140908586808842, 0.16406779080170536, 0.19563617602557212, 0.06652636133647113, 0.2914745407351362, 0.23690223863147813, 0.23516840291673197, 0.2179134381000662, 0.24145180872122352, 0.06921331741874935, 0.276954953708184, 0.19579048405972518, 0.1159410046672753, 0.12780747578217613, 0.32958179025531176, 0.12799840234984108, 0.30632977447457815, 0.10305553427577502, 0.23218514645283078, 0.5700375387374911, 0.12034242673416905, 0.08359639678569974, 0.22851480533579951, 0.32681150805284465, 0.18835298379230905, 0.11562416849054721, 0.17315696332184444, 0.0929970254666013, 0.1279544672207188, 0.11112025871333125, 0.12693316112365147, 0.10756521338345162, 0.11542915031373754, 0.10299195235043143, 0.20098493312811896, 0.20958538425638334, 0.290388382199731, 0.17127036858293104, 0.3371346930200247, 0.21421368960651688, 0.13165286196052003, 0.18934308210051368, 0.2113088084380941, 0.10302288964027087, 0.10630499328342352, 0.11417016119407142, 0.20963276200390885, 0.07710388984478793, 0.147178307319552, 0.34277046898591845, 0.11343688799184243, 0.16744704304144636, 0.17145638415474837, 0.15353384644049559, 0.2230249687977534, 0.08100876494874863, 0.18134890043155835, 0.08085283839122577, 0.10649038556727256, 0.10835726827677598, 0.0965359150374668, 0.11949992318100443, 0.3149898022775563, 0.173960168168269, 0.14701032472556888, 0.06396662556574577, 0.22544752752771358, 0.19346467809642717, 0.2387078664387562, 0.16888093727136239, 0.1751634299575338, 0.18816399698812772, 0.06899629990198752, 0.061680074548951615, 0.19519394766091613, 0.13728726803272778, 0.13023657518828569, 0.14119419574283226, 0.25110093198086114, 0.494743475332184, 0.23877060730015084, 0.07665571202908801, 0.22639479682644503, 0.06081587943684408, 0.3646755490452386, 0.24145106057003424, 0.08495975129666973, 0.10957137317459721, 0.3586500494415827, 0.09500314374930922, 0.43251800575573257, 0.2834136039366032, 0.11150191578726013, 0.14993741238479746, 0.2375031022386114, 0.21283298302110243, 0.12631475387504124, 0.1223766975309975, 0.1521739165265494, 0.13516727466550243, 0.34825176026039556, 0.30866950586611347, 0.1584140326241518, 0.31023665807303713, 0.17197572409029535, 0.11364098916093218, 0.10719440322808808, 0.24630911736471556, 0.12773990393883747, 0.3683743487743048, 0.0935617709907011, 0.07370467225775079, 0.40598132932172526, 0.4020699314406695, 0.2296990375718905, 0.4415258020373488, 0.06758997632383365, 0.4229092529849751, 0.34969514258385775, 0.2463565100315627, 0.30479941451918513, 0.08126580646935319, 0.07107715325358097, 0.2395211193407447, 0.1311227273665902, 0.11262843000320391, 0.2381748198423721, 0.08140667416593718, 0.10689668284902298, 0.36407189278197766, 0.24300345558428477, 0.0877423014216505, 0.31029024786075554, 0.2814425140051181, 0.26591797178682836, 0.15358171106162302, 0.12800909340225755, 0.23698692371370758, 0.40067486371352434, 0.19200903098147332, 0.10319685746056628, 0.2825937843985207, 0.23717975817664527, 0.2786611882376199, 0.22645323916068558, 0.1948349449611163, 0.06073205690058943, 0.498360595429511, 0.09991095880692503, 0.13614258728848286, 0.27888741335207656, 0.07618560893293114, 0.0862208708911033, 0.0815681058387552, 0.2650785410821421, 0.26428334299224454, 0.09346810896715681, 0.3294695549648097, 0.2041122855709811, 0.13223300713715455, 0.08609925394060054, 0.16140920748955098, 0.12584072896500254, 0.10458110810748274, 0.22057737844574254, 0.16975050711572015, 0.19459788792319485, 0.34277046898591845, 0.11262843000320391, 0.07408649755274496, 0.07593599971987203, 0.2031547301579448, 0.29743064386824064, 0.1729128740219585, 0.19073630805882133, 0.12070398134445769, 0.17649793019165322, 0.34935308433775836, 0.08197640136282716, 0.3202762811008499, 0.23343908027075966, 0.5021690208050609, 0.4217195100330887, 0.14238199831736037, 0.14773907993657856, 0.10769458835541305, 0.2211227516005484, 0.1441004825162939, 0.4732068381507385, 0.19179275447798988, 0.08898518202439509, 0.08510174408311713, 0.0700723906812604, 0.12848073548856895, 0.07306425193850365, 0.22701866002410503, 0.2937301108669096, 0.0889015831452456, 0.20308651871138658, 0.11713307335773511, 0.3350448007722626, 0.5700375387374911, 0.5392068968415761, 0.5105371844077934, 0.0847794592795381, 0.10471866673005345, 0.1118909236118764, 0.350709580714783, 0.3261265997522686, 0.06731128901454048, 0.4414394285359859, 0.2944037017645952, 0.2374989597474682, 0.2251423927686935, 0.19346467965509034, 0.09104551091830605, 0.2228185676961265, 0.35906919305253904, 0.2462336542410364, 0.08472550225028738, 0.12030809234066143, 0.12395995447483371, 0.13389805914837552, 0.11809877053036202, 0.1082905025951151, 0.34984656312209794, 0.10222876015426102, 0.2510769238411473, 0.1509999409220315, 0.2391490421197095, 0.06073205690058943, 0.264566598992448, 0.1515796278090285, 0.2164191034192919, 0.2612605933800702, 0.08806113568393577, 0.36830051740807856, 0.08774110943365146, 0.2112606663454111, 0.26095019831573063, 0.16766253433148484, 0.1777319525838392, 0.3125859275076634, 0.3602923632109753, 0.24552976562383344, 0.33076827836683337, 0.16089501062371395, 0.10550364130944026, 0.13746378049295202, 0.45340634057696894, 0.2079599925266344, 0.14141228536608735, 0.1831906937634876, 0.2453764748899259, 0.2505972224407863, 0.1702810653656749, 0.36224846198895, 0.1157536277103237, 0.5239222838932264, 0.13044001322232723, 0.11262940019974892, 0.2612605933800702, 0.07575119149194134, 0.20171746633721147, 0.3897937978556139, 0.16811466597413832, 0.49049742031931487, 0.1219072331832211, 0.11839848206610845, 0.06537794162428118, 0.15434456852252249, 0.10606365795846819, 0.14701032472556888, 0.09620242388808699, 0.13585480316142542, 0.18398882136697223, 0.11159572287579411, 0.10100049863706673, 0.0918285742022813, 0.1320933822099706, 0.3201607680432149, 0.09520168420193499, 0.13233173900215828, 0.0737415781628207, 0.1333806387328686, 0.16205802055509552, 0.2553820988551864, 0.20750067832926708, 0.06735449752918106, 0.09506246813110812, 0.12140452504092296, 0.32010158801632943, 0.364810114517389, 0.494743475332184, 0.10687084347735001, 0.17392232403604418, 0.09204092357119227, 0.12193812763817403, 0.1691897634687336, 0.09555026582993482, 0.10103703466484079, 0.16011888648291225, 0.06073205690058943, 0.10829999510540005, 0.4889656235779832, 0.3487355306541218, 0.2000407512094863, 0.1918473409336247, 0.15777152129369032, 0.2365289283225948, 0.4414209279491147, 0.2515039248521601, 0.11379281645047916, 0.24503365860826407, 0.17186422789327999, 0.09721775183444552, 0.14701032472556888, 0.16312006872739399, 0.23824803930001137, 0.33035773121504014, 0.06525637583806462, 0.33626535001289815, 0.0835455412567554, 0.24218684810571256, 0.5239222838932264, 0.32198293728054794, 0.12222428752379658, 0.4020699314406695, 0.33666384509952024, 0.1231059943234619, 0.17675363225265495, 0.21394625138330617, 0.26095019831573063, 0.17633283440848385, 0.27000935775593077, 0.10343717013577992, 0.18665284885016853, 0.1791804325711444, 0.10695988290541324, 0.1296347641433356, 0.20673983669401366, 0.2774289477730428, 0.11209530687655878, 0.2512955311009077, 0.08016182864049773, 0.30467515153011354, 0.2134631630100418, 0.35871768491143075, 0.18690457483153633, 0.19582558809486691, 0.36865222435754824, 0.12495707866355359, 0.4635942964463554, 0.2814425140051181, 0.07682848742026907, 0.10471866673005345, 0.24234519083257147, 0.36634194688836536, 0.30212303468058205, 0.10885591623488969, 0.27771376676447157, 0.494743475332184, 0.37002301968364465, 0.06794397499055388, 0.06496164224629872, 0.3371197264342377, 0.2020272717571585, 0.08227087927496594, 0.08863565577123914, 0.0986382927531735, 0.10829999510540005, 0.11554090523293832, 0.17789764779935657, 0.10614074260841233, 0.363520875485873, 0.10156445765440435, 0.21551571727330263, 0.1556428093021297, 0.11886365741688314, 0.06789576887584019, 0.3977048478837354, 0.3152786212903595, 0.13870578408936785, 0.17838703714140702, 0.3329198183426933, 0.10819314588166025, 0.3567144568340004, 0.44054766905517073, 0.3700224536115688, 0.238433395463632, 0.2551939411739995, 0.20564497145885352, 0.4040458173182681, 0.08436912150414674, 0.08091777863078639, 0.10543069362774342, 0.1885131497400857, 0.1918678472561419, 0.2267578445460368, 0.10658675590473454, 0.3827258590667838, 0.30089197483876867, 0.10984753398229478, 0.2620447441069118, 0.1382317944184413, 0.07593599971987203, 0.17220053944503438, 0.10878412400322036, 0.28962088998084196, 0.23310487473595895, 0.4269540368451598, 0.3767032142890437, 0.24552976562383344, 0.20768115941549029, 0.3592937334767166, 0.34172661468556187, 0.23949688279741496, 0.07107164778244092, 0.36120066758490404, 0.12252149486202261, 0.20157502333376928, 0.4398581691804453, 0.0894530684065513, 0.12426401130378062, 0.13102808674633015, 0.11493798371866008, 0.20680517326863038, 0.180068145454195, 0.4309932514792643, 0.1268758197677532, 0.09861007394114461, 0.10510940698468921, 0.19299272744964868, 0.12356477357755219, 0.3132363382943539, 0.22755607933195118, 0.2520844509340024, 0.12855024926289998, 0.2860650181149105, 0.20064824180942537, 0.10304051109875706, 0.08772627565263039, 0.09048354994463569, 0.2175263471243101, 0.09658466405097295, 0.10870639257360683, 0.09196077377485899, 0.09016896257201117, 0.0949778432418597, 0.12015969998239014, 0.1937595151016561, 0.17251488766606882, 0.13725468877241528, 0.22674329140020721, 0.16635414824934694, 0.2612605933800702, 0.1725871819335112, 0.1723068107181743, 0.17399250719009146, 0.18482172544522482, 0.2721821170560103, 0.10794386289879179, 0.23114225857815573, 0.35995114060211064, 0.28614706203194606, 0.4011961361168609, 0.11493798371866008, 0.1703629976978705, 0.13293204900530375, 0.0983463982434064, 0.5700375387374911, 0.20115692865224707, 0.11037383673871377, 0.35906919305253904, 0.13431041270459812, 0.1838160642228073, 0.4309932514792643, 0.4125449009724027, 0.3422860014565639, 0.11851755926242727, 0.11012532390223374, 0.2284857211885037, 0.13367519103015166, 0.09806498404277937, 0.38266612507704456, 0.355626889840142, 0.06548145928334682, 0.2417432344751545, 0.11482779353510594, 0.28860705729821345, 0.2566052735618574, 0.25406016485727323, 0.19960508022853135, 0.10361410980774186, 0.13711914660942418, 0.12218669912349138, 0.39600315976906386, 0.4840468968667951, 0.12591355017344782, 0.3502142450218003, 0.11912271638714704, 0.30427652831281093, 0.2142233110285095, 0.22009604606802727, 0.112003315191603, 0.10116897946873127, 0.09658466405097295, 0.18971677822353625, 0.15981290786935662, 0.22262529425863703, 0.3266114210492053, 0.19825654971013032, 0.10100049863706673, 0.11394942095589063, 0.09555026582993482, 0.41746235228070866, 0.238621305477883, 0.07306425193850365, 0.4128071670074034, 0.34996662208337415, 0.09658466405097295, 0.4247094895577783, 0.3334539966452445, 0.18109521228337147, 0.07872448067500537, 0.2879973441792735, 0.18326062977890561, 0.11026657333399939, 0.20140501602718885, 0.1669008685593981, 0.18166383750231968, 0.34092561166254876, 0.10671260555854456, 0.1367770337295564, 0.0768298212957159, 0.06550905699247413, 0.18578219858501743, 0.4414394285359859, 0.15353384644049559, 0.3914364117276333, 0.18230256837893208, 0.19335453604259628, 0.09156412288912867, 0.13637293625358782, 0.14621827018723368, 0.3700224536115688, 0.05835371310636764, 0.34291957810156765, 0.13083605742848878, 0.1710419357100041, 0.10696347770737995, 0.09142556439664003, 0.40324137463004195, 0.07078795089556612, 0.0912795489184565, 0.1951964623944138, 0.21410944936605586, 0.1120155294061944, 0.09231431646309221, 0.34536546928672335, 0.12032823077447735, 0.19491544568877067, 0.15129244172526704, 0.14558196875475002, 0.2217976930342692, 0.3675149884995662, 0.2096595953298953, 0.1270972212484679, 0.12664696952473503, 0.2065165724415169, 0.11764804644509161, 0.14247383968932192, 0.12112611744591344, 0.10907707152022668, 0.12487195312698791, 0.10049722439648019, 0.06902181303081124, 0.12218669912349138, 0.06396662556574577, 0.22784886188079828, 0.19656723837377055, 0.41091687654438064, 0.15250318639240393, 0.27262485701202793, 0.2702824189570654, 0.20566985958283698, 0.23810210251414213, 0.3392071702872053, 0.13360011686058762, 0.11029548946141703, 0.42685157688274444, 0.19192359831860878, 0.205723747805579, 0.1831906937634876, 0.096498046404412, 0.1590024885247737, 0.36761538469922, 0.06851059341756809, 0.13149631868842337, 0.06525637583806462, 0.0949778432418597, 0.5700375387374911, 0.07290920769280826, 0.5239222838932264, 0.21485824311387713, 0.1799338835973464, 0.13939906396309557, 0.13249867065863732, 0.0927757714788998, 0.18727114718254045, 0.14378548754613568, 0.30144399334661487, 0.16202280010952355, 0.09865975599054193, 0.08945027580291413, 0.30809229111323483, 0.12851328940272813, 0.1445734546599913, 0.17660450882917123, 0.1359827954836391, 0.4812848809011564, 0.06921331741874935, 0.19883010396240747, 0.18804611017138645, 0.07546923465126801, 0.37652567365307454, 0.2440050740226675, 0.3703433356382058, 0.3216082654947167, 0.16420976021023231, 0.07748330338172049, 0.19118383804945852, 0.144737145347437, 0.303179349738207, 0.43464323699455903, 0.17868068958023134, 0.19819092503564922, 0.37340209492388926, 0.4414394285359859, 0.1709993927300082, 0.2760436127665002, 0.2945371553365582, 0.23029480285497794, 0.14317061355072347, 0.3255699249246489, 0.09745118434404024, 0.20757227854001264, 0.3798687348114977, 0.07697724632697615, 0.11483389710459133, 0.4577421826022559, 0.3191605972582106, 0.2698707099983391, 0.11489507943162323, 0.15172612447889175, 0.16488487196995624, 0.36945450913544664, 0.09919244655522527, 0.17348921395519637, 0.10299195235043143, 0.1311227273665902, 0.1472022372200453, 0.2946199607068066, 0.1850908099875736, 0.15570410907289967, 0.20186370465505693, 0.11016878024359948, 0.20715642117170024, 0.31757379976192474, 0.19394974257922304, 0.12888314738300197, 0.2622143690754292, 0.07748330338172049, 0.2519568981800296, 0.21297415658867028, 0.30467515153011354, 0.41091687654438064, 0.31726929878074284, 0.3308139467510756, 0.06921331741874935, 0.189785842280653, 0.21953726896005, 0.26428334299224454, 0.1370764092801042, 0.22811032814162746, 0.09272580646633159, 0.3312704618655979, 0.10005097133684511, 0.28035265135095655, 0.1505502908148923, 0.11029548946141703, 0.1619953643456404, 0.2744934883686342, 0.08605032359898919, 0.10200209445298664, 0.20285853402576368, 0.20689758075092832, 0.09632975519135897, 0.17398897009595385, 0.3191605972582106, 0.45162272752971533, 0.26004687170842866, 0.08761192213854468, 0.11783617757119184, 0.2106281688934806, 0.3094501821324293, 0.494743475332184, 0.19444544121285232, 0.3781128150019116, 0.21630848122878765, 0.103354949747016, 0.1296699029270317, 0.2860627730744927, 0.08492707054606667, 0.43696085594441025, 0.27004575011664667, 0.1764296721589217, 0.4735184392518922, 0.39956777116274794, 0.26843576733973284, 0.14119419574283226, 0.09323450484166883, 0.25816089162248307, 0.11235912985463249, 0.15160859770026294, 0.5392068968415761, 0.24754404303192912, 0.22168197815468543, 0.08108738206015977, 0.07633073596562215, 0.22263340417047145, 0.28531332088228745, 0.27952817378580896, 0.07205217503692815, 0.3166415634065851, 0.23993910118507283, 0.34886359400534944, 0.22814400376254715, 0.18692138464347202, 0.10248424017048799, 0.3127087176580501, 0.3613245329051272, 0.16316012791637674, 0.2558303410941634, 0.10458110810748274, 0.186378200228375, 0.2750402583582757, 0.07123233762839568, 0.20753054535708987, 0.2211568560399984, 0.07766723111548778, 0.34969514258385775, 0.12293624440965414, 0.3229988982689671, 0.4635942964463554, 0.18597079418520965, 0.24754404303192912, 0.06666526567299244, 0.3028832916617976, 0.23810599924441758, 0.1011500289100217, 0.20295116913268035, 0.4166161908424612, 0.10153764470553232, 0.144500264782976, 0.33846506099686524, 0.19183627151365054, 0.18649306644384153, 0.22272354341914846, 0.5239222838932264, 0.09865975599054193, 0.26068835019225967, 0.13742122413664218, 0.4414394285359859, 0.10314226914848153, 0.18503036900637235, 0.20995345441727234, 0.22581952693394453, 0.3586767342765921, 0.11029548946141703, 0.26003675330425097, 0.18587887346849047, 0.19758295401463813, 0.16692102955260738, 0.29036766018937504, 0.47081232544410684, 0.3371197264342377, 0.1618811428053865, 0.16406779080170536, 0.27880223923346226, 0.3082113772838753, 0.3502142450218003, 0.10471866673005345, 0.1746398297391989, 0.06868100377137411, 0.0925779575415446, 0.11075218653401395, 0.3653940826176271, 0.11889664869177691, 0.35377340978110916, 0.2196775696637073, 0.32876938094250024, 0.2716271941712482, 0.09555026582993482, 0.222412529492766, 0.16484576849565677, 0.4925819650022267, 0.29856817935508073, 0.20663132062206688, 0.3523342302363196, 0.17430596560251688, 0.141770604512964, 0.12560869521467885, 0.15202809745205761, 0.2430213865207254, 0.1281246489509204, 0.48607652614787744, 0.3722137108386088, 0.20067294246962436, 0.15868949843403027, 0.18461980509728715, 0.44262239732349895, 0.14758556243885754, 0.10110881371858993, 0.07144832356194228, 0.23312999042054408, 0.07687544058359072, 0.317330290579661, 0.1816056750323169, 0.3325066605152254, 0.2230268610558184, 0.3137865493259674, 0.1297561099889295, 0.10659765325985264, 0.1050088661982042, 0.16455680746768617, 0.16914581251220215, 0.2697017760591665, 0.2096595953298953, 0.34825176026039556, 0.13008131108923318, 0.4475551332435703, 0.38572618940077297, 0.2724749985570523, 0.07509536432387864, 0.1139808053050264, 0.41930945029192057, 0.3087031991983019, 0.4398581691804453, 0.10352349794569758, 0.41089685917674507, 0.33656281761936707, 0.19552615737937182, 0.07565682540664162, 0.17962365781093778, 0.12848981170591023, 0.1153427229497059, 0.17852697562465972, 0.2519568981800296, 0.06975124857888465, 0.21864465708871458, 0.2844749648690462, 0.10864567478677913, 0.20663132062206688, 0.31753445939879593, 0.07779317042435814, 0.22263340417047145, 0.15269587878244473, 0.1908449632455573, 0.09845149083251928, 0.1269812532821342, 0.20959365700252583, 0.31023665807303713, 0.12308262759860474, 0.5700375387374911, 0.2057375721652676, 0.22838313238078062, 0.12871263650511444, 0.3133529247279301, 0.20968284362022507, 0.34412366125755567, 0.11886268250309316, 0.22566536180427066, 0.21804186836141837, 0.1694405942136591, 0.2681388620654698, 0.38835276701321825, 0.2797455564043549, 0.12710642544324138, 0.22364470039377812, 0.22814400376254715, 0.07789487647074005, 0.17035097615691425, 0.41097483505905713, 0.18614431262419898, 0.1445933727165731, 0.13478099986727396, 0.3133270185042573, 0.2896592539068674, 0.141770604512964, 0.11519268277650858, 0.14090848673721776, 0.15131004936017933, 0.169369982690704, 0.0798020262493456, 0.11127005831453013, 0.2914808564364721, 0.4840468968667951, 0.40598132932172526, 0.44822342138805293, 0.18684091185797838, 0.12449788633401282, 0.10671260555854456, 0.14457388421157846, 0.5105371844077934, 0.30361735749167906, 0.10534853386442208, 0.31148741239559724, 0.09390189881667886, 0.10000913887329914, 0.41091687654438064, 0.07351148369046064, 0.1945165393600191, 0.30539790515742626, 0.39432362457463016, 0.2569762592366905, 0.16953040259763896, 0.2129065028965606, 0.22136541464342926, 0.18647736374746446, 0.1892633358184119, 0.07268924858386658, 0.18499588680769835, 0.42282996396590317, 0.10632880460719854, 0.10077940050177515, 0.36129302302279886, 0.14619036517975648, 0.07357552865583664, 0.3156207797814182, 0.09751423326457831, 0.37559209885424755, 0.08022097669047122, 0.3955919647325944, 0.08597637346103167, 0.09009863103436117, 0.3094279269447007, 0.1924648359388302, 0.06847276646907843, 0.20047271894839794, 0.10279767424457212, 0.2125049347579527, 0.254993683578219, 0.07250507286439675, 0.1845490682009943, 0.10065696076313983, 0.2922094557118256, 0.18204415360502615, 0.13466626132700268, 0.5028446307030995, 0.3000924262725906, 0.0886287114087604, 0.18086418004774168, 0.11004841245660768, 0.07552499859375739, 0.2201924538199803, 0.13507082231533052, 0.28166816325821153, 0.10878555409463296, 0.10379489000555432, 0.2286229503897854, 0.08841543838969738, 0.3973014586269097, 0.25375538590034036, 0.2504005127318467, 0.06300138824433184, 0.11085264528979646, 0.4309932514792643, 0.07644929535031766, 0.12974860024557777, 0.08677001917963817, 0.22364470039377812, 0.15163644843035035, 0.2005724749411247, 0.09949145495009612, 0.1554936324638276, 0.06425715496474235, 0.46144880840326696, 0.2566052735618574, 0.16420976021023231, 0.15186618429600862, 0.09513178992455522, 0.12811837064603215, 0.1854610626844473, 0.08605032359898919, 0.40255023521088296, 0.2020272717571585, 0.16211358318594946, 0.3070096485954644, 0.19273718722262448, 0.24144886513632116, 0.11043095832817973, 0.2213949791056483, 0.35377340978110916, 0.12591355017344782, 0.19050266615297187, 0.35811270156932223, 0.1296268840907146, 0.29663720354860346, 0.2124354187533329, 0.15868949843403027, 0.3567144568340004, 0.11105748514623145, 0.13079881511938696, 0.06189363933845873, 0.08680407206076382, 0.22455827788373317, 0.34969514258385775, 0.2052577147226353, 0.09361619228964439, 0.18767498452250805, 0.11012178047707862, 0.09875592154440772, 0.14408084544856317, 0.18100645354791206, 0.14290769958609198, 0.3872802238433095, 0.0725145803242768, 0.1480348724118492, 0.14351489425167616, 0.09734344529736984, 0.20723681385853812, 0.10648907578198742, 0.18577874275453174, 0.08933600005989964, 0.15078387999086046, 0.1198899764507311, 0.1493739074118762, 0.1521739165265494, 0.32141454323928265, 0.3001278422934497, 0.22363930619911818, 0.23140234067244933, 0.31635453061616015, 0.09236339060273722, 0.12216710896637602, 0.2599094280795486, 0.12140827038574166, 0.3590062623466837, 0.22454849200107052, 0.3756366443666313, 0.16202280010952355, 0.1048046743059152, 0.14701032472556888, 0.21657247951822484, 0.35859182697902225, 0.34867233869736425, 0.4414394285359859, 0.2800734527170256, 0.24528115913001425, 0.13089694953067352, 0.11492762242457333, 0.5231028569024795, 0.2377352106854838, 0.17186422789327999, 0.28627889282083385, 0.18215004277162522, 0.40982063241150946, 0.3371197264342377, 0.23586043332125156, 0.24080266484294857, 0.18866910408917062, 0.10170268262022598, 0.19564583566175642, 0.12332040504232958, 0.2624144403454566, 0.09023149762162687, 0.41758247900485534, 0.15557792600318718, 0.12629027115954958, 0.17203684447707138, 0.4269540368451598, 0.18572436643070572, 0.22824189403489742, 0.18793906031646365, 0.181973728820426, 0.21452816247483095, 0.1266737434093395, 0.11909250408221796, 0.1565647571975262, 0.16206498417834755, 0.12393876748570262, 0.4716615380503692, 0.31231510449360367, 0.369523792077564, 0.12693316112365147, 0.13389805914837552, 0.19252190993246715, 0.09599728649369771, 0.1195471794198138, 0.08176946501775847, 0.12133873785349186, 0.0944101052039764, 0.1827429032672896, 0.24585509296308644, 0.33076827836683337, 0.17160362402861712, 0.3298034925735508, 0.1544302974078687, 0.41125295611304896, 0.1844464316567191, 0.09976540213318784, 0.13008131108923318, 0.111411901424128, 0.15670637208609892, 0.09700550142033375, 0.2764411924329068, 0.17646132076411725, 0.18234166277370878, 0.1382317944184413, 0.16934898663158246, 0.34112979134588073, 0.34088011161701076, 0.23616672053997614, 0.16934747662972638, 0.10248424017048799, 0.3085141867241712, 0.10471866673005345, 0.0836230905793385, 0.1939094096032682, 0.22896131477386633, 0.16860143620160678, 0.15434790986257932, 0.494743475332184, 0.24445924302907523, 0.19035737447526477, 0.1779944593595325, 0.1663097962716043, 0.27827619173704393, 0.31574524927125663, 0.07144832356194228, 0.24642241593129113, 0.3091667032668833, 0.13833887826770036, 0.31259443065942527, 0.28134380895597894, 0.2278642614922481, 0.16580681219984492, 0.3777272086076232, 0.2814425140051181, 0.30217897017011275, 0.10203050671214654, 0.2835626600045209, 0.4112107400340612, 0.2770550456921025, 0.2401593365849393, 0.3889506312968206, 0.1118909236118764, 0.31732528641153823, 0.09597222382157052, 0.13671644283439005, 0.27594237843105207, 0.07918306777495425, 0.17251488766606882, 0.09620242388808699, 0.10471866673005345, 0.2372090205713177, 0.09038323657331392, 0.25375538590034036, 0.4269540368451598, 0.36157202589621573, 0.3212801075906963, 0.17196255051289597, 0.23992602032959107, 0.14887524151510992, 0.3629293327142431, 0.09996158904964439, 0.2412878046491845, 0.23863149578432682, 0.21411192716711472, 0.1339084564055725, 0.2582236446553166, 0.20674630465764884, 0.15363310014045203, 0.4859960578476146, 0.40653601608971046, 0.18056833435579142, 0.4097841582538229, 0.09954284190067497, 0.07851601346000023, 0.26383288579682374, 0.14013016048024113, 0.1298571186781257, 0.2075478596754655, 0.10458110810748274, 0.1160890508882538, 0.2209528046086439, 0.2142233110285095, 0.2106281688934806, 0.19245009415766987, 0.2573646941066697, 0.1443688914778072, 0.39220002452939157, 0.19328880231364992, 0.1382317944184413, 0.2615267971618581, 0.13800286232367925, 0.3130440173075558, 0.1511756967794084, 0.24540718787030089, 0.20088929787981946, 0.3272231755729094, 0.28777595737293793, 0.4859960578476146, 0.11354822880371157, 0.19519394766091613, 0.1044789699174303, 0.11197748499743501, 0.3539968315239569, 0.2230268610558184, 0.23967678621846966, 0.2395211193407447, 0.1640905592735886, 0.19853873274548411, 0.20442468006715667, 0.11466477509954114, 0.12946775653875855, 0.21283298302110243, 0.20705286067235293, 0.24004048122131894, 0.12470174128232579, 0.10705816048559498, 0.10533058401747268, 0.1779944593595325, 0.25097649810926637, 0.22784886188079828, 0.12376924375805025, 0.2543081193682375, 0.16466432365338585, 0.14498218392765821, 0.2157070159328159, 0.2453764748899259, 0.1512968355255603, 0.2670319589291883, 0.2552328934802543, 0.2549435872886038, 0.21103304319987196, 0.11884954014136753, 0.18690117586102295, 0.06975124857888465, 0.2697017760591665, 0.3542731363086482, 0.264904754762162, 0.20305824717108295, 0.2033890394984356, 0.16779737370779035, 0.0854460456031219, 0.41758247900485534, 0.09620242388808699, 0.33035773121504014, 0.12564204786758504, 0.17248359522616483, 0.41108376823775283, 0.30467515153011354, 0.0938554341214364, 0.16493853740826359, 0.18649306644384153, 0.23344624318401253, 0.23104083601724387, 0.2777362165511124, 0.1770154800874603, 0.1829411370194472, 0.1866663915963569, 0.5549314685543599, 0.10652125406677562, 0.41930945029192057, 0.159947900653233, 0.17605438636334458, 0.33409518715447556, 0.49275780074430847, 0.1890975685905633, 0.0877423014216505, 0.1029141496328236, 0.221164576248877, 0.1482567339853217, 0.06496164224629872, 0.3955919647325944, 0.20892963006589008, 0.06868100377137411, 0.1029141496328236, 0.14143710925785474, 0.06858713239774547, 0.2992187410511475, 0.24219291656596517, 0.1327703027441055, 0.14651545124441648, 0.23533930248624516, 0.42966498527000585, 0.11062933679588001, 0.3055217055870697, 0.20691671693306596, 0.39792306773582964, 0.12033920881099024, 0.31131872862273624, 0.11500643754318868, 0.09965652629458856, 0.20259179248623502, 0.31250262971958465, 0.31593629626406367, 0.3786380783022389, 0.12259922222064883, 0.11029548946141703, 0.12392677364950531, 0.11830384179271417, 0.14928832909342873, 0.11262843000320391, 0.1877759015681215, 0.1759129107410892, 0.2704136659854367, 0.18714215150599042, 0.29541018746742437, 0.2054043040271849, 0.13315040311641504, 0.33948836120756926, 0.3119519185819104, 0.10100049863706673, 0.1382317944184413, 0.11470739647283704, 0.22176843650008982, 0.2860650181149105, 0.5392068968415761, 0.4523756734326721, 0.13547298899384777, 0.46322352322421484, 0.2331278697652713, 0.06073205690058943, 0.494743475332184, 0.11006823009721459, 0.20972305039386793, 0.19454313902573878, 0.33277107037026404, 0.2002035791867273, 0.07393335515652631, 0.512446074388722, 0.1301102565911371, 0.15517259291215135, 0.15210746248360837, 0.29777762218446485, 0.10086262294150643, 0.5231028569024795, 0.2178721150155189, 0.1361624730739214, 0.14529454857649268, 0.15394646023134737, 0.3729213551276749, 0.19284871046267316, 0.08236283045940773, 0.17266771768157116, 0.16659303694521485, 0.11078743043992645, 0.28030906342719536, 0.24891128887295583, 0.2978823502891782, 0.06768258211752728, 0.10346209312899263, 0.30770762699347626, 0.3241786873591213, 0.24024773628056584, 0.18685866583295166, 0.164118949245081, 0.15168339019706084, 0.1292867106802982, 0.18714274979705156, 0.25097649810926637, 0.3979886323822132, 0.174254636835279, 0.1626215436447373, 0.0976433139985222, 0.09702212061767183, 0.2180783202114097, 0.2949102020823361, 0.1462903310729234, 0.1715997046876836, 0.1311227273665902, 0.06940183939736097, 0.2907414625054143, 0.2683980060531201, 0.1749767078946281, 0.45691741295558763, 0.31571270393299755, 0.2361881968704252, 0.08501493806304458, 0.12395995447483371, 0.17532608022790908, 0.3676941688167188, 0.22542315996388176, 0.10868093041218328, 0.4577421826022559, 0.20064824180942537, 0.47081232544410684, 0.49781504657641, 0.5231028569024795, 0.11124800191935968, 0.08861696588993523, 0.1958779119540065, 0.1676750297957219, 0.11195737026560676, 0.4732068381507385, 0.22896323270492394, 0.09957418917287945, 0.28484373843854643, 0.41091687654438064, 0.10512634809145482, 0.14096267266396204, 0.17679743664583644, 0.31592474146396315, 0.2657341210901119, 0.49275780074430847, 0.2561718465721397, 0.14808605497699065, 0.18487150343806638, 0.15353834905563682, 0.0743536491998291, 0.15914362548201255, 0.19393134054718875, 0.14869709045310261, 0.33626535001289815, 0.1326945430110623, 0.20179184077597367, 0.18230256837893208, 0.14413570505636472, 0.13257699435822376, 0.3466440097237671, 0.1056676618930356, 0.08367381984523385, 0.21161512617779016, 0.08180212742048346, 0.39011187953370624, 0.18159591114639637, 0.06300138824433184, 0.4229092529849751, 0.21639433508430198, 0.18888951056058206, 0.3132363382943539, 0.1389475090209101, 0.300980314195066, 0.10339901722486947, 0.32973728118297835, 0.12591355017344782, 0.45559656098105994, 0.10339901722486947, 0.09502626268028247, 0.3288884691634727, 0.08806113568393577, 0.2812652753912411, 0.17895231164508457, 0.11466477509954114, 0.3375364727961196, 0.4736413009951711, 0.18945378913413158, 0.40253475520578963, 0.19173232423165254, 0.2031437945452751, 0.14341620229059066, 0.39600315976906386, 0.49465515843344404, 0.38445890506671476, 0.08567294341123424, 0.17024728651414672, 0.31449661634635706, 0.23614608928227188, 0.1389077565973888, 0.14868528287178928, 0.2142233110285095, 0.22224833194291815, 0.3501071683226308, 0.17191677612131068, 0.20295116913268035, 0.12835456881701462, 0.43464323699455903, 0.07997241023838304, 0.1682099624532379, 0.3539390631818375, 0.1097146913798306, 0.15910523748358546, 0.3417085191796583, 0.1359827954836391, 0.3944565063891678, 0.3105436733355829, 0.20088929787981946, 0.498360595429511, 0.2337353182337429, 0.10515543358350556, 0.14758556243885754, 0.16623192185467706, 0.15409259952237284, 0.23736323892103078, 0.13728719553704724, 0.3388144515034879, 0.3808032925987245, 0.18863398331529202, 0.07918306777495425, 0.1958947126266085, 0.25375538590034036, 0.0697854825210512, 0.359321509735215, 0.1815523210052369, 0.1311227273665902, 0.15708267118885236, 0.20852091949193313, 0.398544889087984, 0.12472893295478975, 0.08781341134121534, 0.21286930482294264, 0.201036358575945, 0.12135211756212275, 0.17210621940591478, 0.1077742745676137, 0.4220558596997626, 0.12419543014328199, 0.30101298335275556, 0.22064683660947995, 0.07439921177606447, 0.35906919305253904, 0.19656723837377055, 0.16746706171759876, 0.4419557712823444, 0.10248424017048799, 0.1339684907749062, 0.13472274076811575, 0.2565876883272802, 0.16285770753773954, 0.24549904229367034, 0.20238327355527524, 0.21802820337152387, 0.3166465636614844, 0.17755012639640438, 0.1638696046829129, 0.11059597423191646, 0.21411192716711472, 0.3371197264342377, 0.25631096109691304, 0.3586500494415827, 0.35906919305253904, 0.2879973441792735, 0.5183290502675701, 0.29219745642254275, 0.15127566564579098, 0.10291748795826247, 0.2878713157584114, 0.1963340993072823, 0.10672663817655312, 0.08689868540738399, 0.13408369936997996, 0.25849081135001056, 0.12534959967539516, 0.09155925036968379, 0.1842006272853377, 0.4112107400340612, 0.24902390455448656, 0.20245419951073948, 0.35906919305253904, 0.13802841250952003, 0.09694458355585671, 0.3700224536115688, 0.19133220163598638, 0.205723747805579, 0.15252405093407614, 0.1370764092801042, 0.1817622454709467, 0.08286005777310101, 0.2115673692427089, 0.08123516609553981, 0.15578254346294812, 0.33970558015033586, 0.12350016541811969, 0.2528884822818468, 0.18117628845178316, 0.18063506214153718, 0.1911630767234789, 0.21155093793334467, 0.1564852472191488, 0.2343753125726156, 0.30855859267823765, 0.21497160374837562, 0.19268934657847853, 0.331025189707348, 0.1648089872951978, 0.0850535679132409, 0.1250313753158778, 0.23991352211202122, 0.36266221909392404, 0.12890604995891913, 0.07520437176025813, 0.15274835978389295, 0.1581649785799518, 0.09010052818607585, 0.0937434903700694, 0.10230405758579199, 0.11498348492822369, 0.17960333631634834, 0.0750838266804585, 0.1188876944237174, 0.43876323653093485, 0.17704703190444257, 0.09774775643127483, 0.0834046408319012, 0.2067819209704676, 0.17148903276476804, 0.16284726115688888, 0.30528195541520714, 0.16281000899755593, 0.21918489444108052, 0.3515884201972715, 0.11706864679817207, 0.4655224446361799, 0.17458129824935215, 0.07932067912757597, 0.16148437900270352, 0.08061821306619982, 0.135197827334975, 0.11421414592377457, 0.2123998079294495, 0.09341206361564042, 0.1969550420854483, 0.16992425755899054, 0.09890282105313984, 0.3405580685055325, 0.3160821952426213, 0.08885050336873679, 0.33046871954865487, 0.10091275074262897, 0.14012870626833562, 0.2430218317657013, 0.5417741479023678, 0.2405955072519033, 0.19830310747241683, 0.0884876211237743, 0.22501832985700024, 0.120596901575263, 0.14592617223328014, 0.14951304323900969, 0.23929861047562606, 0.1974963682681579, 0.14894186672790252, 0.08548717942043127, 0.35861765893170094, 0.144401777889527, 0.28021403677281015, 0.23074909931275714, 0.3020282385570361, 0.09710130618224976, 0.2697452012097397, 0.22053755898887234, 0.16845143726170067, 0.1111337111840839, 0.3698962128951159, 0.14425525206145, 0.5325210523349728, 0.32916598789375034, 0.10367952038339448, 0.08452117261280165, 0.4282273958583296, 0.42678259704559707, 0.23850548650527206, 0.12741223348300826, 0.114973485384928, 0.11720968285770655, 0.26072184524346415, 0.09970697442692213, 0.10105876848404641, 0.08274648352464198, 0.18198093911316637, 0.4852507857112873, 0.26984164590439436, 0.3876269626292934, 0.12065218442460135, 0.30670011300198147, 0.17357941425480075, 0.16636011863516637, 0.2049068240418939, 0.4880128028402413, 0.17462327844460573, 0.3470370107917172, 0.2629401289627353, 0.16183134552369083, 0.3651668511714629, 0.11034547716465187, 0.12344947529558928, 0.10736161899577276, 0.400177437585684, 0.24577572425416921, 0.11551780866878363, 0.5042799061190729, 0.11541847428582837, 0.18666008898175288, 0.28438072613213405, 0.2688672074540786, 0.15975594059047724, 0.22302087731548015, 0.34461722257904104, 0.5314418158689026, 0.23171490292961583, 0.24952580345049957, 0.4282273958583296, 0.32145963035144987, 0.22840276631691903, 0.31399591582378417, 0.13628451658035198, 0.08350140814631886, 0.27062590176698864, 0.49588461238842685, 0.17922676026714635, 0.3633838894286927, 0.28768135292869945, 0.1745030485341111, 0.41159981655187144, 0.37611285834536, 0.08775930858972653, 0.16518758869784153, 0.4201508737627537, 0.1893939868892412, 0.14016525664120894, 0.1465089732223807, 0.09334295821245511, 0.10982795376037738, 0.07121960387089549, 0.3978144687938014, 0.2686870077132346, 0.18605064396868942, 0.13189573261552334, 0.26432981110236276, 0.19221280081980147, 0.14843820165096078, 0.1472997064983727, 0.2926615096273718, 0.12187417140862987, 0.13424854785829435, 0.23002306670495368, 0.4660429922659723, 0.1531601021584383, 0.4720297310623336, 0.3371841051764852, 0.13202477029496829, 0.33008696279811434, 0.19695935727826308, 0.0806531134106335, 0.2568117229127316, 0.10349932460720507, 0.15016219946816084, 0.5083065896569623, 0.0657626342865703, 0.16794787402890418, 0.23952741353409956, 0.1157820185478168, 0.17172319027398972, 0.32391876753768384, 0.12494878340969678, 0.2099660058076144, 0.19188453064269215, 0.24243885416449512, 0.07136532512410022, 0.13939311252132952, 0.1262335847741518, 0.2678265453119845, 0.10543649962093658, 0.18663351783561374, 0.30173598355824294, 0.39473513162799234, 0.10651338748414982, 0.3732708550726114, 0.10374452637171101, 0.08228698998276827, 0.20957768328657458, 0.26563784470706187, 0.14759189262223155, 0.12693028861719324, 0.07739123455338066, 0.5042799061190729, 0.39819853676892525, 0.0873889189259648, 0.4177545311569722, 0.17110155490407628, 0.24827076423648947, 0.26637688299374274, 0.30327965556552416, 0.1670746178305767, 0.5697019195470939, 0.3584154017838152, 0.16769127599628153, 0.12943953135447964, 0.1109832447740384, 0.37902771421483644, 0.15538795778022704, 0.1309024029246209, 0.1647021153108166, 0.15816587956211414, 0.5352136543736017, 0.1016817740843224, 0.3006135417004323, 0.10197510508200773, 0.15299329649748877, 0.12774107100369417, 0.19491855312018383, 0.12267274687402097, 0.11552656437374446, 0.17280026798215936, 0.5697019195470939, 0.31900643758788627, 0.35128677303735417, 0.12823274309063312, 0.1224713619520044, 0.12979346422563434, 0.2020768428013547, 0.14235055109112577, 0.13513151723464042, 0.09725633572881136, 0.1744133423449671, 0.12776747070088296, 0.14838345622789684, 0.44315361209633386, 0.1499320324788212, 0.07023765746851449, 0.12025392240755328, 0.5325210523349728, 0.1442335274061993, 0.10483658073467249, 0.38176685102647573, 0.14127443918211846, 0.13305058675552528, 0.295247026626751, 0.1370860595898358, 0.23225562246591214, 0.08345911914438937, 0.26923683656012537, 0.15684238245805346, 0.1108599272055209, 0.17935403558456833, 0.1463002877615461, 0.07281135513749726, 0.09415504538514637, 0.40569402586439474, 0.16681824815362226, 0.12538800935040828, 0.09671059086702351, 0.10406508501680506, 0.17190051254647817, 0.10375332192509658, 0.3777726918108545, 0.42248418732878984, 0.08000415168452567, 0.2964151111834595, 0.1601729884786435, 0.5207292626501334, 0.14850751939595733, 0.29537059057738413, 0.16316288311390342, 0.21479420369712623, 0.14415787563367258, 0.28613832799421873, 0.07575391148065219, 0.37231168483921584, 0.41057337710869646, 0.3924771020080405, 0.14304270969191216, 0.17017270176590168, 0.07188554528730227, 0.4188831020095295, 0.2174738148346944, 0.2589302675057513, 0.2568776524929812, 0.31918343162790064, 0.11790820093876557, 0.23952741353409956, 0.20527862853146214, 0.09089733641612087, 0.24709228071265316, 0.08442017705859463, 0.13207758803638514, 0.3342555369095639, 0.5325210523349728, 0.5296763659296089, 0.22189040648135075, 0.1436785666444069, 0.31743307327139375, 0.29284086842505397, 0.30968688980872455, 0.1317444420853813, 0.29249407734091615, 0.39429212490362886, 0.16982474368026415, 0.24048250733439333, 0.10173341244891096, 0.09691258079735564, 0.08062367465046782, 0.19889467010422768, 0.25551976306155627, 0.1847273387827273, 0.1091919432598665, 0.13777899122678766, 0.27742115166687864, 0.4625567197180588, 0.16048075131920997, 0.13189182343838718, 0.08672741878453911, 0.33434769438371725, 0.1294660672301743, 0.11076786057076562, 0.2118786906540096, 0.432640983468232, 0.34723245036793104, 0.1514513493333985, 0.28331839378423884, 0.08423791238026412, 0.12162580109892877, 0.09461180138156094, 0.10968739655325133, 0.1425764678043611, 0.1468180911166015, 0.09718287828407889, 0.08350650024575064, 0.10538098516055218, 0.198157163545536, 0.1328311975407118, 0.12096420365190493, 0.11609535043697158, 0.1833001416688747, 0.3569401907917122, 0.28054366041724904, 0.23164424137844167, 0.14064668061561594, 0.24611277325284403, 0.27837790200808465, 0.10982467555179123, 0.1501977792058153, 0.27524164565756676, 0.5551690920576366, 0.14893136575371033, 0.13022879064383608, 0.17375410652690815, 0.4011299948924481, 0.17652428676940665, 0.1382200141696253, 0.268972382349486, 0.3589745090621733, 0.3578845230604242, 0.13565027817345443, 0.21823292584796558, 0.13631522580596306, 0.3133541361307548, 0.5483662592968324, 0.406255352600301, 0.1596486770059975, 0.1337506201437352, 0.16188297122338463, 0.11422540737305982, 0.16429206560564744, 0.23527724892964727, 0.12658988577787067, 0.1981813454377799, 0.1321917321145357, 0.12544379349119522, 0.49782772846378376, 0.11292303927985452, 0.1545512821322232, 0.37231168483921584, 0.11140049217840547, 0.23333049415744536, 0.11711732653719081, 0.0938349084558974, 0.29076434031184256, 0.1444644160619635, 0.37081141351191704, 0.09995830442916359, 0.1003114769720561, 0.19901408765712997, 0.13272276786658993, 0.2782601739116752, 0.1668351689714707, 0.1512271967715023, 0.4990975424159089, 0.26580928387009456, 0.11542984260596933, 0.11805973879769838, 0.2695857093523737, 0.1370268034232954, 0.35270731811832085, 0.10676677377320086, 0.1797235519729443, 0.2718634861834933, 0.09176154113918962, 0.1412991117966229, 0.12597494539391868, 0.12561779078906454, 0.20295411335460906, 0.43876323653093485, 0.14259837596920769, 0.10310707854132077, 0.42470880229920815, 0.13790536674439213, 0.10722826043756382, 0.27014750777441254, 0.3253249098169234, 0.3573439114536734, 0.2115757946391178, 0.14947309825640662, 0.1269360145067359, 0.40815179895522946, 0.108699080549061, 0.1463173589689724, 0.12252777071409429, 0.12317036780689528, 0.13712839283340084, 0.14139628896456755, 0.17828825475466448, 0.2563867627119652, 0.13244607610728854, 0.37231168483921584, 0.1269877644190266, 0.280489543578347, 0.23186933980983643, 0.25599624290515716, 0.27849272896493826, 0.0866671600574047, 0.22222131093041633, 0.17995901391092825, 0.3465242472342536, 0.2780491030438554, 0.19906611489531034, 0.32916598789375034, 0.13469469234318635, 0.2304790943489641, 0.07038246629639094, 0.3836923968116405, 0.08806631619497693, 0.562946372117863, 0.2685057357350423, 0.10781464449794342, 0.21986160973238258, 0.10125380683140546, 0.2972184095484082, 0.34674494270871953, 0.27463324253421834, 0.21574955551295288, 0.14244695547136801, 0.17259255096120205, 0.11639895962678862, 0.3245423817399256, 0.30855859267823765, 0.42587175959202705, 0.24761112471522176, 0.23445099882410625, 0.2882934928425656, 0.2845025981882845, 0.21576561480554823, 0.25375546122417786, 0.1502072700597538, 0.14028570681334274, 0.12871172220426727, 0.10285258226334108, 0.14584320948637286, 0.46498807632489053, 0.10941669204898286, 0.26217438031561613, 0.18418860853675184, 0.11238438344502762, 0.10152932141343878, 0.06592576428316096, 0.1406190709509271, 0.1386816931500561, 0.12067580838752509, 0.19061380357412983, 0.4381001230132309, 0.2839193538668199, 0.3715667719875744, 0.3082620673961852, 0.19369674885955526, 0.11967209942821484, 0.4996797484514209, 0.20978214402393772, 0.1240037493666277, 0.14373128823386191, 0.40121836369468666, 0.11993064215891329, 0.20599197221688084, 0.15600668777167176, 0.12611686648051934, 0.12926481882024465, 0.13829550956717226, 0.16228508388793966, 0.22875534041297244, 0.2716901881544679, 0.1089322774326049, 0.4365351460905444, 0.14340923677659798, 0.14786270881269764, 0.23582418418910178, 0.14182211375460416, 0.14726581953313622, 0.14134534541085997, 0.11863675301254983, 0.12561779078906454, 0.5639892512289002, 0.18894688827293382, 0.5352136543736017, 0.1591736556155814, 0.11677471517858987, 0.07154757210648885, 0.11535637686141861, 0.4978533195146815, 0.11570955367961017, 0.09664695985195972, 0.4539813209631047, 0.19380267921173544, 0.2510934046844359, 0.23234625201946346, 0.2603583379165946, 0.1491958064961893, 0.15252328409809446, 0.08292219825442004, 0.10808896802144516, 0.09319544398084648, 0.08934592463379179, 0.25644384383903057, 0.10806098138435337, 0.32916598789375034, 0.13055377833609863, 0.3603685422805437, 0.1678916671019849, 0.15363130629449231, 0.1631083407607446, 0.13554299630469385, 0.09919814096714398, 0.08486650799022145, 0.21574955551295288, 0.11765510990885365, 0.26704292580011607, 0.34963085351586515, 0.11356806992076621, 0.19456329601284902, 0.10389429375770723, 0.13783344324533756, 0.08560394511921694, 0.27918336552285283, 0.13794560891756227, 0.18788091921552486, 0.17307984745976787, 0.16378788190089455, 0.2041252799862362, 0.40226722785913643, 0.16757578482981933, 0.11537283750429375, 0.09237040932863172, 0.09487283461819587, 0.15531111848643872, 0.10858407336023825, 0.38402055516088096, 0.1084792035429423, 0.28504448894349876, 0.27273141146066415, 0.23906110908762107, 0.13862156997049735, 0.137049218418868, 0.126572978905132, 0.06691403405045088, 0.13591810048582567, 0.12693028861719324, 0.08696774398385478, 0.13612995583895265, 0.44375932588967876, 0.1315725554905209, 0.08010424028357777, 0.33008696279811434, 0.11946056156453924, 0.13404772485744795, 0.20169465281174578, 0.33867860092869695, 0.23601373914762783, 0.3232148745156605, 0.14043169717807463, 0.36575074803827856, 0.14113689694813933, 0.09970697442692213, 0.5294850073535377, 0.0912641427673129, 0.11290895291352131, 0.18405074756834897, 0.19528823576776408, 0.2672196601786201, 0.16917762691743699, 0.2822315760086883, 0.10866795902000297, 0.27837790200808465, 0.38249980760810287, 0.13761545724417795, 0.1332155704359769, 0.10587038549270981, 0.23004936181203417, 0.1412546213883762, 0.4987402638357322, 0.2112048305904474, 0.10442737176647422, 0.14898893420407605, 0.3080470316207507, 0.10982795376037738, 0.44315361209633386, 0.23667339703712592, 0.19214708721579127, 0.10177171856453977, 0.13244463489694022, 0.35453101838678386, 0.15568959901280827, 0.23734445813281466, 0.2225240286478637, 0.1405803437334036, 0.17046404576641544, 0.11867858464490771, 0.15902104901595207, 0.10790217179040164, 0.0911499058309035, 0.18273592363772642, 0.18862068584199174, 0.11968127379696133, 0.14643587228847474, 0.21879223122158542, 0.13222772950583012, 0.14728639877535057, 0.07594064140293234, 0.13524903013571424, 0.2154883545995557, 0.1809070187612461, 0.15210983333735006, 0.20825264830257906, 0.0900374481244669, 0.22485294311374446, 0.23825013292961153, 0.49483128451570946, 0.2552525436304709, 0.1823198906417644, 0.12244288741913077, 0.171832939012149, 0.11201322786554326, 0.4340317981245996, 0.19691514322785453, 0.14922940588990935, 0.09763269160859528, 0.5969265734514443, 0.15457515251864237, 0.11072481108627256, 0.30164945227507994, 0.26092142368573523, 0.3651668511714629, 0.14144380697744877, 0.14074930603402724, 0.5118634841337738, 0.08064928241601539, 0.14867814226595305, 0.26337080553942804, 0.5325210523349728, 0.1907210509130746, 0.489457865583673, 0.19419440275551153, 0.27837790200808465, 0.40226722785913643, 0.13900334691669564, 0.11167315481668447, 0.14802578618783946, 0.12763055158585854, 0.27341798418769947, 0.41989860056663814, 0.13656467077471907, 0.14407038959900564, 0.3651668511714629, 0.19116985187037397, 0.17210187241818914, 0.44315361209633386, 0.09220363861995068, 0.35861765893170094, 0.3740332283936643, 0.4768702973093827, 0.13561855095684489, 0.17941433810295976, 0.08375299305019082, 0.5207292626501334, 0.1634223904031792, 0.18426115826107423, 0.2096984657962882, 0.1044236687826925, 0.2554021120547197, 0.2801725620114279, 0.17264495970075142, 0.13525667568083435, 0.5046257480540519, 0.13939311252132952, 0.0912261855818909, 0.37231168483921584, 0.3510639781698999, 0.19166971794654675, 0.12742154707557055, 0.2038068265387167, 0.10310707854132077, 0.39325548038422575, 0.09559188564912854, 0.11311813284368752, 0.1461370395201755, 0.12991997527660126, 0.24753700306004953, 0.5258148083405186, 0.09785400458949457, 0.3798813874793538, 0.12486173471172879, 0.12604958839817498, 0.28054366041724904, 0.07067623478219695, 0.1773703945213495, 0.11806717249868057, 0.0718889925399953, 0.5826396206015277, 0.10343000745248872, 0.2494222569215908, 0.11449781919138721, 0.14295521969453434, 0.2275623594250024, 0.239439707611381, 0.13590444946872246, 0.07502012630191823, 0.14077689572012284, 0.23324699669947857, 0.42515534416549955, 0.197305663159123, 0.0927163174476339, 0.24784523036535788, 0.10928347106954066, 0.13880436930760703, 0.14774763070472213, 0.13968014271414356, 0.1334091655776315, 0.3465242472342536, 0.26412605054099275, 0.152061398190582, 0.1318935371521314, 0.32926456665150905, 0.1630131358088497, 0.2250096464772884, 0.12885087616715907, 0.12743526838700217, 0.1293478910027819, 0.31757386382248626, 0.2222157254268102, 0.14414798426768446, 0.26094949067192214, 0.10745270415356653, 0.33807465593562075, 0.5022955146149624, 0.1171393519381804, 0.3371841051764852, 0.12524686991416578, 0.46097508294370276, 0.11617434585099497, 0.1762420149825361, 0.07386276894523222, 0.17564629922466551, 0.09189169878863616, 0.3089641255282272, 0.10273124367138983, 0.08174574730361187, 0.16631407556875416, 0.09145024900159865, 0.3092313826752253, 0.1120155458535923, 0.16921029005147248, 0.1867239104974839, 0.31070890441385934, 0.2319521291435307, 0.18044797572629417, 0.15743638896364917, 0.2893016229265465, 0.07023765746851449, 0.12967138633804687, 0.07948876685771573, 0.16680001222132101, 0.19031800589161854, 0.32916598789375034, 0.13653457560274615, 0.14624541643884686, 0.3232148745156605, 0.13776917915718584, 0.17046404576641544, 0.16446603514696584, 0.10802029726969832, 0.14165657663403677, 0.16706236768213634, 0.1439686388972029, 0.23018665853068948, 0.25338968067457845, 0.1660944038804829, 0.13023618942257031, 0.4442235369456067, 0.16667632386293837, 0.11028577515030126, 0.13145865579894192, 0.13013679408017298, 0.170562725795638, 0.12345095926916129, 0.2500557807617185, 0.27690793793529284, 0.31695327222159414, 0.06674274123860609, 0.10895868059347853, 0.24409984020202313, 0.13064250569488617, 0.280489543578347, 0.21354831494259466, 0.15502470871152552, 0.08235747341985059, 0.08864985774496649, 0.15099724203550846, 0.19647500611161137, 0.25484245964348085, 0.11668479818000431, 0.3377217188892252, 0.22650310286497835, 0.11368882107714032, 0.21602227468156168, 0.334635941950072, 0.3395668165151632, 0.26278064458968303, 0.14247497138775092, 0.16823115570393704, 0.24231917845062145, 0.21077390070382016, 0.3109575725445406, 0.4065199881259393, 0.12479406226475251, 0.1100969167392413, 0.1655057159406423, 0.15689471516031264, 0.08244137109005709, 0.36191881397814185, 0.3284620964997683, 0.15366557147275314, 0.10890138032685523, 0.13070528444269577, 0.11745417601335965, 0.13646553887845425, 0.18016810248906395, 0.41066287108570226, 0.16344441122616557, 0.11160120236432294, 0.3105269989066974, 0.1258745016670321, 0.0936620366953558, 0.2832074256683951, 0.2635020981983283, 0.5969265734514443, 0.08926171205393847, 0.1401368994630812, 0.3459137852668773, 0.2121493482715665, 0.14253500766046828, 0.10322845290783396, 0.12545658733928083, 0.12593012196604156, 0.3949175974995663, 0.3073843753778349, 0.1584601713491313, 0.19730104343026822, 0.11759902627790896, 0.38065343119832906, 0.4001195515896249, 0.43502888522872096, 0.11960706129397498, 0.08862671012217262, 0.16895643271689897, 0.20122387913164275, 0.1410970264461204, 0.3896450448784264, 0.2672028321300658, 0.12561421142111803, 0.12361576338932183, 0.13426638753379483, 0.21354831494259466, 0.3588808002691689, 0.11116431500597479, 0.16920689861202048, 0.2966722548840165, 0.21711552710641688, 0.09741159448187735, 0.13675679644013738, 0.23062349037170904, 0.11137750853317002, 0.3715667719875744, 0.11022970912995189, 0.25300914871099073, 0.12443802990055369, 0.10629846589036965, 0.3030385601020629, 0.07211671991851422, 0.4190965709349476, 0.24250081847805002, 0.17128687491076477, 0.20411219273352083, 0.3405580685055325, 0.45318424677531205, 0.09436631380229865, 0.3100440019274591, 0.15016420969323124, 0.15225915792906292, 0.14341105667422024, 0.3046247404695948, 0.20533049985519064, 0.14765444264739608, 0.16485542172717949, 0.5826396206015277, 0.3722109622340371, 0.1605449621004751, 0.3026096367013664, 0.38604859821259757, 0.26984164590439436, 0.09647932097356116, 0.1510050611215265, 0.17081976409484495, 0.15581476349777107, 0.4805377286250357, 0.10898614972619486, 0.38824336134552917, 0.20869646399509303, 0.1786546422707349, 0.10828167290362585, 0.11376603134061097, 0.1430762944537959, 0.13880436930760703, 0.0779208745430069, 0.1185288821152409, 0.4406949668456912, 0.1099692475192595, 0.4190965709349476, 0.08205339851117786, 0.15589528761066618, 0.3300336757725083, 0.4271727713677108, 0.34674494270871953, 0.09633054181437735, 0.1607882264924775, 0.3980825468645885, 0.17958322098621143, 0.5483662592968324, 0.28359909564719543, 0.18251778736055557, 0.1678242432269368, 0.26479266238207355, 0.13234401473160437, 0.21300965635801758, 0.1448898570399701, 0.33292840871321927, 0.14394716268101626, 0.08154614510942981, 0.12279049352413701, 0.19528300288479522, 0.10393511303207632, 0.09812865315695285, 0.14199359299661082, 0.3245423817399256, 0.5219984688619989, 0.366363772895881, 0.13391209312778016, 0.14831225299269887, 0.26471277559124406, 0.3067377762436033, 0.20998922939973913, 0.1268823341721556, 0.1807734470764055, 0.19561732364678563, 0.5417741479023678, 0.12225023244218157, 0.19949621288676803, 0.13058061630019163, 0.11814947438862956, 0.1779613144424397, 0.20869646399509303, 0.12162580109892877, 0.26395347817579484, 0.20224012357229712, 0.1758546836406428, 0.10745270415356653, 0.15627158700882315, 0.1230531011504613, 0.09475985493855513, 0.10988353903982759, 0.07612696153629053, 0.38231408476180745, 0.2670632068245046, 0.16172411247809262, 0.23641481359789557, 0.21300965635801758, 0.13029190674776428, 0.2912714477529313, 0.5826396206015277, 0.4678105456704206, 0.22641793702962917, 0.17083212516481888, 0.13731402553113667, 0.4581858465635575, 0.1405887556347115, 0.11253301541984885, 0.4190965709349476, 0.49943191390877445, 0.09841499635822147, 0.11569441356427389, 0.09685276117716846, 0.18040975749498267, 0.11585765122001206, 0.2074332416042831, 0.3644642656074734, 0.141325946320667, 0.13905966646261908, 0.41057337710869646, 0.24709228071265316, 0.17273506738023023, 0.0713450982770174, 0.13099323311567798, 0.28613832799421873, 0.07402087736477077, 0.3583904225760465, 0.2917959631655176, 0.1585317661965107, 0.2840503938023484, 0.5969265734514443, 0.3732708550726114, 0.20527545435239833, 0.18769211287333454, 0.09766957374278215, 0.06691403405045088, 0.113245614178079, 0.5697019195470939, 0.12926481882024465, 0.10724941022158602, 0.09215661584603363, 0.4867481461904394, 0.09538521989106145, 0.22682360197480614, 0.14127169224501154, 0.13897771774687384, 0.19108886204829356, 0.10975204747960772, 0.0912431447727411, 0.23046279414730064, 0.09119646653297218, 0.1240037493666277, 0.33861663424397953, 0.1741574596097037, 0.4035865572806918, 0.4079303711526799, 0.16643283869304984, 0.31757386382248626, 0.10332362999861504, 0.32391876753768384, 0.15606368269911278, 0.30415567240243035, 0.07578657133761224, 0.16745417289782372, 0.12653709475102964, 0.3027976344822345, 0.3980825468645885, 0.08645745699966492, 0.1702841691533682, 0.08885468628492689, 0.5217873044687601, 0.29594138321967267, 0.08523278323316391, 0.23508345749285717, 0.17981563615371193, 0.10223776242983126, 0.33517507698488763, 0.10883138637492044, 0.07346055147031096, 0.1297455035849452, 0.06938108074349274, 0.3995302475327728, 0.1347628853596096, 0.2600916812588628, 0.31781165295466707, 0.08354245372002529, 0.4947515508965951, 0.49768031955357056, 0.08597627403332371, 0.15831920070752764, 0.11113455749616107, 0.2096984657962882, 0.11887758540351043, 0.16521684624788166, 0.3305496527620731, 0.20218936599439663, 0.19322323202516967, 0.17601359790856322, 0.3930247438298116, 0.39356639692034795, 0.232502097398958, 0.3283088443130893, 0.09238667569081442, 0.14727116391299774, 0.5826396206015277, 0.20046830102216054, 0.0780118490397531, 0.4990975424159089, 0.108699080549061, 0.11124774126043298, 0.17956518557456605, 0.19908834053940064, 0.10112243933370144, 0.133155774721469, 0.07401346736645198, 0.24628061393129944, 0.3584206190561612, 0.20252932688605016, 0.1277259451330778, 0.12752608747809344, 0.28957707033433583, 0.0878544329718182, 0.10858407336023825, 0.1980077934164557, 0.08871007342380713, 0.34871880564344815, 0.3390566483890932, 0.13001306570236973, 0.36266221909392404, 0.1795376195183842, 0.3300336757725083, 0.19107983774280612, 0.11269043139887269, 0.20904366046713665, 0.07006465822963187, 0.27629926444178643, 0.5969265734514443, 0.2653290170598639, 0.27837790200808465, 0.3020045829763086, 0.12573909173617567, 0.2124526763182716, 0.20457371188608767, 0.10030699032261771, 0.10046578941201774, 0.1624746553070091, 0.15531111848643872, 0.27046810950659333, 0.20122028504657907, 0.1665986749695426, 0.4325695949968045, 0.09914788285593798, 0.2016777383255731, 0.1334784468559339, 0.11451527033600864, 0.12747469326426483, 0.3465185441340221, 0.0958760242449278, 0.10655968562446921, 0.2836341498088685, 0.10422916739733715, 0.15525917257469146, 0.10955541959854098, 0.09989587565063762, 0.12427983613136544, 0.32145963035144987, 0.08913148582915321, 0.18512686067466808, 0.38008076721640965, 0.5697019195470939, 0.11992475090506344, 0.47126840789260654, 0.2671214626454208, 0.10562930964999051, 0.09122228666001064, 0.15359675001532708, 0.18672606693094024, 0.1462964764562365, 0.2001869148488229, 0.4554817911726816, 0.4325695949968045, 0.5969265734514443, 0.09914788285593798, 0.0804820698358118, 0.25026966643108317, 0.07672952703749737, 0.0858326429261748, 0.14605940032385636, 0.1091462065032195, 0.10511428355206576, 0.15005195572775729, 0.07610549571710025, 0.28538406361250346, 0.10841407646420213, 0.263984349318712, 0.3066236600821738, 0.09451008565007021, 0.07023765746851449, 0.07370692771451556, 0.18907639680474947, 0.14392543150638934, 0.34461722257904104, 0.09341206361564042, 0.14552364440204146, 0.1368826947233112, 0.2576005640120584, 0.21210153890354722, 0.07639221680757216, 0.1269602645910143, 0.10836061492340245, 0.09290576408263405, 0.15287100798410916, 0.16221390814183284, 0.22530730174390015, 0.2362917189878185, 0.15456231276111507, 0.260469078041973, 0.28846847156279876, 0.12445930545782832, 0.31816897689289964, 0.2795709791630333, 0.2964151111834595, 0.2155941190074646, 0.3688447884743495, 0.23544506133749962, 0.1040573490457335, 0.1908608406434883, 0.3137333663740398, 0.42947618427468226, 0.2980067569800061, 0.317028898457252, 0.2261544653824057, 0.18165039719868264, 0.3278240072264336, 0.16841639560028462, 0.06657773376426351, 0.2964151111834595, 0.34161793941920365, 0.09299159148110911, 0.1859353338369384, 0.18547278383891488, 0.2904500756259928, 0.11138819865028762, 0.29200779443093916, 0.1739041804947612, 0.15121537886149186, 0.10768053490203333, 0.11284914506819267, 0.18562763796028933, 0.1254795504535534, 0.13529264647568234, 0.20350236733896246, 0.23072609749852108, 0.08166502085714429, 0.30521240901255503, 0.11143108385400874, 0.09994766498180994, 0.14480835561726754, 0.22608417137823095, 0.49045651031265775, 0.5219984688619989, 0.10447704610479361, 0.2550829754995051, 0.21259862731960058, 0.3020282385570361, 0.1940736908871622, 0.14071722639016934, 0.07874416298308516, 0.34161793941920365, 0.07885232556276786, 0.1994031858371203, 0.18165158395004333, 0.07140150733483606, 0.18980368175092627, 0.07402087736477077, 0.12394435046866856, 0.11809554098021749, 0.37231168483921584, 0.31399591582378417, 0.27495050759254325, 0.47956090895636627, 0.1083117718358718, 0.5258148083405186, 0.11280108057069242, 0.25028343526697966, 0.2699218937019076, 0.23168324434006754, 0.15235278806126876, 0.32352323308818337, 0.25535840851440683, 0.1410645029731529, 0.13432932451471333, 0.2321768202390846, 0.11160587376390119, 0.0952728186164123, 0.14489127659249346, 0.3014346500276887, 0.2093810506045679, 0.1599915123051119, 0.11344427415175007, 0.18487433278277715, 0.3203013231528215, 0.12610334031831216, 0.14145230792270483, 0.16913329169459337, 0.0893607533193179, 0.11524617112190268, 0.22027959978723782, 0.11564748378138699, 0.07688558879733497, 0.20624472573949038, 0.14249966751628879, 0.13100253003299409, 0.0802344454329387, 0.17167910583116033, 0.24197503694300865, 0.11330477020441332, 0.42114067901080005, 0.08860716249298131, 0.17882811797836995, 0.30990622096589826, 0.1066199468004958, 0.5267248354537282, 0.14756608817803854, 0.16335366809765373, 0.3232148745156605, 0.3578845230604242, 0.17235452311380295, 0.31757386382248626, 0.11939294426548286, 0.12138637110325047, 0.11632089421949363, 0.15864401435652487, 0.19213824960402484, 0.08560394511921694, 0.21942197226730245, 0.18696527444566946, 0.5417741479023678, 0.24419909625051595, 0.11992475090506344, 0.17668097677346736, 0.09246649285300239, 0.08889691291456511, 0.3108360401489262, 0.2938927055256312, 0.2739821162516621, 0.13539191705924505, 0.16334207814891075, 0.10861671346003864, 0.38009704041909154, 0.5360216566134746, 0.17605115599279167, 0.11842251691626272, 0.12304729772410133, 0.23153699011962506, 0.2848713518500978, 0.15340349192701724, 0.15184827196613904, 0.2472520434455988, 0.3465242472342536, 0.09148166214166231, 0.16575735344978215, 0.14776986987008553, 0.17300560031325513, 0.4343335645700728, 0.12941758308544982, 0.11107521552184779, 0.13154839271630897, 0.13794560891756227, 0.13476510642782316, 0.13057456512248275, 0.3393311061472205, 0.12109373154054258, 0.10906889989911463, 0.296518001294623, 0.11737328268985599, 0.30670011300198147, 0.2890759088514565, 0.1387516537971284, 0.2820874448872409, 0.3203013231528215, 0.09109079624636511, 0.11875492511414153, 0.48712879797698333, 0.09613786706620106, 0.4606063117466977, 0.10370851858455753, 0.18074594852093992, 0.27122529158817826, 0.1384217109679426, 0.08899139074597481, 0.5057755271113887, 0.12615590138495558, 0.1101420243378015, 0.32796447269518714, 0.47628774386997874, 0.32145963035144987, 0.1240743825793572, 0.14895832496577593, 0.36575074803827856, 0.44375932588967876, 0.13882963153611616, 0.09377087785907964, 0.12132422534074698, 0.18246745329638978, 0.13546603191090428, 0.17428720541433065, 0.174008326190022, 0.10269319031153566, 0.27273141146066415, 0.3234581261235491, 0.4353755288645529, 0.35664996011706596, 0.42731821350595717, 0.16784052096096594, 0.22588957661554196, 0.295247026626751, 0.2625019992349549, 0.4670818192657322, 0.13300440004574185, 0.41291878476976734, 0.10144523405097187, 0.077582230419687, 0.38959530854627233, 0.3232148745156605, 0.3980825468645885, 0.3388503062383542, 0.14641438401086335, 0.36266221909392404, 0.1712905250987662, 0.1480264826253127, 0.11126701178256451, 0.10001611777214127, 0.10982946825493754, 0.1462527652295218, 0.12431202372842738, 0.11544980334947463, 0.2912213995095021, 0.25744101002096637, 0.3171745912186369, 0.28017403854178097, 0.1257278302999002, 0.11772920595744665, 0.33297063800084986, 0.22758794686679498, 0.5296763659296089, 0.3203013231528215, 0.14672425424865462, 0.14584931223084296, 0.11718210060810612, 0.11786904906663184, 0.37231168483921584, 0.3578845230604242, 0.38402055516088096, 0.1176500061423813, 0.1391524811607926, 0.1338533298762038, 0.12953391599415598, 0.4585533478018697, 0.10570315715810842, 0.11288996520492356, 0.4047914764948838, 0.11915933646409899, 0.26724250142632716, 0.10937092236782193, 0.29534436117514484, 0.10362229404051011, 0.18709782235997155, 0.12301356563559877, 0.1382476256165047, 0.1327446908563402, 0.07023765746851449, 0.08238904347619054, 0.12587219339107084, 0.07006465822963187, 0.12445930545782832, 0.2803943795831016, 0.13224539462130586, 0.11637371598965646, 0.16669697664629887, 0.5697019195470939, 0.11379287981642933, 0.12564782725876858, 0.35861765893170094, 0.22431737541371072, 0.3409242546371117, 0.25483239178849704, 0.14000214884915463, 0.263204122435488, 0.16661514219413126, 0.1544776484622506, 0.39410728285012975, 0.1381991697529123, 0.12248974081566551, 0.28019272846855237, 0.34190329764410043, 0.13125630155407558, 0.1085600452083617, 0.33135606485428165, 0.3371841051764852, 0.31244437183695123, 0.12124119555547931, 0.1076995932160526, 0.1454744477007432, 0.1801425900318477, 0.28613832799421873, 0.20403697456004918, 0.23529758251694302, 0.2654358842395709, 0.4688790709612007, 0.10610006911710528, 0.22189174343717127, 0.1368842830433203, 0.13960819020142606, 0.1446043906194319, 0.3520706692920619, 0.11028577515030126, 0.10415320162106909, 0.4554817911726816, 0.18188730050559096, 0.16330311546717627, 0.32145963035144987, 0.10352053297858557, 0.18398420852636627, 0.34161793941920365, 0.14877229283889906, 0.1291714696989974, 0.4041925973172754, 0.24662951872240477, 0.10148192560457102, 0.2125531771835723, 0.1317071542037754, 0.13729034785416525, 0.0991654511444841, 0.1636921073736288, 0.15921324616974053, 0.13547154852398186, 0.17842039082089653, 0.1251509661750829, 0.1253035718405727, 0.22709748506668975, 0.11008729815528624, 0.36512579217477625, 0.37081141351191704, 0.3715667719875744, 0.2629934651939166, 0.23139583869229768, 0.11163479184712077, 0.11817857451482003, 0.13573821083614618, 0.11363322945087995, 0.0726619395854599, 0.14182308678384273, 0.45688698836978314, 0.06674274123860609, 0.10470725222422998, 0.10870592486409841, 0.3435021410096653, 0.16769127599628153, 0.09316223515299955, 0.09189169878863616, 0.20122387913164275, 0.13952183026992285, 0.4670818192657322, 0.16242675442994445, 0.10371376789598225, 0.16486687473507314, 0.23599175714618825, 0.16754386333398383, 0.1998789439431504, 0.1638721072825832, 0.23158165033461714, 0.30855859267823765, 0.14723713516800666, 0.33975185378567324, 0.29895134822369923, 0.1001397986295591, 0.09994619713752244, 0.19155490039439227, 0.13152856027121257, 0.1812572458008389, 0.4139893174296667, 0.1619482706443895, 0.16066001829523632, 0.12077070417875345, 0.18487261073662367, 0.19035615494828756, 0.392012587707701, 0.2561808133179927, 0.17147025568823926, 0.14080245232505828, 0.10883138637492044, 0.27478651374571783, 0.43486475875201563, 0.12443802990055369, 0.32391876753768384, 0.14464150790359181, 0.4805377286250357, 0.17933928333685983, 0.12351553029633695, 0.1520905530542111, 0.3885883482724729, 0.172371918508742, 0.11985217913105002, 0.2801411817998783, 0.15728913520646612, 0.406255352600301, 0.1257241885813638, 0.11115843976982223, 0.19347974591751893, 0.27014503808834994, 0.24052135658664753, 0.1511788085307841, 0.10611946648388151, 0.08100185580009993, 0.3275691187243804, 0.16043530184431423, 0.13432932451471333, 0.13099323311567798, 0.1099238053038116, 0.30670011300198147, 0.4805377286250357, 0.10389429375770723, 0.25582543549623177, 0.290360486896936, 0.4200276429469, 0.19395445606416273, 0.35092518865650374, 0.08205339851117786, 0.16348963678041914, 0.15179516507173652, 0.13658997664210676, 0.2030806094610008, 0.08634667595257937, 0.10322845290783396, 0.3324787914707304, 0.17324227319993837, 0.1060439201946876, 0.27748503661472196, 0.146595278717635, 0.09994766498180994, 0.10836061492340245, 0.20676089232585543, 0.09065964410779218, 0.2718841368836513, 0.12503376478086628, 0.17068772289222095, 0.07507178464242563, 0.15713312993462983, 0.10781463573383372, 0.10992592052138346, 0.32406399418174103, 0.0925605755522954, 0.15330896671297067, 0.16345575625470254, 0.2546122587337308, 0.15122971535625254, 0.38402055516088096, 0.17256817535015084, 0.45888246607603767, 0.28613832799421873, 0.20950316524385976, 0.07277062423388529, 0.1254348341210113, 0.08810351320289313, 0.11879993139988093, 0.26963038715143234, 0.13241088866679046, 0.5325210523349728, 0.3020396886843371, 0.1669030766352661, 0.30225949414796655, 0.49981740829166743, 0.14584168866338657, 0.3787546478930519, 0.08103744030936529, 0.14351152825842803, 0.20318029706197752, 0.28046146786509024, 0.28060327242040745, 0.1785182355651556, 0.2648448654758644, 0.3217542895579865, 0.37333345035897575, 0.11912285980181943, 0.08933648337898929, 0.08604509969006977, 0.1815823438549137, 0.21918489444108052, 0.12010677138270909, 0.06921003425064559, 0.11063185941898944, 0.12571650729185815, 0.2780893533632306, 0.10817545238459962, 0.12933171875360214, 0.3770212079917709, 0.4584402952243771, 0.17196512184393328, 0.22812274531667398, 0.15339011835505192, 0.40815179895522946, 0.24761112471522176, 0.2910235971408844, 0.47628774386997874, 0.11391736850823489, 0.3770212079917709, 0.10001060219527992, 0.2485320022789386, 0.19006766689811133, 0.20752645503891648, 0.16857595436609743, 0.15396593564196306, 0.18232223358960842, 0.21159896712423848, 0.1702841691533682, 0.1954514749036088, 0.06860504145546494, 0.25308779302317413, 0.14431413104276378, 0.07521095070416813, 0.3680401542662742, 0.08051683714817263, 0.1257062559600862, 0.22189040648135075, 0.37028779143008667, 0.09711124040051042, 0.26346842505309115, 0.2910384147776017, 0.14488977712255038, 0.10918322132354416, 0.09827455387307386, 0.42353766607211013, 0.1434035742946059, 0.3427459036877291, 0.3980825468645885, 0.21718245550485876, 0.2987976544801301, 0.11534035540031445, 0.3715667719875744, 0.11992804925355849, 0.24701652374636449, 0.16043958918296392, 0.1692465815386021, 0.1406190709509271, 0.3334741311731801, 0.1654522170422708, 0.4605599733523242, 0.4229968758774306, 0.31757386382248626, 0.20292340495989036, 0.4141490839182677, 0.15085286864699773, 0.4660354343400735, 0.4752066234932505, 0.17357941425480075, 0.13424854785829435, 0.07140150733483606, 0.28907719116462816, 0.13534665138321114, 0.11899186092194547, 0.49782772846378376, 0.10080436509445864, 0.10322845290783396, 0.11132458687699362, 0.12276446762854877, 0.21417601554228127, 0.14434001827920648, 0.10415035434723945, 0.5042799061190729, 0.31781165295466707, 0.20185164104664516, 0.25925369421464045, 0.15126223047568327, 0.4047178510138429, 0.22360914197474213, 0.28885991736125416, 0.23114096572991327, 0.10901034603261543, 0.22080517507793868, 0.11853642188807297, 0.1269337540015054, 0.1410660919963227, 0.27973443224384426, 0.08634699606658017, 0.26381695988563897, 0.07825973665814169, 0.10807574016554986, 0.3232148745156605, 0.3454127203032528, 0.07411444005115274, 0.23807005694912736, 0.11117332252118049, 0.14316630288690277, 0.1758546836406428, 0.10410072317863478, 0.38249980760810287, 0.23544506133749962, 0.14407038959900564, 0.11002555511062714, 0.2035017046420105, 0.17209730370676682, 0.08226687446188086, 0.3578845230604242, 0.14907642367179447, 0.16678461569997968, 0.14050425634537447, 0.4112897592603239, 0.22758794686679498, 0.10861671346003864, 0.17481236289954782, 0.15872687026283006, 0.21067406397354138, 0.1984938962380093, 0.3568882017088658, 0.23330811038653337, 0.15481534679113104, 0.11823882921720204, 0.13164009322832282, 0.09211548594558741, 0.16859261245376048, 0.30855859267823765, 0.3067377762436033, 0.08738266641700168, 0.2388146096592496, 0.10964015649726494, 0.12194558137739488, 0.21747843022084806, 0.16403769053282202, 0.38402055516088096, 0.1727289064044043, 0.1916932601470645, 0.34161793941920365, 0.1592209505776752, 0.09701894645064017, 0.31275451063000265, 0.0824012644813738, 0.09164754951478683, 0.11797598206630765, 0.22818434205690477, 0.10552601520283032, 0.18631971290523872, 0.12902906445004075, 0.341901139767248, 0.5110718256020546, 0.14092822072168956, 0.20151723225728493, 0.5639892512289002, 0.10071078964338236, 0.2058246838527788, 0.26412605054099275, 0.2892865912823728, 0.37231168483921584, 0.562946372117863, 0.3439099097519766, 0.4442235369456067, 0.24454159868987985, 0.40196555626451624, 0.15960042888397355, 0.09827455387307386, 0.13188978848003682, 0.24262378138665555, 0.1089322774326049, 0.5325210523349728, 0.13188978848003682, 0.11460700745540213, 0.10685272203805167, 0.37275260660874504, 0.19632251548635823, 0.3715667719875744, 0.17764792264678445, 0.23242507025629197, 0.08773165868380621, 0.28569274531164085, 0.21894482565619788, 0.280489543578347, 0.10537263769321546, 0.44375932588967876, 0.11269795001231332, 0.10205866627966549, 0.22428335631372154, 0.10003079407261642, 0.154018866591736, 0.26567906731173485, 0.14375876331594395, 0.11906742405790056, 0.09682725811768085, 0.4155158140791688, 0.114193966229556, 0.22584614767467806, 0.17001163798861832, 0.3285699207530483, 0.22439825860783066, 0.37277295248764697, 0.09975129439534983, 0.15482222793162387, 0.19375587575134035, 0.3421571477249981, 0.3331256967094497, 0.3520706692920619, 0.14720425137130966, 0.35154804248855615, 0.3472401949646228, 0.21918489444108052, 0.21855590853484677, 0.12748618741149972, 0.06938108074349274, 0.13375053789343372, 0.2342200604567892, 0.3393311061472205, 0.18296646151866264, 0.1532870318816103, 0.12297174050694117, 0.17843973095670923, 0.27155002602534306, 0.18581548743884901, 0.13768416613012993, 0.1046888808707039, 0.35818127917038534, 0.3677245487284372, 0.13692484129435228, 0.24721243531009823, 0.07492263101674419, 0.35154804248855615, 0.40256642914233565, 0.07271359599847414, 0.26984164590439436, 0.336920206202104, 0.21397651767016293, 0.2699218937019076, 0.11370180100792703, 0.24761112471522176, 0.14400378582220336, 0.14428965421178366, 0.313950896705582, 0.29551189792384686, 0.2035017046420105, 0.19494069396048322, 0.27918336552285283, 0.14328627867888621, 0.15482691122212988, 0.11204109351419721, 0.17958322098621143, 0.21043794945005853, 0.2738131220112801, 0.17307984745976787, 0.14210113150876336, 0.2699218937019076, 0.0785890835740841, 0.13848684211560236, 0.13189573261552334, 0.2618906490857293, 0.11382737904015765, 0.29891358541826707, 0.17960333631634834, 0.14190290499411232, 0.187319275551403, 0.3752164853344754, 0.12860663678652198, 0.11232350251564636, 0.26127739970059843, 0.11913161602629317, 0.1428511770000654, 0.17833635136482043, 0.16730809936658209, 0.21322948417420648, 0.48768228047833256, 0.2904500756259928, 0.13546588638492338, 0.1122812157177442, 0.2938927055256312, 0.2834250182270108, 0.2413872623015055, 0.1142014731819208, 0.119881274611034, 0.1721438768344183, 0.0890773119849462, 0.33253764190330176, 0.13089791413695523, 0.16081509814699307, 0.14045181602583878, 0.1322853605575554, 0.20916051879330563, 0.16704514343605326, 0.43969586931650156, 0.15531111848643872, 0.3265179164782485, 0.4366916031412031, 0.1627421535260552, 0.1263046041218861, 0.17657424480817493, 0.15772959045460055, 0.10947216197731564, 0.5228223811867851, 0.12534663277811664, 0.10109350606501064, 0.10311856417091314, 0.11288533090812569, 0.12157170799209097, 0.11569441356427389, 0.08845583692775949, 0.2726415137680523, 0.15626624980340004, 0.16875547709282754, 0.19339970064783144, 0.23072334191678942, 0.1620661310355971, 0.15784002926811225, 0.15857122639758617, 0.18403692088076337, 0.10488932592611393, 0.27690793793529284, 0.2521235641702149, 0.1501977792058153, 0.3578845230604242, 0.3560584616973087, 0.5826396206015277, 0.13091442038411746, 0.3371841051764852, 0.3919155273522563, 0.06526498325816393, 0.18240811839842141, 0.10128239366084989, 0.16689247906435714, 0.4688790709612007, 0.13264607377000537, 0.09183039108167201, 0.14757503759962573, 0.12148224112486772, 0.13276748100347444, 0.3472401949646228, 0.23662573559838998, 0.15832943671863733, 0.15468645049398325, 0.2152973198396861, 0.1498061083043633, 0.10446188325973162, 0.14384431778508427, 0.36676610301455403, 0.2093810506045679, 0.15677035030958475, 0.1779613144424397, 0.13373978779697562, 0.43643497527753344, 0.12109373154054258, 0.174885424431826, 0.07523274128610936, 0.21574955551295288, 0.12090727377370886, 0.15803200877104367, 0.2074839947090174, 0.3227136303266316, 0.3581799610041303, 0.4842146120477015, 0.17247968049505802, 0.23429776748027994, 0.10303873644802682, 0.32916598789375034, 0.2634283478404665, 0.08349887163527621, 0.30786775486414075, 0.16725780914598684, 0.14247497138775092, 0.07818392451816257, 0.21760329891021407, 0.3073843753778349, 0.1569076608472603, 0.15478065062816362, 0.206518306988216, 0.16079013654777746, 0.11374818241043842, 0.3594912660881093, 0.12591550635725535, 0.159093323218526, 0.2762680884930708, 0.2928340194509319, 0.20082904369892593, 0.16695924817067362, 0.09262050501164651, 0.24761112471522176, 0.13425999970941205, 0.07104437085119698, 0.44375932588967876, 0.48315578271411735, 0.11912285980181943, 0.4261152802235658, 0.1374750627174287, 0.09786623762165256, 0.20705837888877457, 0.1643998944559662, 0.3496863370566264, 0.13347967960614052, 0.141299604580375, 0.1547672245471369, 0.38402055516088096, 0.308976988218646, 0.11051157688118456, 0.280489543578347, 0.2451879653515205, 0.28046146786509024, 0.08701857662527543, 0.12991126119511032, 0.23529017044535325, 0.2857200840591164, 0.1681090021194037, 0.1604686491458089, 0.16555867079594067, 0.20260015883237664, 0.11150519068641816, 0.1094033087750925, 0.13214933240718238, 0.19502202660878382, 0.12240930310582833, 0.15105395748506845, 0.4670818192657322, 0.0802277556711421, 0.16371717651248577, 0.09678468212171773, 0.10415035434723945, 0.1866585989325904, 0.125377043316841, 0.1318587529189528, 0.1692161337003971, 0.1103004511237496, 0.11893197341720337, 0.1582861943735465, 0.3836310658974485, 0.14063882668632943, 0.23133005349643596, 0.127222377069857, 0.1520263645851439, 0.2648752390612324, 0.30293247497471454, 0.16626363414127704, 0.1712823341011371, 0.2187501752099942, 0.13802115746463497, 0.24709228071265316, 0.23696255681335276, 0.19212537528389234, 0.26872825948233897, 0.17800075032705723, 0.07370692771451556, 0.1461642785370514, 0.11570955367961017, 0.2043919318852905, 0.2904500756259928, 0.27083589657449963, 0.22433639313171644, 0.15539129938708018, 0.26984164590439436, 0.1741681526827205, 0.2527857479316807, 0.2984116269846544, 0.15706178945784252, 0.17110155490407628, 0.07355582016201026, 0.3698782023530253, 0.11274391417447881, 0.1037632831069721, 0.25281198546384254, 0.2195697046224343, 0.12899829228035858, 0.3569401907917122, 0.10422328837963238, 0.2984116269846544, 0.09359230070371032, 0.15250208937887708, 0.09624983325037509, 0.10938351693607691, 0.13925553767809562, 0.15032887026508351, 0.06657773376426351, 0.16165105228511825, 0.11274391417447881, 0.5294850073535377, 0.1673839199997823, 0.12059294742024457, 0.10393511303207632, 0.07518314491709976, 0.10893794765929102, 0.4164931091584333, 0.10322845290783396, 0.118937050355102, 0.14270514058076078, 0.22223733002059462, 0.09691200798892337, 0.28613832799421873, 0.22616852529647427, 0.28046868519448936, 0.1263156646092733, 0.4571089724553004, 0.2995840891695709, 0.1285437628180591, 0.32916598789375034, 0.44162689695372814, 0.10621409638360335, 0.14945416652870097, 0.17658936933478045, 0.11848821628620754, 0.12428098288993944, 0.10152932141343878, 0.08430495471806254, 0.2787926329352204, 0.2250157047394223, 0.490639552644296, 0.08687968545121842, 0.3203013231528215, 0.13589564206537613, 0.11245589422078132, 0.22683203848407166, 0.10097665898637248, 0.3086454873738882, 0.4738067283992497, 0.3339700683899355, 0.15425482313654051, 0.1396740057465441, 0.10909813362435931, 0.4282273958583296, 0.11237922946644872, 0.18696527444566946, 0.1446699103807535, 0.3610188352382121, 0.16563994592251455, 0.1084331902395586, 0.10587998632807032, 0.3459137852668773, 0.10948359363066036, 0.2116540165245158, 0.11430305208620001, 0.12524412118256506, 0.4070144189875508, 0.21802128768444629, 0.2198681624109378, 0.11988648863939008, 0.08850539700198312, 0.22069753159863967, 0.09394225954780007, 0.2699218937019076, 0.06674274123860609, 0.15741180866781115, 0.11328342854847476, 0.3767862672641506, 0.13416750846244685, 0.16560325070059753, 0.10396607770987143, 0.08664216178672124, 0.21589447201239576, 0.1423149043687003, 0.2954099903651102, 0.2327928862219898, 0.13474540377771124, 0.07417187253187789, 0.29848726627086675, 0.09385537673207738, 0.11167315481668447, 0.1011513545955657, 0.0961193968991718, 0.19465441500181754, 0.39005730288695695, 0.48315578271411735, 0.3342447719351345, 0.47628774386997874, 0.28613832799421873, 0.1293648523006666, 0.10441786998227749, 0.16023904519831267, 0.120596901575263, 0.2208512178933936, 0.21232100058782968, 0.1927191001883356, 0.4990975424159089, 0.10403344973401832, 0.1752130404837022, 0.13042716764510864, 0.11136196374165418, 0.16470390545550964, 0.1555294478412502, 0.3371841051764852, 0.26717654978147054, 0.11359664147028796, 0.27690793793529284, 0.2327313322090484, 0.17111057193741913, 0.2899114274163396, 0.1088829988301729, 0.31757386382248626, 0.1293478910027819, 0.3393311061472205, 0.21814122435387207, 0.3254960319210299, 0.47433363426157543, 0.282333751846372, 0.11384494373553887, 0.14591783434099878, 0.14017149256154302, 0.12140044285741868, 0.32907718821939896, 0.18963304137782133, 0.16830707519358698, 0.11809554098021749, 0.17260928468624934, 0.1685546873335823, 0.33265687381652964, 0.09189169878863616, 0.1657437438999696, 0.1241200713455373, 0.1210858316772127, 0.1732455679686903, 0.32916598789375034, 0.1686068246184, 0.15464139227098891, 0.29493202763537213, 0.1718140490389921, 0.1489827617328735, 0.10541382242556756, 0.2964151111834595, 0.14327300652531746, 0.23707691828578992, 0.29377798335981453, 0.49981740829166743, 0.26814424679660137, 0.26984164590439436, 0.13004501715946357, 0.3020282385570361, 0.14270053271027372, 0.17343736790088932, 0.2352695604283831, 0.1832401983603311, 0.5325210523349728, 0.47947946523925455, 0.385140814124566, 0.2209088792145799, 0.12762967224774613, 0.09221849107924604, 0.4190965709349476, 0.23547094910757696, 0.36948678438924976, 0.12021407984984885, 0.08600549496951296, 0.5258148083405186, 0.1418554229633699, 0.12124926051494139, 0.2762680884930708, 0.19705788354285747, 0.17956518557456605, 0.11985655406418336, 0.1090885556783343, 0.3057352669993069, 0.16399046788964944, 0.24811465435658472, 0.12445930545782832, 0.23447965441746216, 0.23912737855594035, 0.12148224112486772, 0.2128706512196224, 0.17389743313436623, 0.07665457350630925, 0.23752430475062974, 0.13840287106943353, 0.1288730032334468, 0.24830267085613433, 0.08884116303632678, 0.1753795993511562, 0.5494160824814951, 0.3870295718958153, 0.15621226840671365, 0.38748705770991715, 0.1586979637174921, 0.1503637644381059, 0.16998519583117497, 0.17535382912216238, 0.19284443906747625, 0.24650616897521277, 0.17654065243720637, 0.37231168483921584, 0.13318287267930912, 0.1564084583326788, 0.25679991867070023, 0.0789376417034373, 0.12937772629984115, 0.18581753545202281, 0.1255961608022139, 0.5612080564256602, 0.3700700287336322, 0.154709133395514, 0.26784376534924453, 0.20623425355943667, 0.32916598789375034, 0.07885232556276786, 0.38984599836951656, 0.32347580466896103, 0.19352699984795896, 0.10814675792783153, 0.4315292136593948, 0.08256506403996687, 0.13029190674776428, 0.11717030263085758, 0.4340317981245996, 0.121558164360543, 0.3980825468645885, 0.5506737460715845, 0.13057456512248275, 0.0993935428409351, 0.22474091135286162, 0.12326646449138817, 0.4054185837315157, 0.22247164610182898, 0.3722402215024185, 0.10934728909561142, 0.3107021717386903, 0.07140150733483606, 0.14438442602186613, 0.2434851031589415, 0.15944815969262646, 0.3881808790911345, 0.204849820249371, 0.1259969692863146, 0.24983246415199512, 0.22651194992774168, 0.06657773376426351, 0.2532304043569526, 0.15564303597827825, 0.15340349192701724, 0.20318029706197752, 0.1354943940733116, 0.1581649785799518, 0.16996966178399928, 0.2014147457940731, 0.4366916031412031, 0.16127084300968048, 0.13736964208636454, 0.28613832799421873, 0.18619446435242343, 0.15310710924031457, 0.1812462270414701, 0.4683613549585294, 0.08007111251648702, 0.16903405308741387, 0.11578711907963776, 0.2256573990853947, 0.15933113931628362, 0.13431680472305618, 0.3332751044368922, 0.22533232828432317, 0.1277917775932603, 0.15553276599395227, 0.3465242472342536, 0.43643497527753344, 0.17400282534449668, 0.17239146377026648, 0.19653062737825394, 0.23369641961414053, 0.21652783259888028, 0.07580306653261243, 0.33008696279811434, 0.12067899772425719, 0.24761112471522176, 0.12710020398462296, 0.1472262201373493, 0.12475899455887832, 0.22305115708565904, 0.19228184694894795, 0.2587298740174489, 0.15153305536264508, 0.13052398051634181, 0.1379833920352141, 0.11985285707134202, 0.08602056639549538, 0.47947946523925455, 0.17256817535015084, 0.39251123815998334, 0.10415035434723945, 0.24709228071265316, 0.30961998072731073, 0.5515548668014476, 0.11853947568400983, 0.24095606031316294, 0.1088829988301729, 0.28613832799421873, 0.19355537577070728, 0.3300336757725083, 0.12954433571229934, 0.15722278479748497, 0.10305593345343234, 0.27837790200808465, 0.2762680884930708, 0.11482483121435395, 0.10861671346003864, 0.5352136543736017, 0.27690793793529284, 0.28438072613213405, 0.5602824362477258, 0.09016307917490549, 0.3322233097951996, 0.10393511303207632, 0.19849987090260676, 0.21084884356830766, 0.23900947984248125, 0.45920676057493565, 0.3300336757725083, 0.09573996507038492, 0.21291863421101842, 0.24132639240661802, 0.08350650024575064, 0.2568776524929812, 0.11262338097047836, 0.1450134887683618, 0.1829131394001517, 0.3681585679085086, 0.20268170053550272, 0.19535746413509678, 0.14071234794362786, 0.17800075032705723, 0.18063494278168996, 0.11114931368624323, 0.14359340812884025, 0.06542696524042436, 0.20966981907898077, 0.38737529776934704, 0.1483737810393925, 0.5147508280562094, 0.20558662119740873, 0.37231168483921584, 0.11524617112190268, 0.110226860020889, 0.11660962675525856, 0.5070364983728658, 0.27690793793529284, 0.1316553381339595, 0.10988102125788175, 0.34161793941920365, 0.08456083651646489, 0.14570961848183725, 0.11114728190615943, 0.2761391465363861, 0.2833773658345738, 0.14529089720007443, 0.1146316501715113, 0.280489543578347, 0.3036267117880539, 0.1940924729744967, 0.12315295460452542, 0.2186177552871709, 0.2186755894305413, 0.5015091841629842, 0.28742434384572735, 0.562946372117863, 0.12774107100369417, 0.2856175505816614, 0.3599224530470562, 0.10190668514844463, 0.09619210981130377, 0.08611893323649064, 0.08007111251648702, 0.08406828603662442, 0.2567920567131959, 0.30491513592603364, 0.08577836521801158, 0.5352136543736017, 0.15321989376132342, 0.2671133268778817, 0.10861671346003864, 0.10563951949556673, 0.09975129439534983, 0.14845200533198127, 0.149308294542743, 0.09055064648690372, 0.23620816167670097, 0.15349444690532196, 0.28438072613213405, 0.19302635688548642, 0.21267693959258213, 0.30158230786966345, 0.1721374202795812, 0.1001869959316401, 0.16492765821777594, 0.42728570986746145, 0.280489543578347, 0.14606609637031334, 0.19952488669838728, 0.10760086889593147, 0.4565822001528348, 0.5551690920576366, 0.24121023698490718, 0.23833508865987155, 0.08851912553805039, 0.1024939410843794, 0.15814853944563778, 0.14947309825640662, 0.10376514871945529, 0.1716321278420844, 0.17356270576346286, 0.14210113150876336, 0.49782772846378376, 0.16106708487341706, 0.5395199441943894, 0.5033554386295946, 0.37231168483921584, 0.1160631097029923, 0.16620769330461554, 0.27945347257322356, 0.09241204395461111, 0.1658472721565494, 0.12311721379792777, 0.3371841051764852, 0.3395668165151632, 0.13338849227936989, 0.09774699221853592, 0.23895160709356236, 0.1687755089538837, 0.33664582807168714, 0.10657681403340816, 0.16565120091507943, 0.3786420259602295, 0.4752066234932505, 0.3355943336610141, 0.38402055516088096, 0.4581327916577438, 0.16601698977845536, 0.4683613549585294, 0.1122849111436587, 0.15377481152566883, 0.4954417852973533, 0.13434616044442424, 0.30764011354486365, 0.11322165820904534, 0.49981740829166743, 0.27918552098752986, 0.08145983577152073, 0.25903179548514943, 0.5697019195470939, 0.1734266274882878, 0.21545330992971967, 0.10103375217155088, 0.1831120117135258, 0.3488365443606917, 0.2561900303676676, 0.11899654931812673, 0.09882802737125684, 0.2790767032487098, 0.181271544276374, 0.2240038579265067, 0.10701752595929027, 0.09563362718474434, 0.1272453596508688, 0.06526498325816393, 0.09919814096714398, 0.263984349318712, 0.25296930362402636, 0.27378494909552786, 0.16327061585328023, 0.36266221909392404, 0.22936326406155186, 0.08947018298534914, 0.11328342854847476, 0.2511122052700088, 0.2128951465068064, 0.08971808866434343, 0.11453969591105978, 0.1445979084670824, 0.27837790200808465, 0.12913305312445125, 0.12403893209247635, 0.10473077324813793, 0.3015397442323041, 0.08166971907309586, 0.3260912621964384, 0.12065484429643272, 0.12638331541563022, 0.20960076547784567, 0.09774775643127483, 0.15659454576988488, 0.1564852472191488, 0.2683960682820014, 0.11406862754013625, 0.19604672106787963, 0.11578730822886071, 0.4179511528266677, 0.09158785804181062, 0.10322845290783396, 0.1573032175903813, 0.15404583553646659, 0.12460952507023347, 0.10849582521683125, 0.49981740829166743, 0.13954429415613895, 0.13048346673349576, 0.12512085766999914, 0.26984164590439436, 0.18739392210994035, 0.1237879780545226, 0.49588461238842685, 0.10814675792783153, 0.3226570085773277, 0.14276684690026434, 0.2877370649078979, 0.09401885780101882, 0.10313019259062131, 0.1935545251277028, 0.20638516572177598, 0.1158067372045973, 0.14066226589068045, 0.16908218953301746, 0.10838392163492096, 0.47126840789260654, 0.12290724988561968, 0.1707929971647295, 0.17585631611598856, 0.33332784893734574, 0.11107521552184779, 0.4031679613134422, 0.26486045674502356, 0.28740604732438974, 0.15478843813594761, 0.4188831020095295, 0.20295411335460906, 0.12648670562835046, 0.1485948728637388, 0.28848227442279606, 0.10621409638360335, 0.10345457195265027, 0.3078488777469763, 0.10941669204898286, 0.27918552098752986, 0.20289371378748267, 0.10976089281644634, 0.17712531416105584, 0.13268806722403786, 0.11037721567075684, 0.1015814460902095, 0.2913701468080452, 0.202852390175004, 0.11716075909340219, 0.09671059086702351, 0.3373061612564026, 0.2697795337630201, 0.45631099607076425, 0.10364819142834113, 0.09873329596179682, 0.11098444337785585, 0.10410072317863478, 0.14596271751924025, 0.2211085688765827, 0.5697019195470939, 0.12580242280959195, 0.3393311061472205, 0.26984164590439436, 0.40270825147038225, 0.14857184922831798, 0.07008701835372157, 0.15348656983214617, 0.1089322774326049, 0.199912981768033, 0.10657681403340816, 0.32137774550603687, 0.47415957395883557, 0.5551690920576366, 0.3328001118383194, 0.12954433571229934, 0.2290286810051482, 0.4978533195146815, 0.10105876848404641, 0.09578850010168045, 0.11660962675525856, 0.20986627095610055, 0.16205535670817645, 0.10389429375770723, 0.21539799993137318, 0.21453413111949715, 0.2140746681679544, 0.1286713015083235, 0.280489543578347, 0.47966081307082736, 0.2860589204605002, 0.0966664309751434, 0.24585925753733062, 0.16760951130821483, 0.19497566612602887, 0.2964151111834595, 0.2428952695761288, 0.13758240180503742, 0.15855699720426203, 0.308976988218646, 0.07968040161861982, 0.10909813362435931, 0.40573972844009454, 0.1466162763863288, 0.24110776481235685, 0.32261103799688984, 0.11290730618845823, 0.3237162682461073, 0.12591550635725535, 0.24536149057496914, 0.14041100066740295, 0.13249498922577158, 0.26398576930923673, 0.21371057735334, 0.16418205665287774, 0.3895791696306469, 0.3362160276075333, 0.5170530606982461, 0.15592549171885633, 0.13547154852398186, 0.13644610567919413, 0.10184533932496469, 0.26211950609386164, 0.1084331902395586, 0.49768031955357056, 0.1542886261734306, 0.10542502718997906, 0.23790215735066378, 0.09630201893270457, 0.16585051257628883, 0.377372025836854, 0.21166100900512608, 0.11315076632254481, 0.14206052024008456, 0.10718769236171329, 0.08166971907309586, 0.5219984688619989, 0.15784002926811225, 0.18056587894672788, 0.08315724363703438, 0.24796104806213573, 0.5362681962111882, 0.45036260278063406, 0.1537770748320909, 0.43767409710138916, 0.16668058978402556, 0.2762680884930708, 0.280489543578347, 0.20408178397539214, 0.2267570632420933, 0.2500954593206519, 0.15640623538632112, 0.2398979328804145, 0.26356597539793086, 0.38249980760810287, 0.17147025568823926, 0.19897144716491594, 0.07750286843489666, 0.1762095018338365, 0.09540812579175202, 0.1740460188070431, 0.1384678686769829, 0.09702560294861741, 0.08297297883455881, 0.0780118490397531, 0.23667853138375997, 0.12614204175780525, 0.11402460864500027, 0.08170419356306159, 0.07612696153629053, 0.3332751044368922, 0.3245423817399256, 0.30577918034919077, 0.1657126413153497, 0.1599915123051119, 0.3525555990460398, 0.26706168768638183, 0.1297326035938864, 0.22407001395687307, 0.12821807588659853, 0.34722282506861296, 0.12099343498717643, 0.22135623366316398, 0.2058246838527788, 0.3658294467266497, 0.1659258435676294, 0.07507178464242563, 0.27592880533647335, 0.22861236080855357, 0.12076088631280509, 0.12719213698340967, 0.1237879780545226, 0.15419372065472084, 0.317028898457252, 0.2412938330566443, 0.13454109673203046, 0.19106760163354394, 0.14099665465865377, 0.09835385864931617, 0.14431413104276378, 0.17215679550478316, 0.16826542514247456, 0.12779533520177183, 0.2706578452768883, 0.5219984688619989, 0.14425525206145, 0.3109211313357166, 0.18821485946148353, 0.1405268915103716, 0.23002306670495368, 0.09210810319337945, 0.10415320162106909, 0.259789240033842, 0.20196969784812643, 0.10660093483152024, 0.2509955491414749, 0.25977976862180024, 0.12066772831790942, 0.19303125439460195, 0.09237474115525796, 0.10760086889593147, 0.20662126829812508, 0.11378999665599081, 0.224721624341457, 0.1337090277165985, 0.4011299948924481, 0.13672048448367113, 0.14104895538643744, 0.1484727832954268, 0.35270731811832085, 0.13692484129435228, 0.1312945470002173, 0.07417187253187789, 0.09827964639675817, 0.5483662592968324, 0.20818219842607422, 0.5551690920576366, 0.13154032897960935, 0.1527469683322298, 0.10339322295008845, 0.23059605907562924, 0.11084890844801383, 0.29844871054232563, 0.3521889277263029, 0.49379136108679933, 0.17109379849079862, 0.09011878265746116, 0.37019283487699484, 0.12108911409824054, 0.18121020430367255, 0.3608118988908663, 0.0956760567197418, 0.16921402588346182, 0.1295566027986179, 0.11598617991470389, 0.19248370143559995, 0.2481158948054125, 0.14425151610690665, 0.08764300291777744, 0.0978651808263049, 0.295247026626751, 0.1943525710124419, 0.36465066221419296, 0.11490925276109985, 0.4867481461904394, 0.19578458527297368, 0.5141922471235416, 0.3910974461444844, 0.2805828721242264, 0.13670734581657473, 0.14019274106878163, 0.1386861261385938, 0.36266221909392404, 0.14324154197109795, 0.3466434919870244, 0.21151776656820218, 0.5325210523349728, 0.1088829988301729, 0.41255116764275457, 0.10858407336023825, 0.15750100571843872, 0.17663402440568524, 0.21442305336458947, 0.1385777254006806, 0.2365505286706955, 0.16955667789488896, 0.09827455387307386, 0.12445930545782832, 0.39097157587345877, 0.47441167827493835, 0.16696254291388118, 0.08535917520568821, 0.2006020238359057, 0.18153613261581816, 0.33691289141773834, 0.14541943660552764, 0.10442737176647422, 0.33139578713501217, 0.2699218937019076, 0.06691403405045088, 0.17852883145480566, 0.18383091844579347, 0.0806531134106335, 0.09207321881784783, 0.10895868059347853, 0.11368765120324692, 0.11388352257680169, 0.11665123958536547, 0.09979150512585244, 0.1909791146179347, 0.39091249256919064, 0.33375198503312375, 0.3429023690891103, 0.2578996846529388, 0.24624484786298537, 0.2764872598557818, 0.17142444629816134, 0.06996525077770452, 0.151659594892832, 0.14628312530943627, 0.5349080767805885, 0.24517520521323807, 0.2009109134258669, 0.2141828958322033, 0.490639552644296, 0.11231119363973506, 0.14166732817716707, 0.3362160276075333, 0.13244813346560147, 0.1560548292534123, 0.14970405957822866, 0.42689626627532423, 0.2540301019594898, 0.21995412140501688, 0.25215378493593205, 0.1304462387831728, 0.2255304887393345, 0.1104972017006394, 0.21578117003181352, 0.22203933638190712, 0.16139500698920103, 0.44688326964507374, 0.17360510612243282, 0.24486639974209934, 0.3588808002691689, 0.2562197664075632, 0.09521602030832364, 0.13905966646261908, 0.3014906504673216, 0.16021242241585712, 0.3052180049767839, 0.09142700203292775, 0.1289706846381472, 0.12806210016328387, 0.32265014736376485, 0.11617434585099497, 0.13305673289509717, 0.21046800549202155, 0.295247026626751, 0.12349455271416904, 0.3980825468645885, 0.09695504511559323, 0.17451190238004502, 0.12677437747374518, 0.16686007528705835, 0.1263282710621156, 0.08951108127348412, 0.07927512020720785, 0.3245423817399256, 0.15457301149822744, 0.09451499319209843, 0.08884116303632678, 0.20148076270572027, 0.2792346430906427, 0.10111959170727004, 0.155819941317375, 0.15005195572775729, 0.12281840921796199, 0.4890513601749364, 0.1704069656306542, 0.12518247418924433, 0.24306775144815254, 0.3284620964997683, 0.27879970812309945, 0.10282218049724176, 0.37231168483921584, 0.1619482706443895, 0.31757386382248626, 0.2515658887964129, 0.08481926145607271, 0.2762680884930708, 0.5612080564256602, 0.12447068139285794, 0.127481588930491, 0.16431907351503, 0.11649725119540107, 0.2305564060188406, 0.10393511303207632, 0.2449893846558101, 0.27914452403682083, 0.13909876100220586, 0.31689313663313395, 0.11245719177012183, 0.18583092695140516, 0.0912261855818909, 0.09559188564912854, 0.1084331902395586, 0.0789376417034373, 0.5181117078568701, 0.35930894611477066, 0.15220969591105118, 0.1601729884786435, 0.3910974461444844, 0.32391876753768384, 0.10206785038359269, 0.16482686078209607, 0.1244102250368914, 0.139066736452951, 0.16092514540011207, 0.12301356563559877, 0.40226722785913643, 0.5969265734514443, 0.14452561938271377, 0.1326662539160785, 0.08203080576829747, 0.26058145455156434, 0.31757386382248626, 0.1376645442399118, 0.260469078041973, 0.5551690920576366, 0.07525614664878906, 0.12157566988919652, 0.1286713015083235, 0.17461005124549808, 0.12737452338760255, 0.218754083366233, 0.27837790200808465, 0.24364696914155157, 0.17943780455658134, 0.15662081452902663, 0.10148267995844083, 0.1773919635809807, 0.142309397700504, 0.20879464829732247, 0.5826396206015277, 0.10310707854132077, 0.19275629174668815, 0.12561779078906454, 0.229316386120148, 0.14581338049562567, 0.31266187512107246, 0.2677220562050985, 0.23993117870691888, 0.09890282105313984, 0.10833384491873228, 0.12698162520449408, 0.2565375014033751, 0.2761391465363861, 0.22471476180958863, 0.5314418158689026, 0.3435021410096653, 0.1559446099613371, 0.21796037653642808, 0.19020682807568448, 0.2055327924374334, 0.16480901651690294, 0.2134484330144414, 0.10367952038339448, 0.21552947137543502, 0.23341051433776622, 0.12240515430412592, 0.1279273212911659, 0.27928825241191796, 0.09847614592896509, 0.11878173832791365, 0.4472553668959312, 0.07006465822963187, 0.09456309397985267, 0.1812572458008389, 0.1085919073564805, 0.31689313663313395, 0.3282239152287181, 0.21883020937772235, 0.1385777254006806, 0.26865056615661004, 0.44770255158096167, 0.23295127933033263, 0.2964151111834595, 0.13320564194239412, 0.15722278479748497, 0.23072609749852108, 0.1997083553184589, 0.10418137569484372, 0.3589745090621733, 0.12037644168237269, 0.43932456271698406, 0.1027988616143492, 0.1199827077049256, 0.28241515294431585, 0.13835570205053813, 0.5138581379997457, 0.24782777414151894, 0.10221497759759625, 0.4766328466266526, 0.2545601562514984, 0.17839158090938148, 0.09350328083744411, 0.24015209128152612, 0.12642354930335206, 0.11354362867996551, 0.2338009074148294, 0.13900334691669564, 0.10454561291648316, 0.11037721567075684, 0.11765510990885365, 0.16241928446474901, 0.2545601562514984, 0.10322845290783396, 0.17958322098621143, 0.11344120504772444, 0.11972113431267993, 0.17958322098621143, 0.1586121994419859, 0.06674274123860609, 0.34511774197955697, 0.15881320044538988, 0.17312496916901804, 0.28120997978822504, 0.2083862252924865, 0.10310707854132077, 0.39308673434576735, 0.4558668842697143, 0.1100939235890717, 0.0862046809540088, 0.2754764103236194, 0.5314418158689026, 0.4200276429469, 0.10790197627165804, 0.12365884480404388, 0.10579200221914888, 0.5083065896569623, 0.07520437176025813, 0.16448053809958466, 0.08368118926304269, 0.25484245964348085, 0.13167831873788743, 0.14359340812884025, 0.4569187797230005, 0.15810780462859617, 0.11327394526945142, 0.1837721899660092, 0.19588102593282647, 0.3429844992164481, 0.35861765893170094, 0.12794052357764807, 0.21718245550485876, 0.24327343407276872, 0.16402192492725726, 0.10112374877604385, 0.16620403739204068, 0.14796893034616782, 0.4585533478018697, 0.3278135480823037, 0.15224355034122025, 0.4443277554775622, 0.12036079392431344, 0.1548580589179297, 0.12313292928609439, 0.1939696314641805, 0.10540987180352147, 0.1616864808695892, 0.22856126235485005, 0.21865366184275672, 0.2649854388685104, 0.09193675507075408, 0.4058571609763194, 0.25864730165846445, 0.11996219517879972, 0.38249980760810287, 0.16373412907889964, 0.3109211313357166, 0.17369309631267413, 0.19048172231532068, 0.37231168483921584, 0.11053275326922495, 0.36512579217477625, 0.16331562159735447, 0.09521560461187512, 0.1001397986295591, 0.1714679716334633, 0.24166170069564513, 0.2124526763182716, 0.4752066234932505, 0.23358715825904355, 0.09642795893828744, 0.11749888388515593, 0.3956734853853562, 0.10342294427473343, 0.21149286418874427, 0.13320564194239412, 0.1888951909002631, 0.12610334031831216, 0.20571255221826346, 0.10488552018211858, 0.4852507857112873, 0.10375176796044487, 0.24650616897521277, 0.18088266024173774, 0.36472255798183706, 0.11975129184059481, 0.08477084225226464, 0.12509437142092084, 0.13442477377401418, 0.11218739340785713, 0.15770910499769653, 0.2633143834249019, 0.0925605755522954, 0.2742898699581737, 0.3578845230604242, 0.3743502392969324, 0.13629518427402074, 0.41328971232876266, 0.3086454873738882, 0.2389498108543505, 0.14363057129755666, 0.1347778865873464, 0.43707202807077333, 0.11017332950351995, 0.0903371204209426, 0.16354850674098415, 0.49768031955357056, 0.09934590479581389, 0.32145963035144987, 0.20879464829732247, 0.2742898699581737, 0.22721060578403035, 0.4526392945894182, 0.3465242472342536, 0.10389713484318158, 0.12616820011438357, 0.3086454873738882, 0.5270810813503652, 0.11488279617808721, 0.11998670432493913, 0.10310707854132077, 0.09599896527415383, 0.3521635766322648, 0.1942446872505352, 0.32432176608603314, 0.368862213542907, 0.15352945979687285, 0.10594170950778486, 0.3265179164782485, 0.1368826947233112, 0.1898762723080338, 0.10256043668588904, 0.3078488777469763, 0.13796577792790043, 0.11773102547480517, 0.4932812458802865, 0.08889691291456511, 0.2412938330566443, 0.10441786998227749, 0.14313297212100165, 0.0920597191215713, 0.18018257575696564, 0.17433305715599173, 0.1491752455929553, 0.16303853067926363, 0.12066379177317037, 0.15861521181035462, 0.3371841051764852, 0.1882129646964172, 0.1417215599326772, 0.09736757044097244, 0.12611686648051934, 0.09016307917490549, 0.12219392924377598, 0.372915674668245, 0.24725300841016914, 0.36982275975943435, 0.24554145855631432, 0.1868032239518041, 0.4258808666012345, 0.3166923344997225, 0.12769384230186398, 0.15522153051118312, 0.216686877845891, 0.12011102616788819, 0.22608417137823095, 0.14983538662545914, 0.5483662592968324, 0.17933928333685983, 0.28957707033433583, 0.26751972259621953, 0.11412609579908335, 0.1261706405208293, 0.12839933692155533, 0.3139765233996209, 0.17030182097738594, 0.31417137950998797, 0.27690793793529284, 0.26094949067192214, 0.16189405576493912, 0.3465185441340221, 0.14371779737868975, 0.13524903013571424, 0.216671821179832, 0.1033674419171121, 0.265777089564958, 0.23363007371699102, 0.28056707205223697, 0.26717832296254607, 0.18825621049065935, 0.44375932588967876, 0.4058571609763194, 0.1709238567954358, 0.12445930545782832, 0.10523514557129285, 0.22441724329226198, 0.42728570986746145, 0.25682084784658604, 0.16563994592251455, 0.29396212925077764, 0.3245423817399256, 0.08855903189075788, 0.4283588012623083, 0.336920206202104, 0.2018801035848693, 0.1125702018813443, 0.10364819142834113, 0.19213824960402484, 0.155819941317375, 0.11431052211864559, 0.10828499736699779, 0.1487493150868313, 0.31564904927335247, 0.08100185580009993, 0.08288460097601026, 0.17192751646031457, 0.14730804055553223, 0.40226722785913643, 0.10863141009989198, 0.12839933692155533, 0.3465242472342536, 0.16406406252217084, 0.5602824362477258, 0.25868264540622754, 0.12455645727500456, 0.1161389848583252, 0.33873713495457314, 0.0689702877943324, 0.16981259469574655, 0.17543173253588332, 0.47126840789260654, 0.1381682154668417, 0.1520071890857214, 0.3300336757725083, 0.2544991382155929, 0.14231297869092996, 0.25682084784658604, 0.334635941950072, 0.10346526015057979, 0.15086571574941032, 0.10937092236782193, 0.10570315715810842, 0.1927191001883356, 0.14451409457957204, 0.10268369482357752, 0.216437839805915, 0.21273435829738924, 0.2190283229289213, 0.1935380387346841, 0.09994766498180994, 0.12752608747809344, 0.13031529666917416, 0.1862974600830514, 0.09203925791624458, 0.14644726240443823, 0.3885143701180209, 0.15021686903802625, 0.07822633913960596, 0.2964151111834595, 0.1353752407260312, 0.15669036346301268, 0.2546071332826994, 0.12728025453600836, 0.17856067566388711, 0.4282273958583296, 0.15153305536264508, 0.5349080767805885, 0.1348637748213185, 0.10275591767579739, 0.12898506828315567, 0.12011102616788819, 0.26661609769323696, 0.27806398087077133, 0.3534839636918986, 0.31959468358200993, 0.13310713969560056, 0.07750286843489666, 0.312025862547455, 0.1560296480676719, 0.12708120305453033, 0.14145230792270483, 0.14933108681501195, 0.11310571523144552, 0.10853258534321776, 0.17083324128383043, 0.08332265292707043, 0.16316288311390342, 0.24700069110091258, 0.25382286399113385, 0.0785890835740841, 0.10847067244837683, 0.1909791146179347, 0.1384270873916204, 0.2550999827933879, 0.5046257480540519, 0.10156083574035031, 0.3633838894286927, 0.27583999091674016, 0.3061209297963733, 0.15723161823115892, 0.13818624659954742, 0.3023524208784979, 0.21449497856341934, 0.3405580685055325, 0.10461915925094623, 0.5602824362477258, 0.47628774386997874, 0.11957287652060754, 0.16613241871701798, 0.31707783305547976, 0.09606532404482344, 0.16729825962974132, 0.22682360197480614, 0.27320876456176363, 0.18395985512074414, 0.4438598537778629, 0.32916598789375034, 0.30855859267823765, 0.11255215038039128, 0.20958607856168593, 0.32916598789375034, 0.314928694999268, 0.20135504208323932, 0.114737171583975, 0.20539502569757082, 0.17445510089128896, 0.07539562661683614, 0.16612764275022351, 0.08933648337898929, 0.37124262347109, 0.11872660436746661, 0.25146928096380783, 0.08481926145607271, 0.29551189792384686, 0.1168303038262099, 0.20580921001561417, 0.16784052096096594, 0.16369244454205567, 0.3193058884873403, 0.40819376425845283, 0.4720297310623336, 0.196880678140837, 0.12200289241689771, 0.16487869490686086, 0.3006135417004323, 0.47628774386997874, 0.1370501245802814, 0.12429418994711201, 0.14277058162994627, 0.30135430586563017, 0.11322162570846117, 0.49768031955357056, 0.2389319999399107, 0.2694081700164957, 0.1544910540140634, 0.21335554269315707, 0.14023795071317366, 0.07539562661683614, 0.15814941682506273, 0.1025951361098519, 0.16805722824772737, 0.411519446848804, 0.14394716268101626, 0.16139941139364933, 0.2735767610290603, 0.09086364031855824, 0.20111549702565593, 0.280489543578347, 0.24221020183119793, 0.1439686388972029, 0.14532079640709747, 0.09914788285593798, 0.1386816931500561, 0.13012608788140576, 0.3371841051764852, 0.306786054029788, 0.07273673537049907, 0.09684687873478307, 0.2964151111834595, 0.3203013231528215, 0.26320132237422555, 0.11053897734408227, 0.2901278843879179, 0.1096997690166597, 0.10435723328983615, 0.2514724460199339, 0.3980825468645885, 0.1836055565669742, 0.18236638729095953, 0.09297892408893238, 0.13985701473128662, 0.3435021410096653, 0.17585212513818066, 0.18604729936904907, 0.22993274748753617, 0.12944668860265063, 0.4821150845364189, 0.09076829145911185, 0.14790998651145662, 0.11325814489509493, 0.09393239613800596, 0.1502282049597516, 0.30235820094619276, 0.5204964090717461, 0.15086571574941032, 0.30425207576502267, 0.2912714477529313, 0.1791496477219438, 0.12903229957533377, 0.1521629980867414, 0.28201138429753725, 0.5258148083405186, 0.06542696524042436, 0.27745881682147067, 0.18465724899614636, 0.2904500756259928, 0.200454173395215, 0.21855487414314123, 0.13733784970228968, 0.4664999971555522, 0.17776513049651166, 0.5080734022390574, 0.23605299122977816, 0.2966788434065093, 0.09185683949026045, 0.3688110067002457, 0.13877713849048215, 0.1064070003846066, 0.127222377069857, 0.47956090895636627, 0.12298713468079968, 0.15338328313602095, 0.28613832799421873, 0.3465242472342536, 0.5417741479023678, 0.5969265734514443, 0.11933375259602527, 0.11570955367961017, 0.37231168483921584, 0.0993935428409351, 0.37231168483921584, 0.07154757210648885, 0.13023150262884123, 0.47126840789260654, 0.15452565534827215, 0.27589463345424653, 0.2569247683646706, 0.5170530606982461, 0.14533351747894796, 0.4930594749566059, 0.09919814096714398, 0.13099323311567798, 0.26501541410777957, 0.1110327645898272, 0.1442554665135565, 0.12097183867098361, 0.11435809350717854, 0.21734851398637448, 0.19326166021858857, 0.2703737487257573, 0.2247169050312979, 0.12954433571229934, 0.12997632469112302, 0.15388277442433793, 0.0783501906285211, 0.14674145890952664, 0.22725255702273067, 0.13972650180198867, 0.3283714919365593, 0.17239146377026648, 0.1325458685766654, 0.2964151111834595, 0.10778201746377881, 0.15087550328830512, 0.19955031322316935, 0.07508282421874665, 0.13122590492523487, 0.5826396206015277, 0.22334601286668607, 0.07811164247894342, 0.3980825468645885, 0.17791798964723005, 0.15442711719416605, 0.1278245074655295, 0.11097413979346527, 0.08391138806338543, 0.15264422168332162, 0.3712557105866279, 0.20879464829732247, 0.14334285393104482, 0.20867142576214096, 0.12643600329362292, 0.1631272510605139, 0.1545512821322232, 0.15674097567923337, 0.14113235077140956, 0.5258148083405186, 0.24846672622690685, 0.1840005200127734, 0.11625050503886492, 0.11420773168360641, 0.27334470187871274, 0.14678620487026092, 0.16620403739204068, 0.17059739701220888, 0.23002306670495368, 0.13798605258182808, 0.12898506828315567, 0.11376603134061097, 0.24758080911818495, 0.2394737195323176, 0.40270825147038225, 0.06911174922135276, 0.32238513608371167, 0.23599175714618825, 0.12218152418473387, 0.11645210186927235, 0.09773884522129349, 0.5417741479023678, 0.4481867062458328, 0.21905825970433407, 0.1240037493666277, 0.24243885416449512, 0.36616285549728145, 0.10840390982988543, 0.2311429331127208, 0.14025270677650786, 0.11216687785492707, 0.2837464594281524, 0.2762680884930708, 0.12942588559707421, 0.3966531801024691, 0.12898506828315567, 0.3752164853344754, 0.11498348492822369, 0.10982795376037738, 0.26984164590439436, 0.12416106298980398, 0.3232435623716124, 0.1829243512146174, 0.13459459633931098, 0.3393311061472205, 0.24202058915274063, 0.14276684690026434, 0.3494751432804876, 0.12757653127565338, 0.25452473563391464, 0.08878622712626592, 0.11681250494636278, 0.306476629936669, 0.23168324434006754, 0.11799141628176299, 0.14071234794362786, 0.10600686400007313, 0.1775194725187887, 0.27478651374571783, 0.30273099905894535, 0.2845025981882845, 0.1390614213308357, 0.3546457424999859, 0.37902771421483644, 0.1617435820624036, 0.1195105541079056, 0.141713842368007, 0.4541845434012721, 0.1663833407973478, 0.09391884974721301, 0.13934414866246958, 0.13945592487446196, 0.09162313648393476, 0.31272877225002266, 0.06542696524042436, 0.1485335502566015, 0.10187284774357017, 0.3232148745156605, 0.13199137737646865, 0.09719092519322227, 0.13554681778706248, 0.30577918034919077, 0.13029190674776428, 0.40741874957385416, 0.12078603971535154, 0.11033552255455534, 0.5258148083405186, 0.18474473767916091, 0.25665968275023143, 0.2534186399697526, 0.10167725795706195, 0.37231168483921584, 0.412161556615455, 0.08357473460391661, 0.22409423778763082, 0.17259069824249157, 0.20796163135943393, 0.27837790200808465, 0.4340317981245996, 0.14139628896456755, 0.1287364558282362, 0.3232148745156605, 0.2964151111834595, 0.1336207756286125, 0.2691625383985402, 0.095278178454963, 0.09527141004598197, 0.3232148745156605, 0.30172003147549253, 0.3240347122797157, 0.10074600272360933, 0.06938108074349274, 0.06691403405045088, 0.15531111848643872, 0.1492085927291411, 0.09608996675499998, 0.35687776576971236, 0.15766820689043212, 0.09030059942743848, 0.16816782126979363, 0.10294863664756414, 0.22201695220484866, 0.0895780081334991, 0.33362105261670577, 0.08859712110725332, 0.34161793941920365, 0.5612080564256602, 0.09863636820977455, 0.3980825468645885, 0.17001163798861832, 0.1394209399940562, 0.11137750853317002, 0.17610725740596075, 0.12194475747345992, 0.15798967347789145, 0.2645457898847371, 0.11165262273220086, 0.1458800731628892, 0.27932671226265, 0.24157036471568707, 0.3521635766322648, 0.0982409428640453, 0.1235291055014698, 0.11730815183960591, 0.3232148745156605, 0.2142884525404545, 0.09598437103858852, 0.09469972357874386, 0.4423618321499758, 0.3042042404864115, 0.11975917408116565, 0.08851912553805039, 0.20869646399509303, 0.17578334038489885, 0.08889691291456511, 0.13177678334119883, 0.20943881060587968, 0.14810551112198794, 0.15733529472232188, 0.44162689695372814, 0.07136532512410022, 0.13418902035998695, 0.1040573490457335, 0.18516060162204176, 0.30764011354486365, 0.20547226981014113, 0.1891014921043064, 0.2755858887031001, 0.17229216889965496, 0.12963247931769478, 0.12996442993765475, 0.4144509534274268, 0.176446580501251, 0.35861765893170094, 0.1161254086285511, 0.5207292626501334, 0.30840561677581146, 0.2775530037248737, 0.10056127071245137, 0.1296247012553058, 0.47628774386997874, 0.4212156156374531, 0.3300668045879973, 0.12323266790443266, 0.08611313426155529, 0.15026454718845975, 0.08196006078436352, 0.13753906293385595, 0.21142077797777126, 0.14396035779297442, 0.4383452973631925, 0.3678864297608493, 0.4362408222759337, 0.36266221909392404, 0.17239146377026648, 0.14850815465876602, 0.07373496161675887, 0.41288043601996516, 0.29193928152785803, 0.3449010680406993, 0.08746511649369433, 0.306476629936669, 0.18175161639543122, 0.11102889584582638, 0.35861765893170094, 0.11975129184059481, 0.14319352073860786, 0.14064566031577105, 0.20105088358768264, 0.167451650554003, 0.4282273958583296, 0.13829550956717226, 0.10884076277505868, 0.2651259255872486, 0.14526872984070557, 0.4954417852973533, 0.15393773029469146, 0.3826222512126152, 0.1616864808695892, 0.5349080767805885, 0.18954924536769893, 0.28054366041724904, 0.39491641435334457, 0.16407656163790305, 0.1867948979505076, 0.09029809267628111, 0.09786007082312076, 0.11260435952811507, 0.10348064024604832, 0.2064921446457251, 0.08856882948370004, 0.2904500756259928, 0.343220293358673, 0.21261410646201562, 0.10056383480825007, 0.14829259227324876, 0.27796733107526744, 0.15391115979710368, 0.12956756724903362, 0.08315360171954402, 0.2704667947518811, 0.25388193310745316, 0.17852883145480566, 0.3590079023124971, 0.08634667595257937, 0.3332751044368922, 0.32916598789375034, 0.17472018394719624, 0.2987604493775023, 0.07632591512034964, 0.12461811473996585, 0.18396802492770117, 0.15065129108240072, 0.31757386382248626, 0.11322165820904534, 0.11167315481668447, 0.23541305568079313, 0.18607275675724513, 0.10956941656102841, 0.24249995267559704, 0.09055530083976668, 0.14529076272960284, 0.07211671991851422, 0.24761112471522176, 0.3265179164782485, 0.20174267945642238, 0.07885232556276786, 0.28527307204934255, 0.1345287920424918, 0.47126840789260654, 0.1667296268739098, 0.11376598291647669, 0.2195697046224343, 0.26439742066657507, 0.10452324021468466, 0.49090156794929496, 0.0789659394252911, 0.12776521483493228, 0.18675955266067712, 0.1752392218410212, 0.13525667568083435, 0.11910113211228213, 0.07951269173947192, 0.10148267995844083, 0.11737328268985599, 0.14918113992508197, 0.21587261256323645, 0.2619052839404032, 0.11330031501266731, 0.2669145448801206, 0.0898713826276284, 0.12315237422282631, 0.18788091921552486, 0.21885155738363987, 0.1499789638311816, 0.280489543578347, 0.1810274212914098, 0.15889189746069957, 0.09388237403191096, 0.24213623113192792, 0.21851657602418556, 0.23460796972684195, 0.49614867772793, 0.19270659123628972, 0.2347690431708053, 0.19508507843781941, 0.44511935562632576, 0.22226342971725283, 0.2079354886248429, 0.07861562383630043, 0.15003780211726014, 0.39812988900291557, 0.1297829502392068, 0.35182698255662737, 0.1936095626485989, 0.2856145428331942, 0.06812187930508513, 0.10478338382393143, 0.1691585686433084, 0.1409115107937223, 0.39483085546694907, 0.14185890853918381, 0.1324640417473858, 0.16124685306529873, 0.2421117440466244, 0.2222179371346416, 0.09384583498767482, 0.2348844295843429, 0.3890406694181111, 0.08991840123130475, 0.08705729188569167, 0.12352301439292611, 0.12278847629526544, 0.4434897235906067, 0.27975584120105057, 0.2456875884919226, 0.15693021365965523, 0.13944508960635474, 0.35021874779122436, 0.3169208908232921, 0.10409092978184484, 0.13115486536002663, 0.27130822881115524, 0.09160080411656357, 0.2909375266535611, 0.18836058336606712, 0.28442183923896075, 0.31501977721582947, 0.06812187930508513, 0.12929932416364248, 0.14599861562079527, 0.26805209562837384, 0.07545923250452587, 0.1592392014838666, 0.1689418304332715, 0.12519682267606694, 0.16262012383487998, 0.1896782736788494, 0.12127025444714368, 0.1371114369400081, 0.09369782655536027, 0.20207005239831877, 0.09160488824395716, 0.13620127224544468, 0.1575870621422107, 0.2566691520774553, 0.5100153713699968, 0.17378626185049936, 0.42514497155478803, 0.08391300212534504, 0.2801205853620301, 0.12794320144340393, 0.10523284244107653, 0.12547696009394935, 0.14505576184731983, 0.16190717173828828, 0.12414566150079187, 0.3144340513922828, 0.23854142909265308, 0.06983118436908042, 0.15995267186384388, 0.2856145428331942, 0.25560538233297747, 0.20827982555302674, 0.11606667441149279, 0.48657932130012904, 0.11918171179467278, 0.1543394836929441, 0.2780894093087898, 0.08911049545627839, 0.185664458214962, 0.12499731822679876, 0.1296891353190815, 0.22365132736914897, 0.09075366810935323, 0.17280733384619398, 0.13031179499719456, 0.21041800387460252, 0.4527211344030608, 0.19911213761026586, 0.13354580701964147, 0.23952728085640143, 0.2704495615140521, 0.4448693291929244, 0.14849119787084009, 0.19866130971858714, 0.17973339715012368, 0.10370891120851458, 0.11875258326820312, 0.2795632622932538, 0.09304634480374117, 0.07210016122179097, 0.10947385325730224, 0.21489074883166526, 0.11737702039134561, 0.11621674137799984, 0.11801635589855373, 0.3553634613322977, 0.17066045362828416, 0.1258227868946064, 0.5885439345133991, 0.16615796593600318, 0.1819832276565875, 0.13280075112947148, 0.13145524292383032, 0.2880466849866186, 0.2020362677598787, 0.11607622352648914, 0.3268308336877969, 0.35617911075951186, 0.15453712055128033, 0.4994699424305189, 0.11529746844059223, 0.17069652250781375, 0.13391768457190206, 0.15853364529677735, 0.16660756108241975, 0.13008672260946688, 0.5017141832068157, 0.15865278252031786, 0.10322251266128679, 0.13280075112947148, 0.17482750432220565, 0.1302388782829011, 0.07168771301956509, 0.19665959013773793, 0.26367333374209884, 0.39847329836837553, 0.20261143188283282, 0.4582580923865728, 0.18565664043901023, 0.16524147896498625, 0.14110959690102606, 0.15024205039628188, 0.1653909724155355, 0.22969734864875638, 0.13236851628352625, 0.20571315538899418, 0.11736315035403179, 0.08239166430583025, 0.21054265699867117, 0.07058831692865238, 0.1722321539198751, 0.4881048915512455, 0.2330494748442949, 0.27236299516499435, 0.12299488891154084, 0.22221730835101822, 0.1988018243317383, 0.07975540496047002, 0.13341069973956116, 0.2638030787320643, 0.3068209215124504, 0.13487759045033343, 0.3173101023494201, 0.203125002303072, 0.1277458072618242, 0.16581703539184933, 0.17359357056133337, 0.19957228261965687, 0.43115975133570195, 0.09827836992663631, 0.11190627162291039, 0.15358150997027023, 0.0981659276545292, 0.11395352014968116, 0.11075117451847129, 0.10457027756519507, 0.08088733505145292, 0.127773790190064, 0.2087416762107568, 0.160520517163715, 0.14642867677987412, 0.46971185732875115, 0.12081744595854191, 0.17378626185049936, 0.3156365605990959, 0.28601044164123773, 0.15264710102041446, 0.3189203456885571, 0.1449133217310125, 0.2549285377312981, 0.092200369121201, 0.23210531632013964, 0.19926648140667527, 0.11341314656534854, 0.40262768397274834, 0.15752306398607432, 0.12413531328476, 0.1620392161522196, 0.14935707952771468, 0.12569491070753455, 0.08105145563757957, 0.10182105179164819, 0.11480094269003187, 0.15926596330265222, 0.16965022660643153, 0.3053581777251496, 0.14811388750515264, 0.25364787339620976, 0.12249065769120115, 0.12064747912025234, 0.20629230463153547, 0.11017064147379188, 0.17948196626090338, 0.12021925630236688, 0.18494637927445903, 0.15731765961008468, 0.32690983093216225, 0.11967182376191073, 0.14322384244390818, 0.13280075112947148, 0.36381330422091945, 0.38868051547503185, 0.12587305684473868, 0.5043540875596271, 0.10600741887158323, 0.5367121421613151, 0.2634322940046255, 0.0764538818804806, 0.2838001491125773, 0.3940236048405577, 0.33987886620612884, 0.16504938727315174, 0.2972809594133291, 0.21315874741543153, 0.1592354902159584, 0.08293645501623927, 0.3603341132188136, 0.09421993618816961, 0.11050815167056062, 0.26258933619853486, 0.19570494564859284, 0.5100153713699968, 0.11681653603110118, 0.1620292187168298, 0.49602160789905725, 0.3619219421007435, 0.25367309744803374, 0.1357069049294651, 0.13269333022904958, 0.46119103071684997, 0.23999193462135016, 0.10840931555593762, 0.3180663309507718, 0.5902400901295125, 0.12386822959658116, 0.4299247008604986, 0.1239178324984607, 0.11982441892041036, 0.12539500655724165, 0.41686937744001196, 0.26900665339720703, 0.24255678537731357, 0.149766858258044, 0.2240273117914997, 0.38827257355613237, 0.1293058490141934, 0.29139769567610724, 0.09523018463665961, 0.09783494907877839, 0.1037085579272017, 0.2522441779060424, 0.2152994350933638, 0.2894861224021739, 0.14515162842310814, 0.18494637927445903, 0.22441799544238758, 0.09878671060389346, 0.1427670752272205, 0.2817822905972473, 0.19375959830365028, 0.06812187930508513, 0.07724885743712281, 0.29774803529721516, 0.07901262644541485, 0.10807167402225269, 0.12675855389341203, 0.1562809394807849, 0.20571315538899418, 0.4434897235906067, 0.09294812815217483, 0.4254436438595713, 0.25442533237217113, 0.17037661787834302, 0.23496050815953523, 0.1665068260485499, 0.5033548833113098, 0.11206723208260552, 0.12000131657738898, 0.19742779159481808, 0.09941510792348167, 0.13790826217482985, 0.2919987943013182, 0.11317637662957268, 0.16322156611618502, 0.09400643431398086, 0.4599179004108906, 0.18845124201543195, 0.09758198746735905, 0.09018878508833497, 0.39103749826493384, 0.3556560717848784, 0.20819064568712492, 0.1216606198223582, 0.11280331649186827, 0.10269226850340671, 0.0846624892345055, 0.27236299516499435, 0.19300230330383175, 0.2036017257143646, 0.11454347831873808, 0.1262961680011879, 0.15261362908025927, 0.17428477409395834, 0.18737551772476935, 0.2817977775784351, 0.4124660297265646, 0.11419373940674021, 0.2121749146586377, 0.5885439345133991, 0.16697101717905485, 0.34781461956774995, 0.2716878092367754, 0.18675675466727804, 0.2485650440263601, 0.10725679061768062, 0.2549285377312981, 0.2863230666627077, 0.07788440602955464, 0.20503077273942877, 0.10322872255670118, 0.1863132270941301, 0.13815400909869224, 0.10969718858324627, 0.26932994432416557, 0.07172029258747917, 0.4083715306619623, 0.3079556271213467, 0.15017527698174823, 0.20648192807251023, 0.2585217634083195, 0.13019973808741134, 0.1081031115962319, 0.11982441892041036, 0.19368229365040696, 0.3102161882745255, 0.2907791507006063, 0.16792770550731917, 0.21335495022995785, 0.1784540209134269, 0.19123262698450882, 0.09094984172882872, 0.154516532968974, 0.11513186357112705, 0.3454739573157477, 0.3087184603114769, 0.1342444919650249, 0.12329618039637004, 0.2768133385992767, 0.19595262237603822, 0.24740406347437097, 0.11419373940674021, 0.25477470651404854, 0.1546734356519963, 0.1342444919650249, 0.15307437465219628, 0.07784097053201859, 0.19032116245657552, 0.4984674638411464, 0.11126444375445618, 0.2539146164388909, 0.30574648284317624, 0.1021414012459412, 0.27022686886058694, 0.2825560274535754, 0.2430294235121295, 0.3184400813767264, 0.0746990914061608, 0.1475362114606862, 0.19061943028008355, 0.19713500339170306, 0.21218016054084984, 0.13433116057897213, 0.16026547940021954, 0.11044172621106851, 0.20365862568522242, 0.13811950100290837, 0.23273129933625972, 0.11602963820202838, 0.15425096135253688, 0.1047380742313498, 0.2693014209198437, 0.10151810795925559, 0.25093084500623947, 0.23031630232265954, 0.12104167081543722, 0.1123626004253122, 0.3156365605990959, 0.2620996713483685, 0.23749862698561044, 0.1053943801532619, 0.10336681247613326, 0.13605428332487177, 0.12683775212921636, 0.14615681353330973, 0.30413828752622935, 0.09981134704104383, 0.12444282179362116, 0.2376914409631586, 0.17466462575292038, 0.07535740396829399, 0.4977177948963284, 0.2586194764056647, 0.1532477972883921, 0.14826107762471752, 0.08998898618294403, 0.11253151186720135, 0.17811489393869845, 0.13872584989119194, 0.341822376631725, 0.18125738058132385, 0.15460607153255465, 0.14942952673769103, 0.096059571467235, 0.1709827447044503, 0.10726503970763951, 0.5300961204343363, 0.18817893608249908, 0.18571297792739974, 0.4434897235906067, 0.5100153713699968, 0.43363725182000284, 0.2449831205264832, 0.1523061526448508, 0.10560651047141005, 0.08254045506814245, 0.1074574207737854, 0.2874315303446772, 0.15922996241361553, 0.2125406059133447, 0.4527211344030608, 0.15778822423792363, 0.13040306248167177, 0.21639925052497197, 0.20571315538899418, 0.25082219815144546, 0.17802559688393949, 0.10835017923016699, 0.08489526021576621, 0.16305003736895926, 0.28130484349458607, 0.23154245487762792, 0.2401756830000911, 0.26884493451731567, 0.24175234246839766, 0.2077796105799607, 0.09511575247093425, 0.10446835870572804, 0.16073804262737823, 0.07172029258747917, 0.17564832454876367, 0.17083918125440783, 0.43836002099573296, 0.2076644735807904, 0.14846914515543952, 0.1478501973568104, 0.11833394317162765, 0.160520517163715, 0.10264058291884016, 0.1081031115962319, 0.22196354012978586, 0.24546423054796165, 0.087699382461065, 0.22837399367788352, 0.10157148500826724, 0.10581252025361218, 0.14528617101322155, 0.17222753066595337, 0.31681225132366514, 0.23004847498049108, 0.1577204382842094, 0.13809742175205902, 0.07392143992795794, 0.13625586357835098, 0.25879404187889105, 0.3326974678263001, 0.40880390306691, 0.5267141769173918, 0.1869211228809786, 0.11982441892041036, 0.3379594934184062, 0.12351973308655777, 0.20388288549473446, 0.11815610389800496, 0.2809548916977507, 0.19037100099597204, 0.16470776569025558, 0.2909375266535611, 0.1447094718591424, 0.19930980871933265, 0.1694635482021424, 0.49614867772793, 0.26180353278109914, 0.12753049579311979, 0.3124938091186554, 0.27192428752675757, 0.18425338889375006, 0.16270266207176437, 0.21425291954074882, 0.1868455439842933, 0.16535165654448392, 0.14188647447401165, 0.07710053562192692, 0.2593322436760958, 0.20604150414397965, 0.17421766112835527, 0.12920193991651213, 0.37649843547059725, 0.5017141832068157, 0.19595262237603822, 0.23196262691173264, 0.1338536463312682, 0.3032805572037975, 0.3999221407776266, 0.4013179746050916, 0.116773691329484, 0.06744062977663694, 0.0746990914061608, 0.15966124004631133, 0.2867590281250579, 0.3681981240930328, 0.13417531598555876, 0.1489462564737574, 0.2794088808046352, 0.2533089103220052, 0.08239150573268962, 0.41969814667967853, 0.2156257200022036, 0.14475253615220843, 0.1571744199405049, 0.5267141769173918, 0.2367174719929666, 0.24336574094928237, 0.19655612607791603, 0.5002196222126256, 0.3451313517249156, 0.20960643726014186, 0.23108290341444587, 0.16124685306529873, 0.2652805370739543, 0.13346047162341015, 0.3299735603937227, 0.0959960705087827, 0.2696191211097407, 0.17886930601569964, 0.3590045915297311, 0.13518870288870957, 0.22023983442209913, 0.30198332867631034, 0.4371283573947101, 0.2606794463098729, 0.11253151186720135, 0.15889189746069957, 0.12810544889464784, 0.36684611098731035, 0.11700041784912457, 0.15065481325721294, 0.22111792023797913, 0.0782624392988801, 0.1706088336043768, 0.2817273902172415, 0.09758301684667366, 0.3940236048405577, 0.11982441892041036, 0.30416174607268953, 0.18073673717676575, 0.11807150184614619, 0.1563333018345562, 0.3978862730482559, 0.08069825893857789, 0.11918171179467278, 0.14206427250550852, 0.12062975917205057, 0.11273372452420677, 0.20978579778676676, 0.17999253779718782, 0.19743625576995485, 0.4497028857110984, 0.19375959830365028, 0.09670502083875557, 0.40927970269548936, 0.20359565419331566, 0.08264121273815798, 0.11890804831783107, 0.11833394317162765, 0.17429255048902667, 0.11099242771957603, 0.15774343639440394, 0.16162483491766888, 0.12064814743691539, 0.16678926166741653, 0.2164037061138848, 0.08828894997850364, 0.2584259314173446, 0.19409794422988508, 0.22585370724062262, 0.49614867772793, 0.10973829059448544, 0.3723281979650825, 0.28427732707448505, 0.07210016122179097, 0.23356792961777104, 0.2237173006471863, 0.14060541789320852, 0.11731001983129649, 0.11521031049208759, 0.09816098711654932, 0.401356808694415, 0.15104302513033005, 0.31556300521709985, 0.09986310004376409, 0.3311433065112719, 0.11890804831783107, 0.19653833194495515, 0.1539688365027535, 0.11291725709529292, 0.2872805528949249, 0.13241697870466457, 0.09973447364891845, 0.22198611810574914, 0.10976044577141214, 0.3503989697090021, 0.39483085546694907, 0.09011487904635501, 0.49025183991330656, 0.15547137962444485, 0.24431305630575473, 0.2869459255543943, 0.0782624392988801, 0.14607847665187804, 0.11835534952177171, 0.14274028762043484, 0.12406891621205135, 0.29914914060058523, 0.07824485522143199, 0.27669663531899497, 0.3714751106120162, 0.27101769535511794, 0.20018463005833625, 0.1761138395462053, 0.12096535773402435, 0.18498018654503148, 0.0887938765959192, 0.13104658658585347, 0.43836002099573296, 0.2176733865362703, 0.2584524294026456, 0.17809458889936078, 0.29243901105609504, 0.24876438583637087, 0.11011626219741509, 0.39600480348605926, 0.10457027756519507, 0.13237663803502953, 0.11273372452420677, 0.17031534119641098, 0.26148477625210936, 0.13783808092687042, 0.082510520988824, 0.11916363053173436, 0.1292149243757901, 0.20347922259024226, 0.3398289514948717, 0.5245315876744738, 0.19634321018588705, 0.10179180482724663, 0.2821054695109588, 0.15915032260393033, 0.10796255183364681, 0.13433116057897213, 0.29568906998686234, 0.1180372004686179, 0.3032755029994092, 0.1598200170237885, 0.1269186857289371, 0.31122939365925056, 0.14850630473205959, 0.2735396336250678, 0.5267141769173918, 0.15553477583956993, 0.27302539021569294, 0.13550331342027933, 0.14142121662372448, 0.3947411578918653, 0.1515376545272762, 0.33714863226344527, 0.07309835494302722, 0.277675524675338, 0.3255162044692349, 0.17373993539659863, 0.32522188451237743, 0.25197637891062696, 0.44640602820566533, 0.2521052161803226, 0.1917006668511329, 0.07141462598745797, 0.12126341725833, 0.2919987943013182, 0.12470193861837846, 0.11232162140241927, 0.14668223130573033, 0.139605623806763, 0.2840597660525427, 0.2253393961488802, 0.1096315966935288, 0.27642655346589645, 0.1982897042279566, 0.11387578307611786, 0.22624678680172342, 0.21101040982428776, 0.26974394791893463, 0.2936399123211407, 0.14242688634207232, 0.20571315538899418, 0.2665858404195905, 0.07065967329744252, 0.23993958235422425, 0.16885809626950796, 0.16237745858980054, 0.1106054145177676, 0.35808269112966645, 0.13115486536002663, 0.12413531328476, 0.17300150733475003, 0.13870466038708057, 0.09993236818171439, 0.12634928071965815, 0.3260866080310802, 0.3451313517249156, 0.16756099526131102, 0.18111737875809525, 0.25364787339620976, 0.08883937071088022, 0.2076644735807904, 0.14403823591680143, 0.14627919220435204, 0.14358947794362972, 0.24169206528013415, 0.15133625978618784, 0.17976332648271715, 0.14324072943965974, 0.1398130141541215, 0.4152255350639341, 0.23589562184813928, 0.1876840563619228, 0.1426234431878524, 0.3666727155873321, 0.08690805452074517, 0.3899385453381601, 0.48657932130012904, 0.3135853321437245, 0.11083984570567645, 0.267025460497156, 0.4228796759223299, 0.13520982199784645, 0.14078137067609306, 0.12027976265992255, 0.07882307920212774, 0.11982441892041036, 0.17085521467487932, 0.11479415405193875, 0.3077953807522802, 0.3874714763073686, 0.10254726925401617, 0.18904879788135856, 0.37479859940435545, 0.2295522115241078, 0.5210074489179373, 0.13605428332487177, 0.10641975138882102, 0.14256404196366593, 0.19729899665743394, 0.1295646412892417, 0.08062885325615317, 0.21176028905112404, 0.1765442991753964, 0.3926311102531238, 0.0933985555493854, 0.36617377244918614, 0.20707053543031695, 0.1099896226394092, 0.1025990165783532, 0.17504421423655905, 0.18123675639656603, 0.19052844149223644, 0.15388907140682856, 0.13901073031373581, 0.14731622754197696, 0.49614867772793, 0.42514497155478803, 0.1439435106207591, 0.32511668154630086, 0.10835017923016699, 0.2919987943013182, 0.3185714746939587, 0.1996986282099087, 0.5240399407415166, 0.15133625978618784, 0.2614703088514125, 0.23539423781196492, 0.1067599456778228, 0.09505716598709311, 0.16527382844959515, 0.12642403895747814, 0.19267878473774577, 0.16093810910396814, 0.1203599040238072, 0.11544124618796328, 0.12877343494689972, 0.11419373940674021, 0.15435220363042432, 0.1661890426490534, 0.08269512552291107, 0.20162639585303688, 0.3002318068981054, 0.22837399367788352, 0.13228419750375264, 0.21505659454246132, 0.12898422132290033, 0.16806270912137558, 0.23967287328700318, 0.12413531328476, 0.15117672619904676, 0.16062212734467043, 0.311517752416114, 0.3299370962827493, 0.08211788154705717, 0.10748081199896568, 0.30076504756101735, 0.2029132129389805, 0.15265000053545374, 0.0760924665431162, 0.18836058336606712, 0.43379199502250987, 0.12368115950655412, 0.31372698338656235, 0.14073593533053974, 0.1354267656075428, 0.14429530809075583, 0.23925557108584278, 0.11526669179993183, 0.4000873975373399, 0.08572831014923554, 0.5300961204343363, 0.15285002206818601, 0.1067599456778228, 0.06819092533113429, 0.09094984172882872, 0.14827049248868843, 0.12385881726278906, 0.39998967459271134, 0.1592381006321566, 0.14493423275821965, 0.27034328245717454, 0.19645371709595785, 0.14540085611404083, 0.1021414012459412, 0.1308898251141848, 0.1161774561561864, 0.08377441182170407, 0.10557091066989954, 0.1156648689196054, 0.09388237403191096, 0.4015409753605512, 0.11307944806333023, 0.07175772783015373, 0.13898382568427517, 0.11922580916354195, 0.3068209215124504, 0.08183874806770688, 0.3191089548536637, 0.44640602820566533, 0.26555688401389116, 0.11682797548319869, 0.1709827447044503, 0.13250815096438853, 0.18334931025763915, 0.14166977448995202, 0.3157938048352877, 0.12183853475556414, 0.2438414346365436, 0.09281674135645691, 0.12558740545911376, 0.10844372330995095, 0.21357385199999787, 0.10066691272490803, 0.09757254437393134, 0.28775667705995894, 0.5885439345133991, 0.10243296156526284, 0.17312564691545057, 0.11251658275298212, 0.10777227948362067, 0.279164576566039, 0.11756199421569578, 0.3708103335939426, 0.2540903187856045, 0.2431992246578787, 0.2352664411506721, 0.17202503736626173, 0.09334461414448002, 0.20635063335096193, 0.10355226414567306, 0.22638030560586156, 0.43836002099573296, 0.18408853457031296, 0.27335956611380074, 0.19655612607791603, 0.23263368226779196, 0.34021896656470557, 0.3270997387584947, 0.19673462650812004, 0.09878671060389346, 0.33793531494532575, 0.13125729177018783, 0.31957848995479116, 0.14568018941548694, 0.25221587699572845, 0.13629953163934533, 0.49614867772793, 0.16039866648815368, 0.11211359800788577, 0.4918920590412644, 0.14806191834034657, 0.20763347917227512, 0.3939309159592986, 0.19800590591770353, 0.23424910767968668, 0.0855265355933565, 0.3484015340057851, 0.12339309024482478, 0.13827377493390858, 0.4016052819387877, 0.1081202307488336, 0.17720219032709783, 0.2573132284013041, 0.2638030787320643, 0.19692861410778195, 0.3127361568644699, 0.20518239400172286, 0.1913304879072479, 0.13827377493390858, 0.13190720858608262, 0.41101949706208546, 0.2919987943013182, 0.40591615265884295, 0.12498484502477011, 0.26930598852722876, 0.20138510447288235, 0.23563204694187775, 0.30416822926184534, 0.11325539761954583, 0.10745270967824222, 0.08849217334182205, 0.1710116323301666, 0.3158158355307369, 0.4575425330641055, 0.40300304507766777, 0.1099896226394092, 0.23990504392288428, 0.15078444584539064, 0.28484617438855536, 0.07973201158663336, 0.32445244470755913, 0.24937313803894634, 0.3457810743023613, 0.22823870187644188, 0.11705245754920286, 0.35456013705630357, 0.147832912731132, 0.16650171561095478, 0.10331403048622402, 0.5043540875596271, 0.21683172814917848, 0.18055022408313387, 0.08119204022299202, 0.07430662651039839, 0.2369483935090192, 0.32946567135386645, 0.2365630747413348, 0.11506396583975327, 0.12387403931151145, 0.129060552799266, 0.21602846911698523, 0.1784540209134269, 0.1720322803437422, 0.23230560344011014, 0.17393968579751046, 0.28995623137124116, 0.19482351247375226, 0.21328970383597617, 0.15906249713329507, 0.25091016766423696, 0.3724901533290102, 0.39430372895678417, 0.16167480452147392, 0.07848427652460083, 0.09102903736787901, 0.11262448672056305, 0.22982332312979278, 0.19760570288451235, 0.41097525459756157, 0.16178201620145902, 0.17643279096274447, 0.2245309414258843, 0.13706570200046003, 0.12993477459387295, 0.10525256331633542, 0.14586932211718984, 0.08895200236795443, 0.10478810341977472, 0.2971400507284286, 0.12945425113908823, 0.11447331804791795, 0.13709102401706022, 0.11801635589855373, 0.07261307152841426, 0.1106054145177676, 0.11294220664508016, 0.24164324079278113, 0.09451995872857587, 0.3645870997314224, 0.13393637797993596, 0.24031250204376212, 0.11091205793146752, 0.15104302513033005, 0.10418678101200828, 0.10890625138519856, 0.44559454010602007, 0.16175240305588556, 0.27692411811275713, 0.18492995013627433, 0.08199803300544131, 0.1766706096247693, 0.11489458862376604, 0.3940236048405577, 0.23574973733014995, 0.2267059705122154, 0.07652496166852646, 0.0737104791759877, 0.2945850239532102, 0.13987549240329467, 0.43269984402572975, 0.33618742681813324, 0.2945739975290445, 0.33520201951557316, 0.4497028857110984, 0.184573851979461, 0.15390192480971854, 0.44559454010602007, 0.1958620417919708, 0.19277011552286755, 0.09309517055038427, 0.20098036715892692, 0.12252425962554298, 0.31628671645937717, 0.2310720869897222, 0.5100153713699968, 0.30896758120897083, 0.13824002912707326, 0.30079622072256607, 0.18996829074288574, 0.2740387496717677, 0.17289729069258933, 0.3527087601487063, 0.11454347831873808, 0.15390192480971854, 0.33426963817898825, 0.07587623214532602, 0.24394197457989975, 0.4157121030822509, 0.5082637954261032, 0.10770914767623617, 0.21930699559977973, 0.10023221067397178, 0.18249445753771792, 0.21108344893180003, 0.3708103335939426, 0.09469197324708375, 0.12131592939164725, 0.10457027756519507, 0.29073893701780185, 0.19287364397539725, 0.07058831692865238, 0.3269587878636992, 0.39483085546694907, 0.3205360059604536, 0.34021896656470557, 0.13977300288984648, 0.23802823002607462, 0.3568294864774119, 0.11807150184614619, 0.1672035273135676, 0.10525256331633542, 0.2235235600451325, 0.203125002303072, 0.27917078907037, 0.13846747158065248, 0.0819025255540692, 0.2737290424200826, 0.2087196838291585, 0.08545014713972839, 0.15994110224721908, 0.2461823553140721, 0.31099004250727635, 0.11377561738474994, 0.23210531632013964, 0.2116773544918299, 0.21372044008585594, 0.09303601174508606, 0.18293714408954456, 0.147832912731132, 0.3603341132188136, 0.11635271026355111, 0.15885887938377852, 0.29226637070367883, 0.11084179424388844, 0.11918171179467278, 0.3055479058651312, 0.49614867772793, 0.1293598000051832, 0.39326378908538323, 0.13600221258042589, 0.3217705837557597, 0.198554144469908, 0.2947545929988301, 0.15264361083841166, 0.16028441921753125, 0.13136743661418673, 0.46450546024999084, 0.12216756193845843, 0.1475041789971984, 0.21910028818804403, 0.43798694072940053, 0.1417345931789452, 0.07742371776163555, 0.18593084048986736, 0.15235803913224208, 0.2977281668541378, 0.19009542080762992, 0.28705590408304577, 0.2803422504791688, 0.0791963523566784, 0.2773285576272151, 0.07210016122179097, 0.3156842543317048, 0.17960950004577603, 0.16429049123991604, 0.16593068307270542, 0.17721914357344035, 0.16394127228931402, 0.14748409602423945, 0.11309123410660517, 0.1540928068305824, 0.18090183224442746, 0.19060695505538497, 0.09281674135645691, 0.5902400901295125, 0.11935140007658401, 0.2240868557260699, 0.13169530309982636, 0.16062212734467043, 0.17610446876005817, 0.11399911086849898, 0.3843517802084817, 0.35139723866133193, 0.22023983442209913, 0.17376521148654683, 0.22859229787850746, 0.27103868875667997, 0.3490670154005895, 0.10973829059448544, 0.2534906030904629, 0.25810987081470754, 0.09986746351024312, 0.2855021248326789, 0.09281674135645691, 0.17213970261964745, 0.15056620174778268, 0.16433099246316155, 0.09511575247093425, 0.1686561897183413, 0.37039929112808295, 0.33392566935619666, 0.11091205793146752, 0.2894625251718145, 0.0986592088210912, 0.2909375266535611, 0.1005331601095284, 0.17207306178313922, 0.08490366930372607, 0.16733406401332734, 0.20799496891424316, 0.15862998423733446, 0.3450585913895862, 0.14989425146567767, 0.2187326186247271, 0.41152409428908937, 0.29171016812693923, 0.17205753480082084, 0.25769067422346825, 0.14662847301319668, 0.11317637662957268, 0.23079378668588546, 0.14235627617360314, 0.12882007114821334, 0.14475547405780695, 0.17952355136412051, 0.3285731114534712, 0.2090831854579196, 0.17282743871246115, 0.1774051485370936, 0.22339998891706864, 0.18954085286216832, 0.1548235324076611, 0.16827909852798095, 0.13510456590266068, 0.22706716542781608, 0.10498363008972592, 0.10777227948362067, 0.17645192347612798, 0.0849896037010653, 0.07540126008077105, 0.16857515916403756, 0.10641975138882102, 0.11664614664565484, 0.116773691329484, 0.2944288463096714, 0.08679819397500685, 0.24023966564142166, 0.19304917052998485, 0.09658019997233387, 0.39103749826493384, 0.11550171993926375, 0.33833862435765033, 0.2855011730624527, 0.08454419033507395, 0.39885519389786783, 0.10942985710716471, 0.13996561885478914, 0.21667989185951178, 0.3353282317865891, 0.40905310221321617, 0.11648726466769808, 0.24153621917331952, 0.08070131201973019, 0.3162267123873651, 0.15380230268829342, 0.14515162842310814, 0.1670272364918872, 0.32269284766051126, 0.13028966903816389, 0.08674292997176164, 0.07882307920212774, 0.37464485453978885, 0.10640329409927461, 0.15099700745919858, 0.13927712699867312, 0.08645778878579516, 0.38344608914342143, 0.40905310221321617, 0.09281674135645691, 0.11341314656534854, 0.12770702049881358, 0.0760924665431162, 0.16186149795799776, 0.5240399407415166, 0.08153588118463585, 0.13250733479745547, 0.1680670589418052, 0.1158002455706058, 0.1554934660016103, 0.18308635715874327, 0.17134992530361226, 0.19425851327605603, 0.10355226414567306, 0.36019970077401553, 0.20689291793046866, 0.06545356805352896, 0.1527916000953782, 0.2325102338060181, 0.2919987943013182, 0.19689777467463937, 0.3274333944974476, 0.13295701962918932, 0.1352437673331941, 0.15915032260393033, 0.24057118306159744, 0.24059487350448283, 0.09397323850606655, 0.19114234238205877, 0.41341976301795036, 0.2874315303446772, 0.2473667950820425, 0.14983972760079056, 0.07554965562557073, 0.22911416553058098, 0.09873954614034651, 0.11410916654415602, 0.1869211228809786, 0.37464485453978885, 0.23196262691173264, 0.38827257355613237, 0.25197637891062696, 0.18444433939312593, 0.14075410996470117, 0.284173202402118, 0.20478386815035562, 0.29390764708733497, 0.09691303761565194, 0.1398130141541215, 0.0908708388412524, 0.08045441957265298, 0.21918016233997945, 0.17672318687564054, 0.20273194773009662, 0.09523763212768072, 0.29885478429565754, 0.23105713233265185, 0.18499373568293537, 0.23478195584564535, 0.11464138358229195, 0.39600480348605926, 0.1442726893730786, 0.12931221393104306, 0.1124116734665113, 0.08527794622475837, 0.12184528516229262, 0.29637359833043153, 0.23449537633401574, 0.22451322258936487, 0.21762490704910278, 0.16205576620798245, 0.446976329457549, 0.2218202597421042, 0.25985271052937553, 0.12941370808209743, 0.4102760680476613, 0.2034491957407741, 0.1531809453897494, 0.3202037245047863, 0.14930079190452097, 0.11815610389800496, 0.282483553021802, 0.204449792387185, 0.4174407982978271, 0.12882989523856667, 0.12352301439292611, 0.1073837321138874, 0.22837399367788352, 0.186898442166769, 0.09281674135645691, 0.1600148103688443, 0.1243235308901767, 0.16268371602630546, 0.12470193861837846, 0.46297329023981093, 0.35646350352551903, 0.49614867772793, 0.13134782865518455, 0.19376168357768186, 0.2825279928307092, 0.3568294864774119, 0.1122641330905096, 0.10070841629398031, 0.2244423511526379, 0.22756141289346615, 0.2063679374497155, 0.11947641675484887, 0.12138191176344554, 0.19177850177018618, 0.11136790061227579, 0.48203632554552034, 0.11032286014495202, 0.11321826329597896, 0.5284610041868364, 0.3410237763617426, 0.3030572810320506, 0.38827257355613237, 0.2500351059638333, 0.11345131916738418, 0.1122163783463223, 0.37326200099296036, 0.30537544356341745, 0.32190952107386744, 0.3250817641847347, 0.24984777272810446, 0.08730835725401269, 0.22226342971725283, 0.1904088890384263, 0.3106125750666196, 0.1511373455176483, 0.12813914345973673, 0.14175843938589638, 0.21599615097412866, 0.09868953132616903, 0.09495905155586974, 0.39600480348605926, 0.2061105955438884, 0.17207306178313922, 0.09919133917372694, 0.11410016257885368, 0.16310940856910786, 0.18826362307064215, 0.09037889699279131, 0.19180190033290878, 0.12708308457640105, 0.36847552499945824, 0.2822568330280801, 0.1499021689142916, 0.5100153713699968, 0.12084063601947745, 0.5082637954261032, 0.14105414555388757, 0.17510966952450918, 0.06852584987618048, 0.12776240174575088, 0.49614867772793, 0.09827058356536836, 0.2732200606610985, 0.2085355835655111, 0.14797323362755896, 0.2189674358288966, 0.18002043559138858, 0.19819786262529185, 0.5210074489179373, 0.09304065500413357, 0.20299953971569273, 0.16214333112597304, 0.3321120604993994, 0.23533820870008285, 0.15071381193294614, 0.39483085546694907, 0.12476987597001368, 0.0791963523566784, 0.27107090697708147, 0.19211436177033395, 0.35188962434159793, 0.20862720055055722, 0.15725091645342107, 0.2171887122402624, 0.16484772069411713, 0.1847619714326818, 0.15225243678682787, 0.47207073411718903, 0.10865942331795937, 0.09483421838434511, 0.186898442166769, 0.2001349186463403, 0.12370401428952735, 0.1338536463312682, 0.11004732761965764, 0.19926648140667527, 0.17279678950021896, 0.0839922545711352, 0.06892145721420637, 0.1879447564759281, 0.2986501733845602, 0.11047629244786464, 0.11807150184614619, 0.3109367691431083, 0.20734937566288858, 0.10979278349223036, 0.12444303881935999, 0.18142935483770192, 0.12089344610859351, 0.14702430929663532, 0.25377808484885034, 0.29122097639879796, 0.23658258535098337, 0.14935707952771468, 0.40341951335878484, 0.12470193861837846, 0.12214977564145772, 0.36289673683755264, 0.07172029258747917, 0.22619435737532484, 0.07434530360224087, 0.49025183991330656, 0.11918171179467278, 0.14534728194134797, 0.1548074414261315, 0.12089344610859351, 0.1334293295620104, 0.18481254735543004, 0.0851250122943608, 0.10777227948362067, 0.12642403895747814, 0.2873556579093672, 0.11050815167056062, 0.3385959102278954, 0.24458454049026546, 0.3449484977034317, 0.26075008542765404, 0.1615142736671936, 0.16270157996246448, 0.11684999697830899, 0.36884073138231394, 0.06783042824609434, 0.4613878293530681, 0.1575780866502949, 0.3116011410108973, 0.24808624174326577, 0.10377274317428388, 0.10316992705506442, 0.19846198544635837, 0.11382796597921863, 0.1475599407752364, 0.20363590902725973, 0.22493552284059343, 0.20475048934895884, 0.1582322340419595, 0.17963471728530803, 0.23400283936366328, 0.13182035940499418, 0.1780192973484875, 0.1699588562038963, 0.24153538627317825, 0.12871822018787474, 0.1663464589823552, 0.13008672260946688, 0.1634592359925266, 0.1376261790547815, 0.15369758452879184, 0.4371283573947101, 0.2219701593192547, 0.12920193991651213, 0.1251151453212273, 0.08694768178118499, 0.12202301355706274, 0.30617402548134043, 0.09644579069396732, 0.11608044295894457, 0.12460039095147775, 0.13184689697491225, 0.14373846503449164, 0.13728321308418565, 0.39600480348605926, 0.11829103077812203, 0.14050810753676518, 0.18350451450324382, 0.09370610872852471, 0.09745538116289021, 0.24061324542435836, 0.1503224023749683, 0.1966581564550664, 0.10479924627004042, 0.11074168803556245, 0.1242534462843175, 0.12745709294615418, 0.15390192480971854, 0.1029451373011489, 0.1591927810150816, 0.148303460203194, 0.33281074878802497, 0.23675041017658874, 0.27483608197512305, 0.19144215259616323, 0.18429785157941164, 0.16341450288976397, 0.18091458829067822, 0.2538197191318916, 0.13025256947901334, 0.10085933736973952, 0.4376861707368924, 0.2763355408166661, 0.08730835725401269, 0.09419023111612627, 0.13513626337995244, 0.4228796759223299, 0.33905576019430256, 0.1107572276033845, 0.15133625978618784, 0.14333134864173905, 0.4582580923865728, 0.23385037465700234, 0.24775388381200775, 0.19100193297741333, 0.14550392269449622, 0.33002449257686234, 0.3093584320922362, 0.2064176239489715, 0.13911473007207567, 0.16028259945165127, 0.16175240305588556, 0.20238941040809338, 0.43115975133570195, 0.14149011847324044, 0.10777227948362067, 0.11137301173928948, 0.36211136488313483, 0.37171079793102835, 0.2951391194638924, 0.27824334325934946, 0.3191089548536637, 0.26439290305213203, 0.15078716362290276, 0.4582580923865728, 0.09201417587049965, 0.10054270681131643, 0.11019202807508227, 0.12837392448389287, 0.13176260801759088, 0.2586210518736589, 0.30413828752622935, 0.1438257319416173, 0.19123101246335528, 0.12042470984741789, 0.20497234000522419, 0.082510520988824, 0.4202410067958809, 0.15048782374787362, 0.2887120414344332, 0.16502314297165513, 0.13677325914959756, 0.12695456796641721, 0.11818547179361842, 0.29332390445613354, 0.1860328428006725, 0.15701796389507386, 0.14994493656000285, 0.22807017769308138, 0.3451313517249156, 0.1242534462843175, 0.14421726815066827, 0.18507672210152995, 0.07882307920212774, 0.21372760282228564, 0.21091747743306646, 0.17296183087323896, 0.1670159101419397, 0.23666869046143657, 0.2863230666627077, 0.1790075393168375, 0.3359025203069861, 0.2383673333082979, 0.4485991802424573, 0.31062003800627475, 0.11014386901326254, 0.08667357832375669, 0.21762490704910278, 0.16677245422784667, 0.13605428332487177, 0.11313480989518265, 0.2826010222237049, 0.10316475061609708, 0.11448493197672341, 0.203125002303072, 0.2215904159313329, 0.12658543513992834, 0.3034627254627471, 0.2994028007616274, 0.08923685801214391, 0.19587044961799516, 0.1308650866536782, 0.5240399407415166, 0.19596197072623708, 0.17688139943760478, 0.35749571945014247, 0.3163801723902918, 0.08199067735678423, 0.2976807234787983, 0.16518609022130526, 0.37756024067589566, 0.08081273119947333, 0.5011106841415729, 0.18651474893759676, 0.1891907324340581, 0.10478338382393143, 0.20234152695473073, 0.1647096258424622, 0.22443750387376848, 0.07978978792341641, 0.07392143992795794, 0.12184162878198007, 0.19315215487984846, 0.2610718874018624, 0.33763144723727, 0.18252543082558562, 0.14456173158623165, 0.29698105762313914, 0.20571315538899418, 0.09102903736787901, 0.43115975133570195, 0.07172029258747917, 0.13371765301387065, 0.10731544068748297, 0.14897164327483778, 0.15893348343442987, 0.32327313042731026, 0.17128557101674863, 0.39845217287746637, 0.22048167540119043, 0.20665248323794244, 0.18476362800708793, 0.23913482977642211, 0.10777227948362067, 0.2904428395524585, 0.5227833488640741, 0.30921642344171607, 0.1511344337488652, 0.2685909452912173, 0.08680467559530711, 0.1064022207068981, 0.22271351843351755, 0.11970656643826368, 0.2424553190029475, 0.14954440213666487, 0.15029529712749518, 0.10287202958622466, 0.2974065050793634, 0.1914952452355868, 0.11632753521872083, 0.2917423291749541, 0.355805724135246, 0.1373520061643024, 0.43392022882053427, 0.1050067355286615, 0.154688721286274, 0.3159468348577108, 0.1279601999367211, 0.5192581283434271, 0.1592381006321566, 0.11599133631136596, 0.22023983442209913, 0.17594266265918992, 0.11360717151349471, 0.2784353643348185, 0.14360761327381033, 0.2255251886963228, 0.19486952363253213, 0.08211788154705717, 0.2954036707278964, 0.20625336509260783, 0.3714751106120162, 0.20717484530990754, 0.21562322658182137, 0.3772573645935156, 0.18129407189284588, 0.10141773324230348, 0.5043540875596271, 0.4316432847419217, 0.3617135604578866, 0.10968409841761266, 0.13250909492794022, 0.18507672210152995, 0.16200991292489836, 0.2012375007937826, 0.10641975138882102, 0.14206618018575573, 0.2132998937875563, 0.07904268509826128, 0.16350344052150287, 0.2757964383454058, 0.2983658324083065, 0.15265000053545374, 0.21731317471351413, 0.07029595379729078, 0.11232162140241927, 0.11317637662957268, 0.09781293052248244, 0.09820098092937597, 0.2213945116834636, 0.226175953882762, 0.11969051388563305, 0.09970068287183606, 0.1791415669623983, 0.15994707906973782, 0.11050815167056062, 0.16732490957259266, 0.21042855423750384, 0.4318106339052531, 0.09018756874243171, 0.4218315272008748, 0.162315602540757, 0.10590834822544866, 0.16124746033734208, 0.19854699645748913, 0.25899782016646267, 0.17416558954209088, 0.16240135944651696, 0.11136790061227579, 0.19155571016636797, 0.40389332754085466, 0.27953959918846755, 0.0795865519199926, 0.37098713201116773, 0.14431523346711603, 0.1361294104298337, 0.06783042824609434, 0.2394837370309508, 0.12472157487300561, 0.32267585216838895, 0.14991893633287817, 0.1476893631718827, 0.40798734396639763, 0.31323921509794556, 0.07434530360224087, 0.3082301771054899, 0.21084061505439147, 0.3724469977861641, 0.4582580923865728, 0.14838256129081195, 0.14151468695941333, 0.12893349282896846, 0.2635598001576401, 0.10962685856487249, 0.07784097053201859, 0.2621859344695358, 0.1390921539451797, 0.29643096697002586, 0.2629641211708804, 0.16658131073942894, 0.48252851631512694, 0.34335066652492896, 0.4240169882758624, 0.1842436267471608, 0.3821864202850278, 0.1168554980271235, 0.23079648069927014, 0.16773736076918425, 0.24236941815835047, 0.08303773924839018, 0.29454920577304544, 0.15151606042910384, 0.13318236204993586, 0.1429253113966837, 0.46123119497598936, 0.09781885060622098, 0.13008672260946688, 0.12370401428952735, 0.23962260132127752, 0.3398630873824747, 0.11409616717101749, 0.14497647445338918, 0.15866692364257926, 0.08905113569108665, 0.2796546547757488, 0.1607317620109929, 0.13728100832525897, 0.06943597213161226, 0.26339920827347774, 0.5082637954261032, 0.16280902477778708, 0.19409523665102515, 0.08991840123130475, 0.10733728734095035, 0.3724901533290102, 0.3129857399606652, 0.13218313292168135, 0.20685829365617558, 0.07901262644541485, 0.31501977721582947, 0.18584742787212863, 0.09758301684667366, 0.21108344893180003, 0.273933789617075, 0.33420074183967624, 0.06545356805352896, 0.17668014766020232, 0.402127334521389, 0.26607670391816163, 0.08297489164798624, 0.17542329428319461, 0.14974715510229764, 0.18398493427571513, 0.14302265437687112, 0.11918171179467278, 0.07452495419409265, 0.1647599428650704, 0.20095472445726867, 0.3048517484927581, 0.44008629360172197, 0.4394118658389668, 0.28396908002249166, 0.19443315218924032, 0.11897144494467332, 0.17010603820219822, 0.1295933853491813, 0.30933926081498586, 0.46119103071684997, 0.07172029258747917, 0.11136790061227579, 0.167049634226196, 0.17008667594275198, 0.07742371776163555, 0.12619919670933166, 0.217410933182041, 0.12368860117770608, 0.14322384244390818, 0.11103280425445787, 0.19919448981684912, 0.2758472447611342, 0.12453263640109896, 0.1538912869647098, 0.13330577460704227, 0.40552797251722267, 0.12326713668695337, 0.19482664185263807, 0.11158312938301598, 0.115348782533282, 0.08502288296041811, 0.12355042524400231, 0.3959661447183812, 0.11432234171061655, 0.19858920482878914, 0.4000291012742435, 0.43798694072940053, 0.21315012394441593, 0.14647655561721246, 0.10777227948362067, 0.10515098778106763, 0.14499945866484373, 0.06671483590002084, 0.19317788569500652, 0.10055210964089586, 0.18250289747053547, 0.22805638364566824, 0.2067350506283668, 0.15682617501939358, 0.13693683434485673, 0.22124538771141455, 0.13462650791749076, 0.2952579619836396, 0.3787973451912618, 0.23999911501759444, 0.11858584582805991, 0.21848100198259784, 0.4881048915512455, 0.3028013611002595, 0.2397789425634583, 0.30058420856559, 0.2752961519138546, 0.1410390082198507, 0.45999854584017336, 0.09600235898877685, 0.13354580701964147, 0.16633161684911388, 0.2917616949263614, 0.15882460624318365, 0.21134795368072362, 0.4630191959022058, 0.1787619228243625, 0.3607021048846073, 0.10049198194955197, 0.14404298258656775, 0.2635127423726674, 0.11251658275298212, 0.07876661153990033, 0.19037100099597204, 0.2942641430608141, 0.172421726202588, 0.13028966903816389, 0.0782624392988801, 0.3217705837557597, 0.08357071107731096, 0.16561555494713906, 0.18826362307064215, 0.15591759581640938, 0.08785574706366676, 0.11019775719259163, 0.2297178878823416, 0.27004738102743586, 0.10365302048756445, 0.3033685294184925, 0.22435175863062065, 0.13481421317279285, 0.16623128299476073, 0.4849399099344759, 0.11474845932473623, 0.22339998891706864, 0.12352301439292611, 0.20804444069654307, 0.17356123958305064, 0.2590626951527349, 0.21593541790867182, 0.4017707685434506, 0.18896800930866298, 0.16387543545230318, 0.12612886432001427, 0.1948863978088661, 0.2718305606548886, 0.15333847252384694, 0.15672971960272852, 0.3902410651605243, 0.2569489115251867, 0.17448134745136848, 0.130870667102178, 0.20449448148470425, 0.1349577466491832, 0.1005080609490714, 0.07824485522143199, 0.0771265996628589, 0.08391300212534504, 0.3032755029994092, 0.07175772783015373, 0.16421579588160076, 0.1963196246978541, 0.21334957252576717, 0.5192581283434271, 0.1989869964068365, 0.5138422565244447, 0.20282391369012423, 0.0986366988333279, 0.1459559148009275, 0.1594500957160441, 0.16622372560443208, 0.10365302048756445, 0.13422829131711328, 0.13728100832525897, 0.24793087123110108, 0.11716279885672701, 0.2186308519638181, 0.18477525498258468, 0.3457393082505117, 0.10775681102774631, 0.20514505374061323, 0.547315432385, 0.08385306460858398, 0.26595655684266395, 0.12004485460902091, 0.2852434341154972, 0.1935963952899105, 0.12556413221258925, 0.3559082848408656, 0.22793227110900144, 0.17395612573816954, 0.2794595728933262, 0.3156365605990959, 0.2240868557260699, 0.08158471319788572, 0.32857498635945687, 0.10259767271682978, 0.1519675157258642, 0.21865897069911908, 0.15875434363659863, 0.20061214207403308, 0.3632585093251057, 0.11175038794773094, 0.2183151294257824, 0.26151767735520626, 0.2039955174831167, 0.421603097100669, 0.19451544866927228, 0.43379199502250987, 0.21328351533656764, 0.1900029318960651, 0.08142465142182535, 0.19357946645165122, 0.16138649793010834, 0.24218317500488326, 0.16053928366902806, 0.17921778387811, 0.19082177689141, 0.1840064598860424, 0.18587059608773387, 0.23047638334876458, 0.4228796759223299, 0.18337973887848705, 0.11481112249575703, 0.11927082322378936, 0.1963196246978541, 0.1586023387411984, 0.06545356805352896, 0.49935852313555745, 0.21080860301895862, 0.08965383820543715, 0.1366245487777777, 0.1064796032440538, 0.1592381006321566, 0.1962053791576381, 0.15459669971754603, 0.06812187930508513, 0.2980342211638378, 0.11195632101594118, 0.08119204022299202, 0.4881048915512455, 0.08730835725401269, 0.13144370724009932, 0.21876812881751279, 0.082510520988824, 0.15774343639440394, 0.3217983868526277, 0.14500574310915368, 0.1110492630141913, 0.2552436364190494, 0.11953556900406677, 0.15316593310584894, 0.1201602602728788, 0.11175038794773094, 0.08991840123130475, 0.1388044349221614, 0.21359865979760628, 0.18668630956823415, 0.40389332754085466, 0.22580063028836495, 0.21926624036787873, 0.11714416225360079, 0.19281226166484602, 0.2919987943013182, 0.09358547666018384, 0.43836002099573296, 0.1084043238468304, 0.13025154430331531, 0.21273270611196965, 0.2427795200881996, 0.15543486395304423, 0.13445869646712702, 0.11969051388563305, 0.21953731745295096, 0.16827909852798095, 0.17466834697009065, 0.14951284129182596, 0.1330777758406573, 0.15924897218103187, 0.09878671060389346, 0.34298872023274873, 0.08493538411771787, 0.1342444919650249, 0.2751281816596599, 0.31628671645937717, 0.11569182725960352, 0.13269333022904958, 0.16678193727254215, 0.1262800239935689, 0.46803048416636206, 0.3454739573157477, 0.19882851119528094, 0.41182005274640365, 0.20017420115893697, 0.16324987832035692, 0.06913410917404965, 0.4582580923865728, 0.4152255350639341, 0.1023337959115068, 0.14050810753676518, 0.21127944851469962, 0.43115975133570195, 0.17376521148654683, 0.15784648633588555, 0.09309517055038427, 0.1775858556852314, 0.19594990874538504, 0.2231097309435361, 0.30921642344171607, 0.1671461333986197, 0.16797837329424184, 0.11616801641155912, 0.09373572390072686, 0.16266803465180402, 0.19842438378515248, 0.2483334914231393, 0.166148623695324, 0.38344608914342143, 0.301965767894593, 0.2295522115241078, 0.1824935832603482, 0.11325539761954583, 0.49200344959199666, 0.19336841329899956, 0.3945766569719934, 0.20999588626998075, 0.3527087601487063, 0.09705026494258416, 0.06812187930508513, 0.143543447583041, 0.0953201402668729, 0.4011819408915889, 0.20177056085662998, 0.11752778406016462, 0.5043540875596271, 0.08490366930372607, 0.1391852922814434, 0.15618587818034885, 0.2240273117914997, 0.21712961108077322, 0.16873677865158063, 0.5033548833113098, 0.09646506903259922, 0.08020429047606392, 0.09894625228870124, 0.46297329023981093, 0.28285987218505093, 0.14127625951766248, 0.11017064147379188, 0.211721833771018, 0.10865472207795686, 0.23851131658660152, 0.41101949706208546, 0.389537688784747, 0.1946784888197023, 0.16028441921753125, 0.3002318068981054, 0.10087143795385149, 0.16099716413441975, 0.1110492630141913, 0.31746197626470685, 0.16897219893643142, 0.12665232106617808, 0.4863135215853268, 0.27062917692127264, 0.07780062771857363, 0.1232957666160246, 0.33050639527523973, 0.17106360436613247, 0.25256195972694, 0.15436263983847212, 0.0860048669501104, 0.1580440082417429, 0.18429785157941164, 0.1461831124482576, 0.277675524675338, 0.3165500420858053, 0.20581176514942537, 0.10118977932345753, 0.08380122807326629, 0.13747954593800787, 0.08309499282734238, 0.2147511643341588, 0.2596643135298141, 0.1600372391584604, 0.2183151294257824, 0.22510715410153131, 0.432545127545737, 0.3972826407012206, 0.09782313937987087, 0.1596889372829468, 0.18425514799291112, 0.16670441713519982, 0.26430205060375556, 0.28272293577759566, 0.21804455614609347, 0.19964246025884483, 0.2971400507284286, 0.12695456796641721, 0.19312759095327114, 0.10331403048622402, 0.3116011410108973, 0.1298646191626265, 0.31062003800627475, 0.1415503690313873, 0.23993958235422425, 0.11531226854427087, 0.1755033462714913, 0.15747649141956185, 0.2592669777612079, 0.28656676119994495, 0.22316798014307251, 0.3874714763073686, 0.4556722314527514, 0.28512800722621123, 0.22982332312979278, 0.34798424396089805, 0.20467511957504242, 0.49614867772793, 0.17594526006951552, 0.16883484469970933, 0.30921642344171607, 0.08102157154031689, 0.07724885743712281, 0.1495481017338884, 0.07172029258747917, 0.5240399407415166, 0.2262955586846708, 0.0869796662701806, 0.17888891019678888, 0.42152943163239565, 0.4447724533963599, 0.5300961204343363, 0.09758301684667366, 0.1819832276565875, 0.22082075270140739, 0.09482942789427821, 0.11179565264297725, 0.09854406428956927, 0.1106560538526184, 0.34352456954568755, 0.17352583740221728, 0.20518099256100733, 0.27927242433709604, 0.27716761121933625, 0.10880157857275709, 0.10126311458722476, 0.14428042768029334, 0.20093192923869618, 0.08936916537159167, 0.11647070512883788, 0.2231211930395937, 0.08645778878579516, 0.4527211344030608, 0.41573739885141736, 0.2873946257131189, 0.21855784349329835, 0.4079318863158239, 0.5885439345133991, 0.3681981240930328, 0.12008352708299908, 0.15072879083550192, 0.10753310686447734, 0.3752114772814278, 0.24768634917080803, 0.18420839646834397, 0.20827982555302674, 0.2863132665683548, 0.14788547981508166, 0.1635618245727648, 0.32036773406429725, 0.13471577914424598, 0.12176561311294568, 0.06744062977663694, 0.11116437203251966, 0.10956545457353756, 0.21796699252939072, 0.18391228533273915, 0.2575814507625574, 0.2709191212866623, 0.0764538818804806, 0.3826947042314976, 0.13815400909869224, 0.20467041420478355, 0.08045441957265298, 0.36884073138231394, 0.2598758107652456, 0.2654954078687667, 0.21802530085528607, 0.15459669971754603, 0.10428219300589292, 0.21334061487540362, 0.16470776569025558, 0.13837426337384262, 0.10078770680266783, 0.10590834822544866, 0.16911363726010986, 0.10331403048622402, 0.227998402859046, 0.26637892773918803, 0.13346840471713536, 0.21327767161847186, 0.10876909783221457, 0.15901761388368424, 0.1939655889344386, 0.1236832814260533, 0.1863132270941301, 0.15579400168627128, 0.20459714073241, 0.20439835289336214, 0.06819092533113429, 0.13041689174387197, 0.25679068110979403, 0.24127608182105906, 0.2081915183896148, 0.17821838146279495, 0.4881048915512455, 0.33884664102626594, 0.13793893668997312, 0.07859974527463699, 0.18313066886582252, 0.2367386068882594, 0.13783808092687042, 0.23460488071804758, 0.21973469527294107, 0.10662733324536922, 0.2553536145751124, 0.28513601449303544, 0.24616293293709235, 0.4979007770772421, 0.3684855660598212, 0.06943597213161226, 0.16874181839771402, 0.12151247675471627, 0.09348429135351287, 0.16379697238408836, 0.13312465460219775, 0.10641975138882102, 0.44312487541198525, 0.14392052346421677, 0.4999620267380788, 0.1320116894895523, 0.20347922259024226, 0.2541295630299908, 0.1332102089853111, 0.2089754744692655, 0.28775667705995894, 0.15649707772491803, 0.1873829744937412, 0.17433746605615763, 0.24143462871342516, 0.5210074489179373, 0.14053091410835167, 0.3426535980176141, 0.41738733885270485, 0.07975540496047002, 0.15129655776287299, 0.0749770648122769, 0.32445244470755913, 0.2330663732398252, 0.1561888693637959, 0.10255276714317181, 0.21876812881751279, 0.10224159399316902, 0.30219774013335904, 0.149766858258044, 0.41226101284252903, 0.10469646226416254, 0.07784097053201859, 0.0820118786445739, 0.30684575584465673, 0.30537544356341745, 0.16454951795260422, 0.11017064147379188, 0.07278181557614777, 0.1744121492459883, 0.4613878293530681, 0.21689264357169388, 0.16701911552594215, 0.125253116745193, 0.07768280128791895, 0.11687282736699181, 0.2518123567371016, 0.2761567897729566, 0.28442183923896075, 0.17608580939421367, 0.10896733114815989, 0.18482982686110025, 0.2145550818709654, 0.34352456954568755, 0.1246418427077361, 0.13959080637866847, 0.092200369121201, 0.3902410651605243, 0.19752910955527883, 0.2774691268737069, 0.20972491783990493, 0.20510768652645647, 0.20726475924169724, 0.32444323889171006, 0.19270659123628972, 0.20266794444064332, 0.1403089048599551, 0.12104167081543722, 0.12092547987529419, 0.11032286014495202, 0.1256979477905033, 0.16057623061028423, 0.08997392580637666, 0.29679518493393303, 0.17691550350114754, 0.2741557192312379, 0.11251658275298212, 0.20061214207403308, 0.17433746605615763, 0.1081031115962319, 0.12175215220841061, 0.41117071212863915, 0.08991746644824822, 0.18249647467865152, 0.42354323886203005, 0.20094893874495354, 0.12094150900325648, 0.07392143992795794, 0.2783344709500292, 0.07175772783015373, 0.2728391948888488, 0.1340017310201915, 0.2214434980680054, 0.13899017306716382, 0.22529786555075826, 0.22963073382214247, 0.11650724327127207, 0.20013283693565256, 0.18231476847489977, 0.29163152134080006, 0.16946086677959352, 0.19869475939474018, 0.22930373966390338, 0.12273558479586381, 0.2174681127926988, 0.336888397509633, 0.116534510096451, 0.2621859344695358, 0.1421994717678145, 0.16524147896498625, 0.10560651047141005, 0.27529446216299946, 0.2641228678624298, 0.2114918238584728, 0.2766177071251018, 0.08638707207657985, 0.12104167081543722, 0.44312487541198525, 0.10979278349223036, 0.13533069078160528, 0.5138422565244447, 0.49614867772793, 0.2977281668541378, 0.1798685665572726, 0.11987345119304324, 0.4474478296476253, 0.0761584356611373, 0.12175215220841061, 0.20953101775954378, 0.17762059658494342, 0.12453263640109896, 0.173579836098144, 0.28513601449303544, 0.1044361761041214, 0.48657932130012904, 0.2323970543505749, 0.1839230383916975, 0.41097525459756157, 0.08626157834121399, 0.15909726095709126, 0.26075008542765404, 0.1361294104298337, 0.18845124201543195, 0.11941049882439225, 0.14206618018575573, 0.1921045527417107, 0.11232162140241927, 0.22527107819745343, 0.15784831205988384, 0.1779198064819138, 0.19017596966961225, 0.4000291012742435, 0.15713754196514362, 0.33914027677589165, 0.07964868742387039, 0.23226042307155026, 0.22614974902758536, 0.2363194771746918, 0.11464055784068686, 0.3048517484927581, 0.3350675216455592, 0.2919987943013182, 0.2756297400903375, 0.21299283513958883, 0.226175953882762, 0.11982441892041036, 0.2728983532281908, 0.09071758720019567, 0.30684575584465673, 0.1297829502392068, 0.18464949078710108, 0.13601019579090942, 0.22245951076697287, 0.2192120571437834, 0.1319963555949402, 0.41573739885141736, 0.5139535898886506, 0.17378626185049936, 0.26327547875932966, 0.37464485453978885, 0.07975540496047002, 0.09782313937987087, 0.35263564346336496, 0.07861562383630043, 0.2232682600617968, 0.12004485460902091, 0.11970656643826368, 0.07612938317375566, 0.20766637307627545, 0.16169762206760938, 0.06783042824609434, 0.40389332754085466, 0.26806884658805624, 0.4011819408915889, 0.20736750468205647, 0.10092599769770066, 0.18870484784336045, 0.23254993803337634, 0.48482859231766867, 0.23138069737484496, 0.5240399407415166, 0.11718859940241133, 0.15982448682239409, 0.16902511135469445, 0.2971400507284286, 0.10625146401917729, 0.3077754584462594, 0.16053147334132797, 0.22507237344120692, 0.22316049115090159, 0.5885439345133991, 0.11730071444606313, 0.19735441010614072, 0.2334866983778135, 0.2191042962661257, 0.15682639070950272, 0.46971185732875115, 0.12160248943737519, 0.13260072537668452, 0.18498179134291035, 0.08234917360901406, 0.36372807281761405, 0.28967039929278854, 0.36951289732856873, 0.12916920205023005, 0.28716916195829106, 0.31857537361272165, 0.13538007183413509, 0.11307944806333023, 0.3022525595484482, 0.12569491070753455, 0.19803823273330995, 0.48482859231766867, 0.28754577238208046, 0.28509843559646925, 0.19344006218742443, 0.11079300071983705, 0.16633161684911388, 0.09382123853424978, 0.12605543203268627, 0.3028794034662309, 0.3018505382570477, 0.11418378602918047, 0.19669326822182626, 0.09622061918880853, 0.2892351968929272, 0.23756523575346075, 0.2469414056265181, 0.09281674135645691, 0.18430219434165726, 0.12475900577114697, 0.12887543029748233, 0.25308695596918396, 0.1484565183641811, 0.1058558963182952, 0.31527669054663593, 0.12814391037814357, 0.28178882849277426, 0.20530902241541543, 0.14212623153552015, 0.22781482431861574, 0.10840931555593762, 0.2849838569887995, 0.19124938754790044, 0.21991258333339986, 0.116773691329484, 0.09281674135645691, 0.17729520607907245, 0.20726578063568918, 0.18002043559138858, 0.13122559439142867, 0.19514222532950895, 0.13320125565057028, 0.39311346560320215, 0.33767220910964835, 0.33134723837065155, 0.20014946578070178, 0.3211284776643047, 0.1291104654276855, 0.3890406694181111, 0.2634322940046255, 0.1804385931234232, 0.09699389024075002, 0.3040627812499217, 0.20734937566288858, 0.36704230768458435, 0.48203632554552034, 0.1268491168992694, 0.3068209215124504, 0.3098585066682273, 0.2509168318193756, 0.15390192480971854, 0.276945525468266, 0.5138422565244447, 0.2183151294257824, 0.31601688996168154, 0.14276534110532096, 0.311143659598879, 0.26728424046925375, 0.1441159451756663, 0.1738306795603823, 0.11201104385470274, 0.1382371121888899, 0.2397259203598256, 0.2608963461844825, 0.07742371776163555, 0.34642697075784895, 0.3180564028098171, 0.10243296156526284, 0.08234917360901406, 0.1885519183755718, 0.15159086851954884, 0.2718305606548886, 0.08965383820543715, 0.1298646191626265, 0.16089020516648556, 0.3945766569719934, 0.2237173006471863, 0.29565807517605913, 0.19180190033290878, 0.28209244050087573, 0.2116272940488101, 0.10492371830784725, 0.1878949897213182, 0.10446835870572804, 0.404218913840972, 0.20238332305876625, 0.32036773406429725, 0.1099896226394092, 0.08045441957265298, 0.15642908062398447, 0.23370777061633494, 0.16524147896498625, 0.12874044072681445, 0.5043540875596271, 0.12320776994354234, 0.07942860279702633, 0.15923259511842786, 0.11862797516393765, 0.18169258289732174, 0.19439190746973656, 0.1273335901906775, 0.13466837236558027, 0.19720577822500998, 0.33763144723727, 0.44397380699299555, 0.0815176266724036, 0.14871705988787176, 0.10317048702077418, 0.06783042824609434, 0.12757518708992646, 0.22692524897644625, 0.24193411056992167, 0.1817091645153647, 0.1460120142813997, 0.11731998691829597, 0.12189597578258578, 0.0760924665431162, 0.12065588434526435, 0.10770914767623617, 0.09051886994472147, 0.35749571945014247, 0.1666299140292663, 0.11207511572839751, 0.18926100786430233, 0.3048517484927581, 0.3681981240930328, 0.38521910887246197, 0.17998488296361304, 0.23697887917461716, 0.17789031476722478, 0.1709827447044503, 0.10640870310782631, 0.1784540209134269, 0.3959661447183812, 0.10557091066989954, 0.12112117319249527, 0.06744062977663694, 0.5885439345133991, 0.32325961354567456, 0.07172029258747917, 0.1553428314643032, 0.4645261811210848, 0.2467075266853337, 0.1651210790146167, 0.40452516626811474, 0.1865076888196176, 0.2199959011381188, 0.17840370323653557, 0.2990322234654859, 0.24293836192636586, 0.49025183991330656, 0.17664859458026014, 0.11207511572839751, 0.289125045155276, 0.12274501024801536, 0.10218583053356352, 0.14875935687302785, 0.49503679284975993, 0.20063904500672156, 0.49614867772793, 0.4132224400260449, 0.17338374832155956, 0.20173236115361956, 0.28882320374719583, 0.2011229050940048, 0.5885439345133991, 0.49602160789905725, 0.3527087601487063, 0.1295714287480497, 0.09225911774352888, 0.2741806892721291, 0.35616567795162113, 0.41182005274640365, 0.1285974986587533, 0.13487759045033343, 0.10726503970763951, 0.11150588763472073, 0.10337073640974198, 0.16028441921753125, 0.4299247008604986, 0.26665040449592037, 0.16756782609503149, 0.18577090322760015, 0.09823776457386968, 0.17026354980090597, 0.18496408758030125, 0.12929932416364248, 0.3020130893850102, 0.23210531632013964, 0.5240399407415166, 0.10675602412014934, 0.11050815167056062, 0.23851131658660152, 0.14646215857273237, 0.43651836684314216, 0.20541065372194794, 0.16867690650163367, 0.13044212594646545, 0.1754460974209526, 0.07848427652460083, 0.2230634555703951, 0.38428453146087665, 0.37039929112808295, 0.16333117251813012, 0.11117172482307684, 0.24218317500488326, 0.2891784317489502, 0.22300854215108548, 0.18298117746085407, 0.20571969396934298, 0.10777227948362067, 0.2609617104284031, 0.08045441957265298, 0.07859974527463699, 0.30198332867631034, 0.36059678087250185, 0.09483421838434511, 0.5300961204343363, 0.31292804565332133, 0.11521031049208759, 0.11543324224146513, 0.2756297400903375, 0.10494935606513839, 0.15680841284797586, 0.2537173559437796, 0.11973774546481468, 0.198260252566716, 0.08245774042627389, 0.34021896656470557, 0.08911049545627839, 0.2636940001232283, 0.28524355350538755, 0.12148312951940961, 0.30198332867631034, 0.2126137947654101, 0.09586114408092833, 0.1179366625346746, 0.1426974360718224, 0.13341746533384044, 0.19596289406022602, 0.3821864202850278, 0.08667374435985034, 0.22454975590510218, 0.5192581283434271, 0.5267141769173918, 0.46123119497598936, 0.08062885325615317, 0.393157452134415, 0.17802559688393949, 0.2096941211220352, 0.19842438378515248, 0.12284040103928538, 0.18831536583758052, 0.16774990688120725, 0.27062917692127264, 0.3452638129852844, 0.15875434363659863, 0.18851430409007897, 0.36381330422091945, 0.48100399784080367, 0.1036504360889866, 0.08020429047606392, 0.07430662651039839, 0.15858294374424695, 0.1646670895388734, 0.21984812540844728, 0.2761567897729566, 0.06812187930508513, 0.2652587600746443, 0.10956545457353756, 0.1908080312856637, 0.2808221790899922, 0.186898442166769, 0.27875995616025817, 0.09808618941251641, 0.13768506233997288, 0.18168336027603535, 0.0821591211022933, 0.32211779648607214, 0.2147603898298754, 0.29853982537847834, 0.20601039515124342, 0.40452516626811474, 0.2208909990091681, 0.24027443691711817, 0.31062003800627475, 0.11987251266393316, 0.3321120604993994, 0.10672706084585802, 0.13380754090213948, 0.42758471024525957, 0.25832470378902017, 0.16722733044253837, 0.07780062771857363, 0.1343455466209425, 0.39060174118956226, 0.07768280128791895, 0.11273372452420677, 0.12008352708299908, 0.11922580916354195, 0.2312715887910288, 0.46450546024999084, 0.11297347107623398, 0.5300961204343363, 0.12776240174575088, 0.2943401792845017, 0.24653522501130506, 0.3724469977861641, 0.15890417426852346, 0.11321137657735651, 0.19858920482878914, 0.11226167976078598, 0.2114536762341987, 0.14451684704119877, 0.3817904964107684, 0.19669326822182626, 0.21044574026455237, 0.3454935492220036, 0.0893093730175525, 0.15230190448674533, 0.21237680254378669, 0.16430871080010886, 0.12895308561209, 0.24767958721357258, 0.5227833488640741, 0.07540126008077105, 0.1319963555949402, 0.14052231350143704, 0.31817492915434253, 0.3144340513922828, 0.11599734349201087, 0.20347922259024226, 0.44386378924688796, 0.15081306136235564, 0.2773285576272151, 0.15555943194497496, 0.1001532569653127, 0.08509848241383958, 0.12431929072927393, 0.15494182744418164, 0.29171016812693923, 0.18379113803177638, 0.17252808260071745, 0.09309517055038427, 0.320597079265728, 0.20784939718817352, 0.20449117793648916, 0.13388083711490023, 0.08081273119947333, 0.09717645487772979, 0.23166914926809876, 0.30537544356341745, 0.15302918170156626, 0.24432857735635832, 0.11781387182399851, 0.49602160789905725, 0.23163399680712354, 0.16616584888179434, 0.13881776936285398, 0.37661355274687175, 0.09508115775274836, 0.2232682600617968, 0.17801731891794922, 0.10462962849476078, 0.11268110004492544, 0.14823778576264438, 0.16075041102377102, 0.46450546024999084, 0.1625696656316073, 0.14639587205931442, 0.08384439954773747, 0.07810729832726178, 0.12242011300196019, 0.4977177948963284, 0.16420971680433827, 0.30511629976842164, 0.1498309422439771, 0.38131937565042423, 0.3902410651605243, 0.1958620417919708, 0.18854140064471958, 0.2189674358288966, 0.09218949784946788, 0.21689264357169388, 0.5033548833113098, 0.15061949159383292, 0.51220262723774, 0.13790826217482985, 0.3441556441727742, 0.5885439345133991, 0.16483456792257292, 0.2941500268524819, 0.19721417931518775, 0.5267141769173918, 0.23304898093121681, 0.11651443748238302, 0.3320886035118465, 0.2530942159253586, 0.1230562079480442, 0.12472157487300561, 0.16098371731261021, 0.13790404552199392, 0.20345114455172691, 0.12151247675471627, 0.2918695858366135, 0.49935852313555745, 0.1948146385486331, 0.43798694072940053, 0.13494943534455464, 0.12547331142365822, 0.18492995013627433, 0.211315639416962, 0.21114821669092843, 0.08829884346629013, 0.08150393778563012, 0.20608174287290743, 0.3156365605990959, 0.11575809860787657, 0.13977300288984648, 0.26705963934318083, 0.11543324224146513, 0.3103495108864638, 0.15732359844607338, 0.14428306117203474, 0.28258289550145405, 0.42127878179140177, 0.25238573103368855, 0.1583648025353103, 0.06812187930508513, 0.1759697154146307, 0.11215370661880096, 0.2680171704102846, 0.11522020403306639, 0.07175772783015373, 0.25306480779670004, 0.2766165395332622, 0.11987251266393316, 0.10973829059448544, 0.2454893804269376, 0.25267229268007757, 0.29480062626782677, 0.15726641406784747, 0.21995283166410948, 0.40880390306691, 0.31062003800627475, 0.15719266226731818, 0.1305207585857277, 0.1673717975002061, 0.22154147509726574, 0.23294492833723357, 0.3270669713601086, 0.22856796457859532, 0.39103749826493384, 0.19082423405280008, 0.3666544094653956, 0.0816218884415584, 0.1276854429568149, 0.22837399367788352, 0.5240399407415166, 0.10677008915125712, 0.13397009983698493, 0.4254436438595713, 0.2133709621468004, 0.15380230268829342, 0.3429481251746607, 0.23675939998330256, 0.11918171179467278, 0.10840931555593762, 0.13540625414150784, 0.11309123410660517, 0.11436813203707795, 0.12389720538035075, 0.12106923881786034, 0.0774285096006695, 0.30292015806409506, 0.11032286014495202, 0.24299937982170605, 0.076429266317353, 0.09620946704773295, 0.22580063028836495, 0.09494606692965736, 0.09762866590396252, 0.15752482709954224, 0.116773691329484, 0.17174702627148508, 0.3033685294184925, 0.14807882689599874, 0.13341069973956116, 0.1686562531809447, 0.16054157232560456, 0.10467186041470963, 0.3312941703823481, 0.4739428453102785, 0.22947913513057894, 0.11918171179467278, 0.160807424898374, 0.1338637074153935, 0.15484676677680395, 0.2065056401164324, 0.2267792790093242, 0.12962227832948678, 0.37464485453978885, 0.22554871911333615, 0.28641345301514415, 0.43540466491005864, 0.08207046556908967, 0.3179232969447762, 0.3554973887554903, 0.17339173018690782, 0.10240608132857294, 0.21751221319149341, 0.14764775992856286, 0.10956545457353756, 0.20993788236701322, 0.07780062771857363, 0.09034191963741428, 0.21824339418646962, 0.19300719128745386, 0.1203065525926804, 0.2818258232951875, 0.1824935832603482, 0.12064382225544058, 0.1207289001340605, 0.2687198200578348, 0.21475978497701492, 0.2123341573117277, 0.12352301439292611, 0.12870237722777367, 0.29211777628188107, 0.15105755349092342, 0.19723557910945677, 0.1047380742313498, 0.2085655302311944, 0.14256404196366593, 0.1384369940690863, 0.24269927688859633, 0.19785448086778548, 0.16464575330973824, 0.15307437465219628, 0.22580063028836495, 0.1227941126854549, 0.12936866709261508, 0.3495761351862624, 0.1641577841730944, 0.3089820892982143, 0.17455051887673678, 0.15658105412985662, 0.5082637954261032, 0.11309123410660517, 0.35749571945014247, 0.09689195184987258, 0.09596162495653231, 0.12601511175875402, 0.21021423140115733, 0.2502444082620506, 0.29806501313331785, 0.19108722212103055, 0.17984946757210457, 0.11736315035403179, 0.14811388750515264, 0.3234413019550815, 0.22192110153058192, 0.19598884355174087, 0.116773691329484, 0.10687419031403456, 0.07058831692865238, 0.06783042824609434, 0.15729215676763816, 0.08337005551358855, 0.1534771046782513, 0.5082637954261032, 0.20648192807251023, 0.0919635001371414, 0.2919987943013182, 0.23230560344011014, 0.1256979477905033, 0.20789548370405753, 0.20090678963296693, 0.33461592911112836, 0.4689190303818471, 0.13346047162341015, 0.20075199572868538, 0.17111448369140186, 0.1685573131414594, 0.11180586556554731, 0.10768205783555758, 0.08501345711136425, 0.2295522115241078, 0.15558949128237107, 0.2237173006471863, 0.11225698885667638, 0.18028545114240133, 0.23460488071804758, 0.30617402548134043, 0.12075845976065072, 0.13635369597596148, 0.31527669054663593, 0.09596162495653231, 0.4430423439331548, 0.13227272816329214, 0.14466895989379033, 0.1222171544708591, 0.09959976404372776, 0.23913482977642211, 0.20385730337598051, 0.2562757847316549, 0.07352352199044845, 0.42326052590681484, 0.13738028324361504, 0.09917287680581059, 0.233205494223331, 0.17801731891794922, 0.16497073656953498, 0.12160770246290013, 0.27459110806014847, 0.1586168662934718, 0.11226167976078598, 0.17012195848559902, 0.10777227948362067, 0.13620127224544468, 0.24579274941476797, 0.30902495780826555, 0.12475900577114697, 0.13198615049522558, 0.2189674358288966, 0.1445416633327452, 0.3691674123946346, 0.14120288449807367, 0.51220262723774, 0.23733982247433785, 0.2271627693771663, 0.17082482516687675, 0.08433965574754951, 0.25118566669557046, 0.07452495419409265, 0.13138172745023458, 0.1942431245942423, 0.4269205359652847, 0.08067370830724062, 0.1550391433102166, 0.17720219032709783, 0.12104167081543722, 0.11050815167056062, 0.10486098728637905, 0.13766058570023665, 0.18736831547238403, 0.1776360384925922, 0.24127885981203254, 0.1578375866286394, 0.43379199502250987, 0.09543787633923442, 0.14723352410561352, 0.20712151433471054, 0.10777227948362067, 0.1838091600430512, 0.48482859231766867, 0.31264037432773506, 0.2442118666670605, 0.19854699645748913, 0.2534405992283941, 0.12612886432001427, 0.14074614091888193, 0.22674454520652731, 0.28894255864376084, 0.13604494151736557, 0.267961151252289, 0.3234413019550815, 0.2989691484059586, 0.09823776457386968, 0.22317607107747803, 0.18350402227461776, 0.10492371830784725, 0.43115975133570195, 0.1593251814500269, 0.35338790717258917, 0.31036984657285105, 0.12499731822679876, 0.11918733160314357, 0.1994997108668515, 0.06943597213161226, 0.10264058291884016, 0.4409300063804416, 0.13824448023660404, 0.16403003475199623, 0.10704766632270908, 0.19037100099597204, 0.1759697154146307, 0.17626366184254202, 0.5283499443434283, 0.07194631480332603, 0.11983742217012279, 0.13258940775482395, 0.34781461956774995, 0.38246726616532417, 0.13388495070086656, 0.19402927314446386, 0.21775753398582734, 0.12365944028229457, 0.3299370962827493, 0.12202385864109562, 0.07175772783015373, 0.07058831692865238, 0.11922580916354195, 0.17241212607986875, 0.14060917778990858, 0.19102255755868924, 0.3161661229548991, 0.11266241980219732, 0.12535807136101265, 0.10243296156526284, 0.15488349463756035, 0.28656676119994495, 0.23563293312416744, 0.22919289103087143, 0.13988153417952634, 0.08605348907340196, 0.14529114474978605, 0.18632235968354133, 0.11726439406240712, 0.1420143744702325, 0.3270997387584947, 0.15686688027079068, 0.11973774546481468, 0.148303460203194, 0.23129289478925177, 0.17671425002805258, 0.08234917360901406, 0.2762437088247078, 0.12870538087714103, 0.11489809399206599, 0.10336681247613326, 0.267074050311456, 0.2477659272389369, 0.09646506903259922, 0.16677340355598702, 0.1110492630141913, 0.160807424898374, 0.42988745553034463, 0.14475253615220843, 0.08020429047606392, 0.2953899417798576, 0.13703259602799936, 0.4156432294824125, 0.2142785202636358, 0.0761584356611373, 0.20464635722458072, 0.1901142453706201, 0.1698022178034898, 0.17280733384619398, 0.1398678557953579, 0.08119204022299202, 0.2171347631925701, 0.1701474893964483, 0.24652528557960537, 0.10478338382393143, 0.10336681247613326, 0.2894861224021739, 0.07210016122179097, 0.15328152192316946, 0.21182460103360676, 0.31099004250727635, 0.1263725565889183, 0.2537574837930899, 0.35150286930922103, 0.1803269919686432, 0.11922580916354195, 0.5192581283434271, 0.36961973832022765, 0.21732706005158015, 0.1170973575661308, 0.25856258071504046, 0.21209215189367112, 0.5267141769173918, 0.3229281688088031, 0.20238332305876625, 0.08905113569108665, 0.4979007770772421, 0.27952476724831554, 0.07309835494302722, 0.11056364028026384, 0.10049198194955197, 0.09986310004376409, 0.08070131201973019, 0.12190511563022444, 0.28509843559646925, 0.1647096258424622, 0.33763144723727, 0.23276830960052375, 0.17757823725090177, 0.1849809000172558, 0.41573739885141736, 0.36400440440957504, 0.3724469977861641, 0.25162132561338185, 0.13520982199784645, 0.1071639464133845, 0.22023983442209913, 0.31575397013137424, 0.27669663531899497, 0.10519188235813498, 0.17005832267353738, 0.3902410651605243, 0.11772893515138326, 0.10777227948362067, 0.14814729054075793, 0.1486189452225744, 0.20277493109012637, 0.3131767424887724, 0.35456013705630357, 0.07210016122179097, 0.08020429047606392, 0.10875317752968051, 0.3756314254177673, 0.17132973999087717, 0.08332744535514466, 0.21952750509081057, 0.19886620431008178, 0.43798694072940053, 0.10331403048622402, 0.14185890853918381, 0.1564305124233148, 0.1362235893981405, 0.12273558479586381, 0.28388835794746964, 0.31468625350429325, 0.18680089569771685, 0.1971638679446732, 0.23764696418569714, 0.11807150184614619, 0.3708103335939426, 0.23494054283429588, 0.07400008905592859, 0.33763144723727, 0.3809390587532736, 0.23666869046143657, 0.0764538818804806, 0.17586481098848525, 0.11464138358229195, 0.3233049237017126, 0.2977934237932881, 0.3907000499562065, 0.21163562775366362, 0.11973774546481468, 0.2610180675276923, 0.26870395921399015, 0.4575425330641055, 0.33426963817898825, 0.20098036715892692, 0.24969510932296732, 0.184573851979461, 0.3760191296640524, 0.4743555946180752, 0.07904268509826128, 0.1302411480867958, 0.20148192207702417, 0.1793927409184479, 0.24206843111752954, 0.35520487436515763, 0.0795865519199926, 0.23745175412469038, 0.1796089567713644, 0.09135860720714166, 0.18584742787212863, 0.10049198194955197, 0.17168464505644035, 0.5192581283434271, 0.2806073465161222, 0.116773691329484, 0.31501977721582947, 0.1285358615055808, 0.3708103335939426, 0.13320125565057028, 0.11954413570140612, 0.1626285431932247, 0.1271722328457227, 0.1935963952899105, 0.2012592286198541, 0.1846664420877548, 0.3041177846840176, 0.15553477583956993, 0.18055022408313387, 0.275306380713363, 0.1453930125839577, 0.2736000534419348, 0.12709900616500086, 0.12152343078340927, 0.2574406274951888, 0.14828642264744524, 0.26634408834421425, 0.19277249072100835, 0.1507047953788407, 0.14185890853918381, 0.21390214044007796, 0.368437914338321, 0.19953667081540113, 0.5885439345133991, 0.09931495000733193, 0.18384791546999252, 0.1129741061294057, 0.20338439438592149, 0.31978453302540066, 0.1258696982818358, 0.1714545672747416, 0.15206249312540474, 0.25086288842567567, 0.11520902813539152, 0.1502653509949649, 0.13605428332487177, 0.11373769910953475, 0.4422443296987556, 0.10411993103282309, 0.24798343902365969, 0.20957835266216168, 0.10786846812220385, 0.2919987943013182, 0.4847145042981084, 0.446976329457549, 0.21566935771019352, 0.10049198194955197, 0.4391280856750502, 0.07699519396624196, 0.11970656643826368, 0.3787973451912618, 0.14858125708471517, 0.21772917230387054, 0.2795415073059046, 0.22897490079305494, 0.1255591694786527, 0.11256211846834473, 0.24286809873859344, 0.2849838569887995, 0.1116965996772654, 0.3077953807522802, 0.12409910214230825, 0.23357065299829058, 0.1796089567713644, 0.2556264685955808, 0.2686069703086634, 0.19248541235094224, 0.10126869669850294, 0.42317751391989655, 0.1849809000172558, 0.14816634189482542, 0.1305207585857277, 0.2490030759585289, 0.10494935606513839, 0.1238169487560856, 0.11222152349586055, 0.3702326917729453, 0.23780004241965785, 0.17134992530361226, 0.3590045915297311, 0.27106428055120374, 0.2585806610996551, 0.13468755785102968, 0.108131975982505, 0.07434530360224087, 0.44386378924688796, 0.12546993949907043, 0.13295701962918932, 0.3743761326655826, 0.3108799561330804, 0.22399287738145482, 0.16197268246131707, 0.5283499443434283, 0.06983118436908042, 0.10444702765085928, 0.3787973451912618, 0.07413363578799025, 0.27517953247430826, 0.23972231126252738, 0.2605349571338436, 0.20907643816885185, 0.35139723866133193, 0.07392143992795794, 0.0795481031878506, 0.244474293490962, 0.1238169487560856, 0.1398130141541215, 0.0855265355933565, 0.07689186115886, 0.15015541882849112, 0.1784540209134269, 0.22317607107747803, 0.16824512925903498, 0.08393539192740779, 0.14378855434813048, 0.1670159101419397, 0.18047424178427315, 0.3008999519489939, 0.08020429047606392, 0.108093134010225, 0.149171975408971, 0.10161563612796576, 0.12356172486990373, 0.12274501024801536, 0.19614104150402933, 0.20593261709690988, 0.11922580916354195, 0.4195710006634318, 0.5210074489179373, 0.11589164097725281, 0.35263564346336496, 0.16504938727315174, 0.3762723125701621, 0.2784353643348185, 0.2322975792145291, 0.10682054340792646, 0.16614563315821246, 0.2102033869009271, 0.1120504267111088, 0.4228796759223299, 0.1984742291873472, 0.5885439345133991, 0.1307401615785778, 0.23090588352491725, 0.1754091963310304, 0.3124938091186554, 0.07917092950448301, 0.12521059146753225, 0.08821433088101639, 0.43431156810374333, 0.11126843337382182, 0.07194631480332603, 0.40880390306691, 0.15709192354518733, 0.25212983858418364, 0.17388031656818784, 0.11489549340588201, 0.2727197818400175, 0.36381330422091945, 0.15390192480971854, 0.10826430882981739, 0.3492983441246116, 0.272735039556892, 0.42117012803563963, 0.2189674358288966, 0.2461823553140721, 0.19123262698450882, 0.279164576566039, 0.3779290627576653, 0.3085058870458409, 0.12413438130081657, 0.11255676721513508, 0.2584524294026456, 0.35106289517619615, 0.2942876249896051, 0.20551366638429241, 0.5016837497095513, 0.19998610109015458, 0.2593322436760958, 0.370880818292623, 0.1857445318314441, 0.09882967652121086, 0.16593068307270542, 0.2858536500783285, 0.1369352364259806, 0.25091016766423696, 0.09968770047247953, 0.20914576101574958, 0.23796022125862445, 0.13312465460219775, 0.5284610041868364, 0.28263728618640394, 0.0981452713288138, 0.28202433428921625, 0.2499179413759246, 0.21702361861945438, 0.5885439345133991, 0.13341069973956116, 0.1460120142813997, 0.1821483564135784, 0.13198615049522558, 0.10112938735727277, 0.14788591512507532, 0.36363934426792716, 0.105874866761894, 0.18349367130812258, 0.12882007114821334, 0.11114907464058159, 0.13442678444447165, 0.22100831412443422, 0.1403307330987273, 0.13250815096438853, 0.1405187792214667, 0.1923549170459913, 0.13762078999899957, 0.20402384156225822, 0.1977115966496774, 0.11469090050002274, 0.0818552228362895, 0.2295522115241078, 0.3945766569719934, 0.48806453270746464, 0.3759145666226724, 0.16537407257405257, 0.15906938898115577, 0.18192506369916667, 0.09401555763528599, 0.19296268504679828, 0.37475116164349903, 0.10552271519783522, 0.15432800347073408, 0.19017596966961225, 0.09751493687945384, 0.14553280377922928, 0.5284610041868364, 0.16483456792257292, 0.132801691733671, 0.1536272866725234, 0.2737838212534315, 0.11099242771957603, 0.07172029258747917, 0.13506371639991746, 0.07988175506234814, 0.18058343159326207, 0.14338999975196423, 0.13723863985687412, 0.14748080911671763, 0.08239166430583025, 0.1784540209134269, 0.10556259776095919, 0.1724860625990188, 0.48203632554552034, 0.23563032228680963, 0.13672688109479314, 0.2623288169705052, 0.11736315035403179, 0.15909579075562075, 0.25652490545162127, 0.0843106987830313, 0.080017373700902, 0.15952027119590168, 0.5192581283434271, 0.29206159212756144, 0.10274376002931575, 0.2021943366704447, 0.24677002732062545, 0.10511545739519149, 0.3086469632862065, 0.1772451427355914, 0.23429915610805863, 0.15275760700770083, 0.40552797251722267, 0.24413823256504666, 0.2870720168051411, 0.37098713201116773, 0.19357946645165122, 0.13134367628560253, 0.10712908642303078, 0.105874866761894, 0.5240399407415166, 0.14852190395161252, 0.49614867772793, 0.13132286427845322, 0.11216705438575152, 0.1643586856488033, 0.11211697131313274, 0.1868851475674176, 0.3048517484927581, 0.49614867772793, 0.18498018654503148, 0.07141462598745797, 0.11890240731653705, 0.1772451427355914, 0.19689777467463937, 0.08272973594321673, 0.09158812676983855, 0.09821670466626188, 0.18544011492244752, 0.14559055392234996, 0.28995623137124116, 0.13104791771459004, 0.10365574027324347, 0.2325102338060181, 0.12706392841839853, 0.4743555946180752, 0.1785559374436098, 0.10331403048622402, 0.11694702352892272, 0.16410815749149912, 0.1246418427077361, 0.323141595578027, 0.3124938091186554, 0.116773691329484, 0.12302430715610552, 0.10080228825160377, 0.14935707952771468, 0.24407029584710815, 0.1694635482021424, 0.2923854775052891, 0.15855236603531003, 0.22441799544238758, 0.43115975133570195, 0.11268110004492544, 0.3082301771054899, 0.170219891045747, 0.16003816726798506, 0.0918203991495278, 0.182323065669285, 0.14559055392234996, 0.24146727310623833, 0.17475535317677146, 0.27236299516499435, 0.07352352199044845, 0.14267352351820797, 0.18806387144399864, 0.2488789745304074, 0.11154230486732096, 0.19054220207695874, 0.17180715240478894, 0.2973486747994152, 0.07975540496047002, 0.1338421930155298, 0.18781947840761073, 0.20038620244017324, 0.21145848618437352, 0.11308188598732014, 0.12351973308655777, 0.3823645209446136, 0.1864431610142796, 0.06744062977663694, 0.07235470432279204, 0.28942513615678556, 0.4058821711863738, 0.10373462194057155, 0.1772451427355914, 0.2532044614219256, 0.10988036088876625, 0.22607831564247977, 0.10961745651477808, 0.21762490704910278, 0.11489458862376604, 0.5267141769173918, 0.06812187930508513, 0.2737838212534315, 0.24966132165259497, 0.07141462598745797, 0.26131001140232823, 0.12065588434526435, 0.16674334216073614, 0.3947411578918653, 0.08677809250651745, 0.16773736076918425, 0.1067599456778228, 0.49614867772793, 0.15620740590451654, 0.17931347541260587, 0.1996986282099087, 0.14692772041864302, 0.07522899119405212, 0.49614867772793, 0.38310045587126623, 0.17608580939421367, 0.1074871497105629, 0.203125002303072, 0.1251151453212273, 0.14559055392234996, 0.07882307920212774, 0.2685801718936502, 0.12175546103574196, 0.19334946865562866, 0.13134367628560253, 0.14764775992856286, 0.4999315928897711, 0.19878892976359666, 0.07780062771857363, 0.1464119850245881, 0.1312108150674331, 0.1048952743317372, 0.08020429047606392, 0.17897715913871887, 0.2078742864770805, 0.1637348224536747, 0.23405905893224263, 0.09959976404372776, 0.10933572675950898, 0.11731998691829597, 0.10511655698720031, 0.30198332867631034, 0.21504974745014577, 0.08645778878579516, 0.1614716775778332, 0.2285395439596421, 0.22291650224582166, 0.30520108064768986, 0.11937851521984642, 0.37789472372135785, 0.2986712697994747, 0.3213779795073414, 0.108093134010225, 0.1214940351932152, 0.28513601449303544, 0.1878969100735005, 0.21161027146714995, 0.1323301796040772, 0.15660774448391096, 0.11800599474931986, 0.24654410910834615, 0.2923854775052891, 0.18926100786430233, 0.24168827939588058, 0.06812187930508513, 0.21922892358716187, 0.11682797548319869, 0.12757518708992646, 0.11708785846085322, 0.21840931823712348, 0.2142017683266767, 0.42354179532307085, 0.10457027756519507, 0.10365574027324347, 0.12231049743397093, 0.1971586369921185, 0.0818552228362895, 0.18673226822045189, 0.37464485453978885, 0.12374971501867964, 0.12665803367681872, 0.29370288617997226, 0.2610718874018624, 0.1958620417919708, 0.13904993698880144, 0.1343190120569148, 0.10908431884981919, 0.08548104832779573, 0.10777227948362067, 0.09309517055038427, 0.23507403673738053, 0.21912297927682364, 0.4497028857110984, 0.25899179730213157, 0.20385730337598051, 0.07070100449593564, 0.1508999386137619, 0.2851796048119685, 0.1900607716026185, 0.2825422725631446, 0.07699519396624196, 0.17801731891794922, 0.3831917611680925, 0.4527211344030608, 0.1258193766443443, 0.33905576019430256, 0.20405601336735166, 0.06812187930508513, 0.3112050755018704, 0.14824612550060326, 0.18250289747053547, 0.1379224676595406, 0.28632237370842634, 0.13028966903816389, 0.13454434520088487, 0.13109881744008034, 0.1658684809531923, 0.3217983868526277, 0.17282743871246115, 0.32291816077244717, 0.43353102348785155, 0.14263744363166078, 0.18238068666522467, 0.1985385973607362, 0.1811754217549962, 0.3029399054911247, 0.24059487350448283, 0.16343750580127056, 0.17046576702214183, 0.07235470432279204, 0.22125863586004288, 0.0744500071362869, 0.4144287205397152, 0.085417576837741, 0.16039866648815368, 0.1844292624737169, 0.1622972961133806, 0.21723644984089077, 0.1119577619666338, 0.12210945103433714, 0.17687511769732647, 0.1398130141541215, 0.10521853477884717, 0.11955035581824143, 0.15725303004427263, 0.17867036301298303, 0.1277013084774675, 0.1457318066088493, 0.2692915623423681, 0.0860730887074006, 0.29308274120712563, 0.3308926730989713, 0.20965702747231751, 0.165864151029222, 0.3744980545396318, 0.144997746346865, 0.1970941715435769, 0.29243303045715185, 0.2033889185902952, 0.3696351217151315, 0.10570841843707693, 0.18024422105997945, 0.13492639808058154, 0.3229575220026843, 0.12951993032651798, 0.26499185599571107, 0.1426234118934099, 0.3032544384786644, 0.10742330571582828, 0.31028572651141567, 0.1125557430073872, 0.3358049430285387, 0.530515818704632, 0.3121190580443248, 0.10283091633829194, 0.07900952741715103, 0.3154574556024836, 0.27191631924086374, 0.10536674422966814, 0.14601680641140638, 0.16914055214773657, 0.23309299711582226, 0.09811233236276988, 0.15162095660214236, 0.22661858869473028, 0.33344868364406477, 0.19645407435191345, 0.285922673250451, 0.23756936403778212, 0.09893245364465592, 0.089489257255462, 0.25308143746078976, 0.24548238713072806, 0.3556623954891565, 0.2208551900175127, 0.43273522317485413, 0.14708012669468262, 0.47826652487746785, 0.19000391813411785, 0.0895793149416112, 0.35084452192312626, 0.2103233390120088, 0.20156570215401196, 0.2445175865050521, 0.1438594531071438, 0.26085890866784667, 0.22249144159607137, 0.26704412361338753, 0.155955916144649, 0.10656207240800042, 0.2622941585904637, 0.5005424504941136, 0.23680513795928004, 0.1643035188885836, 0.10113919024998551, 0.2087893063142531, 0.30432269964157105, 0.1421004904157481, 0.19468051243670323, 0.30982442233101254, 0.10235198207794302, 0.15266254483933597, 0.08111052624229526, 0.1950459577343706, 0.17624281539849126, 0.13876807911032588, 0.25823714740610837, 0.31242672668784516, 0.07960273038931341, 0.10592436878608003, 0.1718638204685246, 0.18634300807662615, 0.27288251018708, 0.15033659650992334, 0.15774053372264576, 0.41289366399383115, 0.25950974811193256, 0.157585011919441, 0.5693655086686017, 0.20533739789225638, 0.12863936999062917, 0.34707899061968406, 0.13914151095237, 0.1290357023588819, 0.36297294871907926, 0.2866919630438502, 0.22104320627097462, 0.12324600428838177, 0.31573897571765225, 0.09480806921560905, 0.18355082906047016, 0.25633061330914203, 0.175796848004689, 0.5676103904224539, 0.26325016769757875, 0.2556224311385908, 0.15600901714879623, 0.11240608826945923, 0.4892774922528369, 0.43143683202929356, 0.08916562210065516, 0.3209361335661749, 0.39916226445365743, 0.5062057488495489, 0.28454226784988135, 0.14744149868351178, 0.1265204450956462, 0.15807344573910806, 0.3561541919023432, 0.0981799163496774, 0.20732386105223596, 0.13758698007606227, 0.08391991923409912, 0.14338015439619767, 0.17733174303576327, 0.15129322614553142, 0.3060659372199056, 0.11182344674526659, 0.12080258504038133, 0.32801861051493225, 0.22583121134270542, 0.18288894519476454, 0.16028460312074794, 0.20541094820004285, 0.4864480859551052, 0.12554340754589413, 0.21291693149283292, 0.22014412861312954, 0.1928955820682981, 0.08137466540224762, 0.581573341970609, 0.158154042906516, 0.21637207528583938, 0.10564358648040814, 0.11708796774944509, 0.07842074052508247, 0.2615011326942835, 0.2059938493464377, 0.41540809124157185, 0.08348478153410147, 0.09659959809224918, 0.09489046970761383, 0.11528046651772371, 0.2318424862276752, 0.15541555782469813, 0.18064633073082048, 0.43273522317485413, 0.14073350776444177, 0.1272902051861624, 0.38284206465850645, 0.08168868306496127, 0.09489046970761383, 0.290275603276264, 0.11578669680179635, 0.4349993051812495, 0.48307084379793763, 0.2604963838128292, 0.33820663833454917, 0.11002973627209373, 0.10245187833082475, 0.2993445478557408, 0.14888273979300296, 0.32526008707535253, 0.1483598267415715, 0.25060007775740323, 0.19179114149022025, 0.15997763436740722, 0.09767866321200573, 0.15628086523274548, 0.1495095212158963, 0.4648934396739465, 0.24347448138968203, 0.10808925419323254, 0.11118185740180503, 0.09564964959042344, 0.10698743669161229, 0.10270250146428307, 0.4080178813885962, 0.3778127788066039, 0.14783679415143633, 0.09628895226792367, 0.21538578629936098, 0.14186877261273115, 0.1838801518382188, 0.13559403259702132, 0.0869770416608111, 0.11419178620235122, 0.1970033913705819, 0.1912083359214019, 0.27909786500531286, 0.17002662611548927, 0.11814867631251635, 0.19828177398639163, 0.2220069933681192, 0.2177400111134246, 0.18444732789392224, 0.21604272785153467, 0.4246362078020467, 0.2435067145170179, 0.12012145590491122, 0.34422844009028886, 0.24579867737465264, 0.09035657628978697, 0.17228725975276132, 0.581573341970609, 0.10262156513772296, 0.17998862938295299, 0.11683142000522374, 0.2209608568913069, 0.3477247000271902, 0.08313645366451355, 0.11400403488880213, 0.1445738908829828, 0.14293312197286626, 0.11006170105374069, 0.13222680983394078, 0.40235292248928334, 0.26543625747938515, 0.188060530733776, 0.0883160627400469, 0.3426916834605597, 0.5217726801783739, 0.131047398895532, 0.12593532435680568, 0.17006734164304477, 0.12536770753930712, 0.23136164668445036, 0.11127723802043774, 0.20293806048215532, 0.21231390677298675, 0.3209361335661749, 0.16604707350596407, 0.581573341970609, 0.09516038902588801, 0.09337727681778547, 0.10410057249516264, 0.17816161794944882, 0.1174869970549314, 0.27413310324961065, 0.08688834677071788, 0.45071432277301615, 0.10581420842318352, 0.22010274602533184, 0.26594397949078674, 0.23755251433465244, 0.18441191424793438, 0.09704567422258917, 0.18288894519476454, 0.1607463240870131, 0.12584434150728532, 0.20985381826079538, 0.22946300713092482, 0.22752614696369125, 0.14723708957337686, 0.34197157022727775, 0.09911969742016861, 0.08909544849964182, 0.4892774922528369, 0.17419997018068378, 0.18505180806001792, 0.3326471519146407, 0.08416028419372736, 0.1360644640907346, 0.3121190580443248, 0.08522164157726764, 0.2200551436882639, 0.3555951207491793, 0.30314976250798364, 0.15490443802477583, 0.11186441077917132, 0.3226591919733774, 0.28154757610525366, 0.14502228436851833, 0.15163185278827185, 0.41042286100150205, 0.18370017382619472, 0.24119372709960346, 0.4746162024194521, 0.2148355041001209, 0.08869727197956209, 0.12235931566919847, 0.15771327106454044, 0.08946316746566785, 0.20062744884842, 0.15098738072714749, 0.2246128260689475, 0.20705571638735742, 0.1792803178148213, 0.19179114149022025, 0.1886226296188395, 0.12810736812828627, 0.10964869437162862, 0.15058516567631136, 0.10849720948195657, 0.26698027384083883, 0.15576305481496489, 0.25784043067181767, 0.07664212306872403, 0.20211941561971258, 0.1526843867287427, 0.43143683202929356, 0.10251196087720806, 0.09705368530782554, 0.21958987536905322, 0.10754974310914252, 0.19445522094764883, 0.07817944001586198, 0.14706112992859519, 0.2566665929362667, 0.18132648121215716, 0.12089376703623295, 0.265536717745179, 0.13126831800598046, 0.29331168344339315, 0.3378965601959633, 0.2051054578053823, 0.16821912682135337, 0.5386394814686629, 0.20524371856128049, 0.24397341099118636, 0.1658699975801241, 0.1598886077137299, 0.15427821188349022, 0.12359187872830868, 0.18618021439160834, 0.15901399412341566, 0.10354358047387928, 0.298903979735031, 0.16709366361509653, 0.17558999845866136, 0.13518051239518855, 0.17415146090052686, 0.2776820370701776, 0.09950731513205884, 0.142001717518172, 0.23192126163644805, 0.3299966368685384, 0.13521440711296545, 0.08432936601726441, 0.24004276364885097, 0.13445100138737362, 0.08592498210208648, 0.11691752314352533, 0.16144004595255812, 0.102783963621731, 0.3068657416066611, 0.3493002637418274, 0.1692485961168098, 0.1632670688285319, 0.2880157254526639, 0.10687761466720143, 0.31907004092467217, 0.22445777428357463, 0.18942113641179859, 0.19929343537066535, 0.45071432277301615, 0.10845233898929327, 0.3963696474722627, 0.20768410844234844, 0.101208815782359, 0.09565726780044577, 0.37323940585552595, 0.16848252209856676, 0.10698743669161229, 0.15851811182529094, 0.1293411816872645, 0.1692217814624694, 0.19472090759663246, 0.10262156513772296, 0.0963774509640795, 0.1100783767649699, 0.15602024002081327, 0.12593532435680568, 0.1637404231109772, 0.19261576475558606, 0.16000863440220528, 0.41540809124157185, 0.1341754080388932, 0.20022111714436225, 0.17465244253085374, 0.12682938481572828, 0.1698240519355579, 0.2854088800073205, 0.29393789014381805, 0.2280453112410289, 0.16953963911460893, 0.2575350699129925, 0.17078540274201917, 0.2438649125721218, 0.09723282220875246, 0.16354919099969864, 0.11811809366170106, 0.4004509671570935, 0.3038116579383437, 0.0811676159519764, 0.16218299713769613, 0.11209904517010137, 0.12312667757501143, 0.28158913260250107, 0.12950765533172606, 0.15870130900330384, 0.404589873751683, 0.18029762428626753, 0.27865411532618184, 0.1478857585296905, 0.10580094169613792, 0.5189462997226596, 0.11106876841400137, 0.10191966812536746, 0.20013445661299528, 0.25992594780492584, 0.1350146208851554, 0.1001903097269929, 0.2535448258578573, 0.30684057573003587, 0.16478442438860094, 0.11639478223965823, 0.1769169806097241, 0.27024544944961865, 0.20039708510746346, 0.08198169395277345, 0.17579591979833256, 0.5676103904224539, 0.5204764260920854, 0.4879795919033028, 0.2732986755263155, 0.317989174838929, 0.1817719320177802, 0.18008671681515206, 0.16003993711937134, 0.5386394814686629, 0.1882197652420197, 0.49804319310719175, 0.10833312234900155, 0.27796585955164665, 0.15541086489807218, 0.31792156811481437, 0.11107709871423492, 0.17066700089681164, 0.3529665985653962, 0.11607600028382897, 0.342884138532754, 0.18755316536598302, 0.2506711842423598, 0.15974026745039321, 0.2412880781045374, 0.224662914583293, 0.18166891598597135, 0.09046523272324104, 0.21291693149283292, 0.4425022974195137, 0.23252142518848176, 0.11950186180656996, 0.5444209163494056, 0.24145812935587072, 0.291027020875775, 0.23271863358052372, 0.18594999353935834, 0.2218738005928391, 0.35904458446213694, 0.09646824492800803, 0.28651317091633066, 0.10333479370655396, 0.18436198036233822, 0.12751016416231858, 0.30489358144832274, 0.17494368308527236, 0.11244296822209882, 0.16425079000501552, 0.0982394891224725, 0.15809014530232296, 0.3945428541738009, 0.17924440318096466, 0.18284083903966003, 0.11134085258526698, 0.23744121168491986, 0.11899248825436302, 0.21380463130264127, 0.16117912596814096, 0.20583470970846465, 0.1622624847329674, 0.18083051388380278, 0.09230080207895988, 0.12581376748899148, 0.40956206770992376, 0.37056178765824144, 0.17816283075115666, 0.5023456337725495, 0.21864154644805073, 0.11803362042046896, 0.09016061574864384, 0.28802873839029136, 0.19483273719772065, 0.18627873465505332, 0.11313589727912955, 0.10620405789244651, 0.10686527239137285, 0.19015461921368035, 0.18789634675874783, 0.46611505408381887, 0.2187455717773951, 0.10964756411988826, 0.21713255072641788, 0.3230858744217582, 0.12965758192000665, 0.10446539411283977, 0.14318687392159513, 0.23140278297763628, 0.30027996112012917, 0.08506123834025969, 0.13840895726749514, 0.1605427772463358, 0.1358823536792075, 0.2471850646137789, 0.34560183735851774, 0.24649463078945605, 0.39430488546032033, 0.37341267277575474, 0.22126454906681164, 0.19129529609359955, 0.21291693149283292, 0.10453021694374351, 0.09911969742016861, 0.26572836651812093, 0.4927837701046833, 0.35958878306660114, 0.299049576214694, 0.30821023784933604, 0.1311069713797178, 0.17803271429971265, 0.1323289735962528, 0.11578669680179635, 0.10013307848615764, 0.28662633095731965, 0.29353490262997184, 0.4449155616500538, 0.17587799567060913, 0.2081243540417797, 0.24080335888020227, 0.4892774922528369, 0.1583446962194306, 0.3351001971162965, 0.13267604126566393, 0.1426234118934099, 0.10149621928461382, 0.16406961755670255, 0.0792334486080982, 0.11938566655115236, 0.2557167367405714, 0.14602817734014853, 0.08451742650769661, 0.31056648436897955, 0.299049576214694, 0.5023456337725495, 0.19449156624925965, 0.20099062767039996, 0.16221394061639194, 0.1632367385691342, 0.09792444391163284, 0.1645381117633467, 0.3768600074238967, 0.3052145982785364, 0.15042284427496588, 0.12037981471714825, 0.11266533488665245, 0.10469195673516152, 0.2766076850124122, 0.4827242407847912, 0.19261576475558606, 0.10354603739897389, 0.18540169635397286, 0.17732681573033457, 0.3089480668694904, 0.5075040767947708, 0.14587754635364555, 0.10293480446490866, 0.2406118423104766, 0.24145812935587072, 0.19045866146209106, 0.2525962187755733, 0.1538997455840675, 0.21477327355425388, 0.0970482658419703, 0.10438922809241308, 0.17245406489597623, 0.08194010211910656, 0.24348826603137602, 0.2959426145602771, 0.4249165326826548, 0.11621825990050355, 0.08598922162379637, 0.14947481349730832, 0.3337626566314943, 0.3308926730989713, 0.3556272192419958, 0.13890016330357902, 0.45071432277301615, 0.3262727958616278, 0.11682708258622936, 0.09489877161156261, 0.1721714414248477, 0.2839108692679109, 0.2847400888866708, 0.11665606470859494, 0.10797059451683076, 0.37380915824603106, 0.2824611923802084, 0.5278551456050324, 0.26048413316679697, 0.2638082701421961, 0.42072429415148416, 0.0917311169415917, 0.4289166217731148, 0.11776320016627329, 0.07551105919737836, 0.08259718765977073, 0.1257979412504297, 0.11732941813900842, 0.11163044101691132, 0.11409288573919384, 0.3481218414011921, 0.08706447552140086, 0.11971381864156581, 0.10006798069333045, 0.13958601419545774, 0.21827660505247723, 0.08303419887027647, 0.413006713200097, 0.10482512436873243, 0.2001211730524984, 0.112652239423083, 0.09755276006205572, 0.13646485496676874, 0.17668300053042346, 0.3214742587614987, 0.09974238727625606, 0.1538997455840675, 0.2746769183014854, 0.17892280287267948, 0.22155129275557447, 0.15349040108783935, 0.16896084564892405, 0.5496342499375625, 0.5075040767947708, 0.22528658777192528, 0.1448370807345, 0.1054454070283681, 0.4333811307478777, 0.20138796408388782, 0.25038896836735947, 0.11655033785002744, 0.09339462560618357, 0.23430271203716238, 0.10112854024400511, 0.2900249248553572, 0.10179561412373897, 0.16256946318349946, 0.1311069713797178, 0.16981869195693483, 0.36280483860180307, 0.19238093427879255, 0.29327080780891457, 0.22667436910775643, 0.11947608840172487, 0.11325697387399414, 0.20057727423994326, 0.34361296273026276, 0.21162767342084973, 0.13507259371307814, 0.14078821950390025, 0.1306315114988074, 0.09676304643647711, 0.3652284045679604, 0.3303597588352889, 0.23216875050924654, 0.19869760794693955, 0.12407790976385433, 0.2647128041795909, 0.18267421598388003, 0.18576445639634162, 0.08312859195351505, 0.1537332358068098, 0.19509372272597233, 0.10459923871345296, 0.18400466236099342, 0.2839592821881482, 0.21533134783505348, 0.17562408066057664, 0.2225529656823845, 0.2655400552680342, 0.26502858350589703, 0.4100160493191524, 0.33344405825633644, 0.10188687125918659, 0.0890327113746771, 0.16425079000501552, 0.12961232408533813, 0.11595234774628393, 0.08451742650769661, 0.20811692486793595, 0.23111697711582302, 0.144751492345552, 0.09281594464026313, 0.3744980545396318, 0.4078902803863565, 0.12965758192000665, 0.17583959502905486, 0.10149483671769068, 0.13876285564107355, 0.12926712052588718, 0.23024715197525716, 0.15592525299131696, 0.22521278718526383, 0.31278014697340745, 0.13341406119123547, 0.3645409457200287, 0.10992717640565214, 0.4410030339830241, 0.24649612246413646, 0.07780516750743667, 0.1795022449694776, 0.20654517641593403, 0.13895676050786887, 0.19570744416388308, 0.24649463078945605, 0.30703524402206217, 0.2562139567129883, 0.13876285564107355, 0.12913026949322065, 0.27337987762287586, 0.1924224729858069, 0.12587669022904083, 0.09568642728993794, 0.10076214730673831, 0.15241730304548454, 0.336062538828434, 0.32397032886571575, 0.16758168431910173, 0.17907008464537455, 0.2264559399010862, 0.22892320606708486, 0.33266447267179805, 0.39916569530252877, 0.09646648559332772, 0.36558902055632464, 0.1593057403474868, 0.17203116780946245, 0.11682734569788987, 0.11845032980046925, 0.15142540170898244, 0.12584434150728532, 0.19756153719847439, 0.15674628369662474, 0.21574218970337822, 0.49804319310719175, 0.11455711942955067, 0.15809014530232296, 0.16671557239345874, 0.1302963338312477, 0.27933838455399274, 0.18921651142821555, 0.23744121168491986, 0.13058864622399824, 0.15224337732037882, 0.2863615791350808, 0.4419714371206637, 0.1643688438601965, 0.35235730098613816, 0.3556623954891565, 0.3007835816983411, 0.2301140639509742, 0.10066831425687435, 0.08864190263664928, 0.16963958359389344, 0.10333479370655396, 0.13060968842005652, 0.15053274954541668, 0.14344169178784863, 0.2634602837324139, 0.2907635840633276, 0.14897794109291868, 0.30227646222549415, 0.5911986789310528, 0.3418471056140834, 0.09717402226475669, 0.22068332137211744, 0.10081829253227642, 0.16764248636466694, 0.45966351222595603, 0.13085089885926676, 0.11703577648820913, 0.1999807702727489, 0.08340987712256485, 0.21463219254220678, 0.12170559543547141, 0.1296404093222757, 0.1554282914121531, 0.16831491431235282, 0.11850806156670061, 0.3213070022305914, 0.10601661798023927, 0.2733282674611304, 0.25274342180353765, 0.09984489776532847, 0.45127829607471903, 0.11845755678101069, 0.46882779188079277, 0.14748614982856764, 0.3390495289664521, 0.14986559045404552, 0.16767866414261953, 0.15268525193637086, 0.38284206465850645, 0.33899866302725273, 0.09762451263699008, 0.1733975758724807, 0.2806990629939265, 0.12351447948234899, 0.27136846336233145, 0.4767993833161306, 0.18226818876751089, 0.1604870830611875, 0.16607142393471236, 0.10698743669161229, 0.2529508226253969, 0.1582451894853659, 0.14206388558709152, 0.19908525337850705, 0.14351675205301742, 0.142571494090831, 0.20038018567045623, 0.24966977858829217, 0.19387508521562494, 0.13868207212092945, 0.12787331890997986, 0.12536770753930712, 0.37615021157431894, 0.24901236487265957, 0.2174866887530322, 0.22285131211469547, 0.15056903009997682, 0.42349926069713334, 0.22021645474698354, 0.3072009664112458, 0.13260756115685515, 0.11894241150853536, 0.15957539006893665, 0.26174033631602506, 0.4020154258608125, 0.4215266825013674, 0.15864544412643616, 0.18212497758889346, 0.14153166309025775, 0.3284670648115655, 0.2077996446689502, 0.170453250922486, 0.09283569773770635, 0.24819516857751078, 0.09005909828529803, 0.22720103315552856, 0.14146376667829305, 0.09124305997531014, 0.29804962551771613, 0.24982419913544718, 0.20670281452161435, 0.11298336474073832, 0.22936437367274387, 0.3282559954133182, 0.3302652889564966, 0.21094497061151074, 0.25419623785214296, 0.2687237581194079, 0.24593799671371103, 0.1528055077513681, 0.10500947148433991, 0.1299162994505014, 0.10757325429559769, 0.146259489503132, 0.13202636678752483, 0.2052306909884481, 0.14716954351511985, 0.2647128041795909, 0.1062626835322055, 0.08294216664556375, 0.17102678040901134, 0.402972522787509, 0.2510245967383938, 0.49809769133596216, 0.14860840255506372, 0.32924471570486374, 0.13222680983394078, 0.17614204418050428, 0.17049347542383306, 0.14660659625902045, 0.3307510694635067, 0.0763020657908858, 0.2948771996635331, 0.19490989454420413, 0.10840515883965933, 0.15883528862330967, 0.21431954027247824, 0.09752656400970515, 0.19630296449568774, 0.4879795919033028, 0.14751015267740805, 0.09721464821849908, 0.43404199953769934, 0.1158292875664418, 0.09147139984091565, 0.15946944502320617, 0.08998365640321317, 0.07687795995086626, 0.26298413074049315, 0.3302652889564966, 0.26572836651812093, 0.24548238713072806, 0.16037814292561092, 0.1277667215506989, 0.30440571584664466, 0.4726550495681338, 0.4308603303625888, 0.17918589508379465, 0.23574559724396632, 0.1142351613497443, 0.2744358263111243, 0.22430721394097572, 0.12458105356867417, 0.15121580663974296, 0.5992042630512019, 0.10556443716895801, 0.3744980545396318, 0.12964265193631588, 0.12891463059928027, 0.4755037655346167, 0.43963308356128256, 0.25875476423529026, 0.09926336914176216, 0.19839652658068818, 0.2104532603011265, 0.4078902803863565, 0.19468051243670323, 0.14908274171681524, 0.2341106247050245, 0.16888392812242045, 0.17664690580906442, 0.35668572895852946, 0.15000585657232327, 0.19431854792046757, 0.1936938068837512, 0.4951519286692458, 0.08469394152825838, 0.14723708957337686, 0.1518741039854467, 0.23608344902822445, 0.08916562210065516, 0.2505716384445119, 0.11760344011025098, 0.22720103315552856, 0.16580714504063246, 0.30810809575249, 0.08694027450760242, 0.20537167578379187, 0.26609172220009303, 0.25619113541343025, 0.28222953822996455, 0.1705184782669015, 0.141867991297807, 0.07219095094029455, 0.14375447726825177, 0.13274936598138515, 0.12803883265643418, 0.20831778693118264, 0.3589879305755459, 0.1371250447293831, 0.13447076665265986, 0.5062057488495489, 0.09002452668652586, 0.11606152266615148, 0.2904765643398297, 0.1460908067635261, 0.49804319310719175, 0.15847605865584236, 0.12351447948234899, 0.24805638761956067, 0.1637404231109772, 0.1257802290629722, 0.10901820756073136, 0.144719214375879, 0.19344762964495585, 0.4978991377038254, 0.1856482929028116, 0.17388422412123594, 0.581573341970609, 0.26594397949078674, 0.09042422928828275, 0.1714802392976752, 0.4746162024194521, 0.21202018317350005, 0.16976719087008388, 0.1706675306505114, 0.22659289686724982, 0.1747845604148639, 0.08193882931815956, 0.2465705709917966, 0.1564368817464919, 0.22351271317506563, 0.45997635375897117, 0.1643688438601965, 0.30351257847203456, 0.16363479499594885, 0.1382068501274288, 0.26480368191418985, 0.2342148110540248, 0.37627766484956343, 0.329179383561337, 0.14881305732594466, 0.23956165873383417, 0.2055280977277746, 0.37935986064632815, 0.15266254483933597, 0.12816222413067327, 0.21571388370897843, 0.15262860921026214, 0.10257837616516133, 0.26150635373952663, 0.08323969557838516, 0.16828661775369252, 0.13955737590188835, 0.24417202193385779, 0.12507278575776237, 0.14357748286723437, 0.14891378948716216, 0.14542934541883057, 0.4342982777859838, 0.136419951961322, 0.17024064598413705, 0.18267484976318857, 0.13421649948173123, 0.1362686204026964, 0.14970721909227278, 0.23091728651784774, 0.10201662808466902, 0.16704827662529384, 0.211122291991845, 0.09536784671659154, 0.43675341370576265, 0.4064981587916048, 0.26352748818121935, 0.09408193234390179, 0.12345653620608511, 0.3264152199973173, 0.13123774626507523, 0.22210614871054474, 0.245911046935289, 0.1341663063798063, 0.2038237807338604, 0.20699277379809147, 0.14854545745050957, 0.10745721001611427, 0.404334065080115, 0.1339707248386085, 0.12898112791749486, 0.13874658795230327, 0.14645433190384471, 0.16227215706698667, 0.17359591561519647, 0.2614476366037361, 0.22068332137211744, 0.09685964541755591, 0.21217711827255423, 0.18343233424620156, 0.084650727982307, 0.1333036889875702, 0.1939635713361775, 0.14973925005082991, 0.1151122763149764, 0.2263449650235256, 0.1357926551496397, 0.5496342499375625, 0.21639007026478937, 0.11884678444987824, 0.21615665543229537, 0.18801691599380804, 0.192645521201237, 0.11252112848287613, 0.07219095094029455, 0.16845779050223314, 0.0869770416608111, 0.1703479918979787, 0.2470172389884725, 0.14746073407677296, 0.23142809693625643, 0.164016114755294, 0.10683003369698553, 0.2743529877708538, 0.1506258359459026, 0.09980981584261177, 0.25527780647058634, 0.18828963219715175, 0.09721464821849908, 0.10668952249731105, 0.18855313678484578, 0.36297294871907926, 0.12024260385866097, 0.17462752628761913, 0.17754415392311076, 0.11516178111074504, 0.40615949817977903, 0.3337626566314943, 0.09829602174009583, 0.25830963265294066, 0.10820262671573208, 0.08655960141417127, 0.2276362938685233, 0.15307741704582173, 0.23207304852781788, 0.10016168401467808, 0.2105410844465145, 0.23802327290859687, 0.19687821735892044, 0.16175644971411637, 0.23375030344542466, 0.24566995470476227, 0.09623075718692277, 0.3316510055813295, 0.15300847004317553, 0.09357193944022624, 0.2156786849361259, 0.322617097468352, 0.2940786738164651, 0.1257628297350049, 0.13934691735727298, 0.30121374265278517, 0.09676304643647711, 0.21695196929735805, 0.26692517092439505, 0.16360965249900403, 0.30244768146975315, 0.18028165986890618, 0.11645610024404518, 0.5538905794661377, 0.22461100617922217, 0.37743066461775054, 0.22530689585695196, 0.1604333523582686, 0.33899866302725273, 0.2191259401499518, 0.4291599852995417, 0.22151975344282013, 0.2925786193144232, 0.1880379877286971, 0.11131561003151172, 0.2346107138530053, 0.1661755174870178, 0.1333319918291936, 0.1333036889875702, 0.5538905794661377, 0.08319823293047475, 0.08891344740895088, 0.09972077832861453, 0.08962237146829291, 0.12780774296986408, 0.4275779929438576, 0.3212758875579785, 0.30884788654929457, 0.2552098759566686, 0.41364762167394253, 0.1371250447293831, 0.28812030470477995, 0.18149137994720202, 0.22449949348846604, 0.09301765959934669, 0.15248578201335442, 0.15756657049330214, 0.21231390677298675, 0.2162145903815488, 0.3421864051905337, 0.15429198459465857, 0.3749740837682289, 0.12845114167738247, 0.11436786211279787, 0.09373814438482016, 0.30722596476679026, 0.3054135426388047, 0.20243364677389852, 0.1758842222432827, 0.516266233161901, 0.17292664650375875, 0.21850778294874942, 0.258561899337689, 0.10383439462468422, 0.49809769133596216, 0.18213445260167316, 0.20017867996820363, 0.2207026669434865, 0.15168208032367195, 0.22429273900027333, 0.14465243692039445, 0.0913904366630979, 0.3652284045679604, 0.28602995064895204, 0.09393521906411274, 0.21300846112238755, 0.48307084379793763, 0.24768597762441727, 0.36066457164809496, 0.36066457164809496, 0.21557254360118197, 0.20705672893022603, 0.20277177457513085, 0.17666048958820343, 0.38062807690327277, 0.2287962070474898, 0.19036764642673773, 0.1778831279752028, 0.3556623954891565, 0.09300409269391559, 0.18455458664005503, 0.2033889185902952, 0.23890429647076766, 0.131018142410963, 0.23967317695843884, 0.08145180692455684, 0.22781285993597056, 0.19824449354773313, 0.21162767342084973, 0.28403232757028996, 0.07722983359846543, 0.30457378761620235, 0.07664764618848162, 0.1631168131038313, 0.12419284449423136, 0.1112667810512355, 0.5496342499375625, 0.3325674117664461, 0.10398558069748855, 0.15674628369662474, 0.15916656818676447, 0.10702578573752214, 0.14154831352869934, 0.1637404231109772, 0.0792292407185636, 0.11599892722202147, 0.09558201696852361, 0.2052328617932476, 0.2961678150596346, 0.2888360132871205, 0.17897648237209746, 0.1563076284573003, 0.1582603861730573, 0.19564619493829924, 0.43273522317485413, 0.18259377290184628, 0.1663672221854692, 0.21531906695453062, 0.08353876938736614, 0.1205846988408812, 0.19103233461970665, 0.30405192640389206, 0.5305701143823528, 0.2969814488427479, 0.1505640824773646, 0.29804962551771613, 0.49223613258670923, 0.45071432277301615, 0.3464404994014297, 0.2948771996635331, 0.07548430490928862, 0.19593941491285602, 0.29483187491767754, 0.11516178111074504, 0.21775254786300804, 0.5911986789310528, 0.10593219767091977, 0.4275779929438576, 0.18077638749355895, 0.3561541919023432, 0.10789714006031573, 0.2984559694888138, 0.12588194651725804, 0.27680146099154945, 0.5278551456050324, 0.39572479997877474, 0.13267604126566393, 0.09887314324827419, 0.20413170782014692, 0.12980236043416768, 0.10348730424398427, 0.2342057400501906, 0.14095187854567115, 0.31028572651141567, 0.18397682103799912, 0.31814620197595705, 0.21707159485817137, 0.26532880430717787, 0.35813059154120197, 0.09972077832861453, 0.15003831217403713, 0.11466922712086833, 0.175190689140677, 0.26920706790135923, 0.21073033260298282, 0.13964717662615625, 0.18984462864343124, 0.09268399410518761, 0.13271540236049278, 0.15811227304003334, 0.21240476021229393, 0.1531883295546623, 0.36078581911501506, 0.11424682199143853, 0.09683396255769174, 0.23129411689181148, 0.14295251175317658, 0.5594377295378345, 0.1856482929028116, 0.10004442592621253, 0.08775950978847695, 0.12995083336330598, 0.11314903156287857, 0.2104532603011265, 0.10395592296328626, 0.17200758986593417, 0.15851719046581245, 0.404334065080115, 0.1798404669937289, 0.2725071061071586, 0.20844412772609064, 0.3319231724811951, 0.24095412536924526, 0.21388594713704728, 0.147863930255063, 0.08512701218811032, 0.39078649025570533, 0.4879795919033028, 0.24732127980023208, 0.5189462997226596, 0.11453209192827526, 0.21220800845145843, 0.10398592979702657, 0.24446052765217247, 0.1195391488703702, 0.3456819191853205, 0.10400512756807674, 0.32850876549315006, 0.3237406853633931, 0.17006245049326169, 0.16680091758050994, 0.15297672003563384, 0.16934883953353694, 0.10007911380630746, 0.17650920588462257, 0.10850123334191522, 0.09138422837563023, 0.10081829253227642, 0.11418848090945335, 0.09823870659048338, 0.09668990037054624, 0.1273625747325793, 0.26352748818121935, 0.09598571651684643, 0.22640404774964945, 0.10514558664461499, 0.11763745029874044, 0.09339462560618357, 0.38711958740620017, 0.1604814376205376, 0.15454770510586577, 0.0923844737461427, 0.226361680303301, 0.16871547607875412, 0.4333406399781108, 0.36312938298641245, 0.27283804261188127, 0.09312719673482589, 0.07983045591267703, 0.19521061930763922, 0.3954102997575931, 0.11148485133248243, 0.12951993032651798, 0.2435067145170179, 0.08956069222565703, 0.10825227833976693, 0.144751492345552, 0.12446945499178087, 0.28914779878388996, 0.3563412955320864, 0.27187639106686884, 0.31217681993672086, 0.4285724760563478, 0.3864932201397586, 0.18113547105355657, 0.08137783550603292, 0.3096396654741684, 0.14361141791922719, 0.3684916359056116, 0.34104385149334004, 0.0792408537864871, 0.09517526612330003, 0.23322330844554828, 0.18058700531705296, 0.09582289617675371, 0.1135701389643443, 0.07923047481492222, 0.09864958531605758, 0.19399008400011208, 0.14746073407677296, 0.21315157234104506, 0.16209832430878177, 0.2201247745587808, 0.2347851115012072, 0.14785729693379354, 0.13505539905280384, 0.30156179614210676, 0.24901236487265957, 0.22425575966357905, 0.1733495092320929, 0.5676103904224539, 0.1116961056932253, 0.3555951207491793, 0.16345268672792054, 0.24949207416032856, 0.17942546077786747, 0.1640171181452575, 0.18288894519476454, 0.14265358700886263, 0.15719393945176757, 0.0694722771154489, 0.18786359066514444, 0.16215135617154283, 0.1278425501903753, 0.10000529860229558, 0.2283941929444279, 0.10079207701712152, 0.1679982243266812, 0.23327682009322326, 0.161906301507911, 0.07725254127547554, 0.09942468923441589, 0.11682734569788987, 0.2189540700436359, 0.5992042630512019, 0.2305438566623278, 0.44416796058040303, 0.4072036220444063, 0.10415982319944453, 0.09228630800550174, 0.16130306161735897, 0.14559601133975397, 0.12939152005380558, 0.10588831518876184, 0.15080492486275937, 0.44715997692283826, 0.0883765058432294, 0.1054454070283681, 0.19240827201993912, 0.24844234353533243, 0.2071338879800809, 0.1828730339767451, 0.2668654610114585, 0.18397654656933093, 0.15044246961219232, 0.22706263303922344, 0.12385905665382399, 0.09721464821849908, 0.09665898906617192, 0.10855705380095192, 0.3105777441044052, 0.1402861417894645, 0.1605427772463358, 0.19010429311849925, 0.1838801518382188, 0.1898285874063158, 0.23882774911229296, 0.13782742321658817, 0.11740862772109137, 0.10385402556777004, 0.4275779929438576, 0.2863615791350808, 0.09010360813177984, 0.305207975358882, 0.22504276887430513, 0.09721464821849908, 0.1999807702727489, 0.2565369400839187, 0.08789513716986623, 0.2206080049033294, 0.1749083213567277, 0.10999862610959486, 0.17435640303110386, 0.11772428593548484, 0.13874658795230327, 0.07694937747463038, 0.1371204501853264, 0.23094693861421828, 0.1375369974871021, 0.3396149322135154, 0.10849720948195657, 0.18815155162744993, 0.17970091172832156, 0.2794662546901962, 0.11127723802043774, 0.15366083100486058, 0.1054454070283681, 0.3060659372199056, 0.15788096739072666, 0.19724334084596845, 0.15495242335085804, 0.24242144939552907, 0.18031588435432197, 0.1972492154382991, 0.10596218965301508, 0.13884327852030579, 0.12191027136220771, 0.5062057488495489, 0.09721464821849908, 0.19159291887302776, 0.10849720948195657, 0.15538552257536697, 0.15713870600731683, 0.30486939683792086, 0.07817944001586198, 0.1840459990957578, 0.11603303870989533, 0.1653375673201317, 0.2900489322966894, 0.115541598888476, 0.47826652487746785, 0.13791407629022434, 0.3529665985653962, 0.14937837516174476, 0.44127539637386703, 0.25980383790480355, 0.12801098254770146, 0.1638022100917436, 0.09629030846595182, 0.39257818089963675, 0.30121374265278517, 0.09251964792459191, 0.08995926762983471, 0.1607186018008023, 0.1958484763455522, 0.20970838977871523, 0.3153531061614419, 0.1466929470181797, 0.18671917712933045, 0.11776320016627329, 0.08812409833985295, 0.3379513769200171, 0.23399189452995162, 0.14804473794734693, 0.11750953883673948, 0.22678656289674248, 0.2140634626585486, 0.20382474395467148, 0.2594956673125582, 0.1596758030590062, 0.2826714168210919, 0.10017617970858118, 0.31080307943228325, 0.285922673250451, 0.08476079267403287, 0.5676103904224539, 0.4019966962988656, 0.34992751898467456, 0.18028165986890618, 0.14474680086288647, 0.15780571051011874, 0.12147648470974065, 0.22669256506700228, 0.24204556972420405, 0.2490956443066799, 0.14932646467924054, 0.19615750967122736, 0.11163044101691132, 0.3089480668694904, 0.2248668100233856, 0.13652322405295458, 0.3184401163992525, 0.08242869268669717, 0.18335565597480746, 0.16706487047346827, 0.1322684055189003, 0.4390264432055758, 0.10218658839352153, 0.23076698451675284, 0.10563029940562024, 0.17013074776457732, 0.2320664779263138, 0.1120523685810114, 0.5911986789310528, 0.21697857400746726, 0.33312404637789594, 0.169349997907248, 0.22504276887430513, 0.11639478223965823, 0.1144600043797284, 0.2717824017482678, 0.2528914071520095, 0.3464404994014297, 0.43273522317485413, 0.13690577696980263, 0.13799897310804496, 0.08167897021003309, 0.12003171616187808, 0.17903615545673973, 0.11025123841908964, 0.3481218414011921, 0.46985711797160595, 0.1206040494136112, 0.12970645330430983, 0.166628197949665, 0.3196132487092144, 0.18222024303650772, 0.13136149607453476, 0.16845779050223314, 0.12457216472097032, 0.18330431741370745, 0.08737076427199131, 0.2097103697778887, 0.21844193404157847, 0.1655977697722604, 0.21340252299073095, 0.20243364677389852, 0.11725066459492822, 0.15889213921812476, 0.12955888211626668, 0.08655960141417127, 0.09972077832861453, 0.1410321005342784, 0.3097236512461196, 0.2008406773111972, 0.2524434967915985, 0.29490205418963783, 0.3072540443061422, 0.1270283620018425, 0.10808925419323254, 0.2000096249506376, 0.0939725497872042, 0.12478424517099454, 0.09576799338800036, 0.10838826730904585, 0.4892774922528369, 0.08476079267403287, 0.18984160231224473, 0.5007265828309193, 0.4098850350158341, 0.262746871516112, 0.3303597588352889, 0.21742333347441709, 0.20999243321805208, 0.13976735282011987, 0.16589379011525046, 0.21220627529118716, 0.13521440711296545, 0.1521378183984535, 0.17801591304815836, 0.3153531061614419, 0.12452342074509112, 0.29718547104105564, 0.28097092189605305, 0.10065440306314531, 0.25998091170000226, 0.3322490204588803, 0.30919527870429014, 0.0829178800342472, 0.20605277339867342, 0.24848217603526632, 0.44999238187508817, 0.20457060678227215, 0.19954484586903257, 0.2206229678073629, 0.08869727197956209, 0.19573982402920423, 0.22910849802512437, 0.1808226055026336, 0.148355414106622, 0.11470982559026482, 0.07183212440116483, 0.14409674719370982, 0.1189430335266848, 0.12292500481593034, 0.1508020160823245, 0.23432349525448426, 0.16440249936067305, 0.29659200931497276, 0.355893061209745, 0.13598248311604808, 0.26675548508437763, 0.15399700868409288, 0.24351800704468557, 0.14288276882078008, 0.13643708084650608, 0.16557266637254175, 0.19201033699202355, 0.09564964959042344, 0.22037883531357402, 0.23967317695843884, 0.13312971285960903, 0.11396306075710662, 0.1080729495230017, 0.1644243607070993, 0.2588321805927142, 0.08418607993623836, 0.1955786724808231, 0.0835528210745957, 0.14964796398714927, 0.2723838415161273, 0.2984559694888138, 0.10698743669161229, 0.11724287487195098, 0.08892796499872734, 0.1451006116170418, 0.09274194636695501, 0.19253728047931346, 0.16691694985261124, 0.22519985535890522, 0.17998862938295299, 0.13284528967012302, 0.10616523937356886, 0.10849720948195657, 0.23851031984678756, 0.20163106347931856, 0.3529665985653962, 0.3076364250448088, 0.19869775854946675, 0.0870516935677695, 0.13652322405295458, 0.1542600853416243, 0.10096337789560307, 0.18265952173174133, 0.16028497555285579, 0.4350586109168038, 0.36312938298641245, 0.13416297040089298, 0.09274194636695501, 0.26730277785316936, 0.21448510698160275, 0.17551666722599377, 0.13276162081251583, 0.14433329137430023, 0.24342689779557816, 0.11244143985674866, 0.07725254127547554, 0.33535794820086634, 0.23622389603679275, 0.12143114035918465, 0.15628086523274548, 0.3054135426388047, 0.1051347279842948, 0.08700706224922303, 0.26805344653305735, 0.16232431861741553, 0.1299504809557707, 0.14245912117495046, 0.13910032785920196, 0.12385905665382399, 0.29209661713981794, 0.3581941310359627, 0.3127006184675347, 0.09469272886637715, 0.12774697695777215, 0.08828123664565694, 0.26994464751545494, 0.07216841780016076, 0.1209776958694921, 0.12631409935836238, 0.14323664142684883, 0.15490443802477583, 0.17099589655624226, 0.28925673830957055, 0.16601314822579236, 0.25756398527429747, 0.13315377287303645, 0.22742518901339276, 0.08734928416600729, 0.17070098235142514, 0.12390142812331598, 0.1892292067003814, 0.09453898475970059, 0.14642075037971486, 0.20060509002192112, 0.26985060053023857, 0.18203396078606068, 0.36499962655658225, 0.0860478676972594, 0.10617172522609522, 0.4078902803863565, 0.20131546657807653, 0.1890554136539731, 0.17956696674124029, 0.11874871584269013, 0.09086525669988808, 0.2716644406919173, 0.2650409037977105, 0.5372360511999499, 0.16782476052861414, 0.12198248991911313, 0.188060530733776, 0.16924762987463696, 0.21822833349365642, 0.2969145806833568, 0.16828661775369252, 0.18018221659055922, 0.2444502303388614, 0.11979686118522458, 0.15281859370973924, 0.17376086387823297, 0.22699723908148664, 0.43143683202929356, 0.16538614985294808, 0.3586421013770097, 0.08857314730406107, 0.2216039256060509, 0.10087029258927442, 0.2921400327211872, 0.11681673599109567, 0.115541598888476, 0.10973139417373587, 0.1284873549057459, 0.38243426914594114, 0.15173185641429612, 0.24150127761279802, 0.12249685146067313, 0.36183417030499276, 0.15844396051018544, 0.15845608833083638, 0.49112973075634503, 0.20603337872141264, 0.19210472493058947, 0.21306377177263794, 0.19347254102365832, 0.09182931438141688, 0.08416232805944036, 0.11594365650881355, 0.13284528967012302, 0.15565446793207333, 0.14624478637465949, 0.19818219356418157, 0.297086810206946, 0.14648335992459216, 0.1808452345460532, 0.12565880037631136, 0.4291599852995417, 0.49112973075634503, 0.0925437465035653, 0.3274969287424971, 0.5676103904224539, 0.11276362042498092, 0.19879462505778137, 0.40235292248928334, 0.17438532787188293, 0.3054135426388047, 0.11158653834886832, 0.23431877205023544, 0.15480731215513452, 0.28741355545173297, 0.1598886077137299, 0.1777745058130528, 0.2622941585904637, 0.10849720948195657, 0.45001036328293187, 0.20144979973197655, 0.11650003169759168, 0.09630317167583742, 0.2202643804802802, 0.0890534709590729, 0.4855540674714484, 0.23500996883670805, 0.0924219661174671, 0.3507285074451686, 0.10686488522898972, 0.1746062576216124, 0.0792408537864871, 0.13808056224838008, 0.20811692486793595, 0.19885135089971478, 0.12814991343803292, 0.29690848550919857, 0.0792408537864871, 0.5303722950037895, 0.3571371188848233, 0.27079310876672685, 0.10186844427306516, 0.10201076398865425, 0.12334054284204644, 0.12615710961843343, 0.19862759731988266, 0.1759096302645158, 0.3626856851858803, 0.3003914957270279, 0.2464448215780562, 0.0763917442289248, 0.41442020201971624, 0.35444618226764346, 0.14441418924527016, 0.17097909668559746, 0.11832221347350931, 0.1975349548577866, 0.1692217814624694, 0.1394794632789857, 0.4648934396739465, 0.2115053724012099, 0.26994464751545494, 0.15810605610909467, 0.20084628282917566, 0.13270817712611976, 0.17792028308349533, 0.17320315959777757, 0.09138422837563023, 0.2086354727445693, 0.188762677557766, 0.24988423127992895, 0.0829178800342472, 0.23669909558850308, 0.37009009909606516, 0.09870716087716268, 0.10500388246436494, 0.2703045430718607, 0.19417049687765572, 0.11738780501566466, 0.13776219278375404, 0.1655977697722604, 0.2494628759024888, 0.2372214960139332, 0.31840967286221444, 0.163686973074266, 0.3586421013770097, 0.09395257984854814, 0.20605277339867342, 0.10486254947536265, 0.21666234381705837, 0.2441036686534704, 0.3259832796248456, 0.25014998320460763, 0.1570065323633726, 0.5372360511999499, 0.15780954584398452, 0.12934954986447075, 0.10893136834306807, 0.2805237028654107, 0.15608861781542882, 0.12662502338872736, 0.20042579116362355, 0.09281594464026313, 0.1606331582783955, 0.12673551765597757, 0.21726641457320392, 0.1713132299411805, 0.259254165318737, 0.12530198458804856, 0.15974026745039321, 0.09172116692947967, 0.22855151924509856, 0.21918371669369885, 0.09426325970808629, 0.12751016416231858, 0.3619292772448288, 0.3064864186731076, 0.45766755307061197, 0.10932850913415366, 0.09249101570577997, 0.12472487488286739, 0.1570065323633726, 0.24898750953896262, 0.14265358700886263, 0.45071432277301615, 0.17934843887491764, 0.3749318862958041, 0.12186219698030791, 0.10593686050175938, 0.27511447878590667, 0.09979674213038434, 0.20829509696787185, 0.16993199520800353, 0.2563166048477054, 0.25998091170000226, 0.32313093334861337, 0.15434502836875882, 0.3556623954891565, 0.10452146639993247, 0.21705850936439192, 0.16816481544915915, 0.15590838700079004, 0.23362894641220683, 0.16723125313274848, 0.11752718314440476, 0.15709192085616724, 0.17903615545673973, 0.2384388776625355, 0.10330831132644942, 0.18023416605070702, 0.28917923320400973, 0.17339851402548456, 0.2227971643364486, 0.17650920588462257, 0.13280322100346428, 0.1793225926642975, 0.1725798624107977, 0.23843188549504565, 0.15786182995668424, 0.14193137216527682, 0.18938987738731394, 0.1831717924292629, 0.08897490097025261, 0.12676008325382068, 0.46717105903924094, 0.08951679902333384, 0.47477885186369395, 0.49112973075634503, 0.21926289827441833, 0.14885245095288163, 0.2944308846103895, 0.38217035716443476, 0.1593092290641674, 0.1768303154365338, 0.17745082582047636, 0.11556696343646855, 0.15248233219470575, 0.12961232408533813, 0.12204986324339932, 0.2197551610402951, 0.25829610993447466, 0.21895936342424638, 0.2839592821881482, 0.10741197098828335, 0.12016431434193231, 0.31715752092588584, 0.2119551977241507, 0.23493107706036523, 0.17822142808285216, 0.5062057488495489, 0.17050262981661443, 0.12429593329986581, 0.5496342499375625, 0.38243426914594114, 0.24980778818890845, 0.305790817811014, 0.3613620811593052, 0.19638408103083868, 0.2696368354719022, 0.260920851898254, 0.08706481292279733, 0.2565351431720534, 0.23586453069594668, 0.206773732337035, 0.12099364863263845, 0.39076146022178454, 0.14492481852932593, 0.1903332342343614, 0.13390694179524879, 0.10146298966424964, 0.14547580770490784, 0.13868207212092945, 0.09956254051517331, 0.10208502242416474, 0.2098131872963416, 0.2280866081763736, 0.10912546109170812, 0.08829061119801344, 0.34668491129124235, 0.2831957526585417, 0.19650232732236925, 0.2123270869212077, 0.3290165037058286, 0.17413758888524647, 0.1507743768909221, 0.14215995901520714, 0.1527116881934841, 0.13401082150981583, 0.19613552676783982, 0.19179985653973697, 0.10020316641537662, 0.18701877926169022, 0.22504276887430513, 0.20138796408388782, 0.4091679481437744, 0.09224700472221704, 0.17198350897275166, 0.18706837324895662, 0.09452103790702011, 0.1497848460143534, 0.18371356046301957, 0.37341267277575474, 0.1021264634885355, 0.2799657717741513, 0.2990516006292591, 0.15974026745039321, 0.1562250344137578, 0.3125962157758979, 0.18265952173174133, 0.226361680303301, 0.12606750071522246, 0.17100169819591973, 0.11314903156287857, 0.09831310032630114, 0.1970941715435769, 0.10289050258931809, 0.09784448393053372, 0.28222953822996455, 0.37216844193268117, 0.18437710138264182, 0.16926033875506194, 0.14435088583300099, 0.5189462997226596, 0.2805237028654107, 0.10779552957318742, 0.07466016059359659, 0.20235804808336993, 0.17851162728576886, 0.2097103697778887, 0.1440620039520821, 0.155301025558858, 0.4275779929438576, 0.12165854412399515, 0.18383884396028363, 0.2020211911031126, 0.15997763436740722, 0.21432674916287509, 0.2711261575520333, 0.15224337732037882, 0.11494996094757742, 0.2571294785750161, 0.18395235217147737, 0.08710646270436607, 0.27893486230434655, 0.15450156766686565, 0.09676304643647711, 0.3652284045679604, 0.2798925319238355, 0.2404100409048167, 0.11009376087770772, 0.2948771996635331, 0.13876285564107355, 0.1623243741279086, 0.24637433970307032, 0.37323940585552595, 0.19010429311849925, 0.3185916095209961, 0.11564791641848282, 0.15173185641429612, 0.1938133457956634, 0.1405309529280773, 0.12495194242298369, 0.13557703287109235, 0.0800724254065348, 0.21367385782799345, 0.16382780513534503, 0.3556272192419958, 0.18578137542697093, 0.14372898557811817, 0.24278924818320463, 0.15891627711354842, 0.39635864550359473, 0.10292710333075578, 0.2305438566623278, 0.12960538259662646, 0.10695299084742178, 0.26964164796081375, 0.08576940410974533, 0.12701454176362306, 0.1892292067003814, 0.4215266825013674, 0.13464286831476435, 0.08778613777765076, 0.16780067988984568, 0.23291503503199998, 0.35492220723497975, 0.11787802769102913, 0.11806371261950399, 0.1509024913047384, 0.07842074052508247, 0.3079233821917625, 0.2948771996635331, 0.3561541919023432, 0.3406738197569653, 0.36474059138119713, 0.19748168064855426, 0.11073774438430041, 0.37323940585552595, 0.3561541919023432, 0.15632182119383817, 0.1537332358068098, 0.09463656533680058, 0.17816283075115666, 0.09015063415377855, 0.17225227890819697, 0.2616735349745243, 0.13740600272087294, 0.17958900216498835, 0.10932850913415366, 0.32256574536647775, 0.0940229415392273, 0.2502502323463465, 0.1054454070283681, 0.1660920736595111, 0.1193170066424536, 0.1174869970549314, 0.24883102241603483, 0.11755643350338348, 0.1980433995749506, 0.10597682312179216, 0.19629736015866298, 0.2709326254726797, 0.10873294932673991, 0.17147012412382137, 0.12261548308461884, 0.10105665120057454, 0.18061285194775525, 0.1959582725471781, 0.30663536254072404, 0.3786503283268564, 0.1631168131038313, 0.20005728369306877, 0.08263734780307312, 0.16207838766127033, 0.1623554065455652, 0.3563458598934735, 0.28662360971259293, 0.15516175577988855, 0.30295524379732963, 0.19364482611526987, 0.14153913864591045, 0.1838801518382188, 0.12509880215616903, 0.17983249413880797, 0.140756527616877, 0.3464404994014297, 0.5386394814686629, 0.30121374265278517, 0.3572080507697602, 0.1958205595706002, 0.15579971749989244, 0.13264799461095478, 0.16601314822579236, 0.43143683202929356, 0.11991340215056326, 0.28204562325713745, 0.14323651709023283, 0.20548775532166194, 0.15108964640273334, 0.08942645401833604, 0.1311069713797178, 0.16875483146719736, 0.15484130407324884, 0.15147953513766857, 0.3294642239372865, 0.08790383508514957, 0.3032544384786644, 0.08082161114422931, 0.1525299164112463, 0.24267224887326874, 0.18086195413602552, 0.168783037894047, 0.48307084379793763, 0.08482184370178025, 0.09489877161156261, 0.1272671417428029, 0.49357866900955694, 0.12581376748899148, 0.19179114149022025, 0.11737249975861576, 0.12211722238931726, 0.305790817811014, 0.09191901036160852, 0.16421715945804016, 0.17173610022091673, 0.16828661775369252, 0.3644716578377502, 0.26095525099816297, 0.17188665844362727, 0.07136612786916544, 0.10385402556777004, 0.2378463121231133, 0.2306479662868554, 0.19905879959769596, 0.08638865200208011, 0.08473645294897719, 0.1002389911420655, 0.3230858744217582, 0.09274269977156972, 0.16354919099969864, 0.1792803178148213, 0.24313568032841343, 0.16456377298000754, 0.19355151996738937, 0.22195173403982965, 0.12425409681325862, 0.23417673932606906, 0.09721464821849908, 0.4755037655346167, 0.15804610028809624, 0.09853589112989862, 0.3306395106048871, 0.16926033875506194, 0.1964024452753589, 0.10480472462433948, 0.3556272192419958, 0.21605875236902025, 0.18786359066514444, 0.0967589228207791, 0.13683301634828035, 0.16144004595255812, 0.38284206465850645, 0.15810605610909467, 0.123440959851078, 0.09010780029305862, 0.25527780647058634, 0.09663805187922758, 0.1999807702727489, 0.3072540443061422, 0.16215135617154283, 0.4951519286692458, 0.15180178740178854, 0.5911986789310528, 0.21886125110592405, 0.3556623954891565, 0.11281420399252011, 0.15370315486348515, 0.2645994982453534, 0.18417166715732258, 0.2627693311810196, 0.3485717253127431, 0.13182219793652356, 0.11845032980046925, 0.48307084379793763, 0.24293243933568492, 0.3652284045679604, 0.149947809998002, 0.23855319892371968, 0.14660089292411715, 0.10384250688806393, 0.14830355685211002, 0.21456045025104778, 0.08956266835492055, 0.238439159404375, 0.3068657416066611, 0.3961507121558759, 0.24216562118906346, 0.21291693149283292, 0.3062096284706934, 0.15600901714879623, 0.18259222478508347, 0.3111284907423983, 0.16664743638106444, 0.17369404503456637, 0.1554282914121531, 0.21211388170293027, 0.10260816262547005, 0.15683055890718145, 0.0867714952326428, 0.2707144595667503, 0.08956103835165247, 0.22685445657538986, 0.3046882971357362, 0.09275883779401049, 0.14153166309025775, 0.13074970866891275, 0.20084628282917566, 0.10656736434959187, 0.15492333927340332, 0.20970838977871523, 0.23463693007426964, 0.146228975297742, 0.10068138299913315, 0.5188698690167043, 0.30901284990769934, 0.2813713488096617, 0.19210472493058947, 0.13314207289509108, 0.22027977409035684, 0.09537925983485017, 0.41590454658217263, 0.2508477331810298, 0.13385745754125114, 0.48307084379793763, 0.08196922247319159, 0.1804568506286891, 0.11614122936969014, 0.14615709299207735, 0.20390882284948944, 0.13472766607206554, 0.1536094135110699, 0.45071432277301615, 0.11127922449786873, 0.2104532603011265, 0.2739878289257711, 0.14797399929352792, 0.25434006012779614, 0.1230441635062626, 0.21705850936439192, 0.23935319953242162, 0.08418607993623836, 0.29490205418963783, 0.20962625090695794, 0.35226501657436776, 0.1855388272070347, 0.1041765455382294, 0.23474109536078416, 0.1526646586587794, 0.09605821257925216, 0.13643038309953612, 0.0958041057345338, 0.25703035186359996, 0.23517224303789352, 0.2335268191816845, 0.21216568432071273, 0.13791407629022434, 0.19916877573328487, 0.27051836554972564, 0.33433121658625425, 0.07461951299889692, 0.21084735553125616, 0.23947079923307585, 0.11933921792708746, 0.25375396944409984, 0.24323614268427737, 0.35935658686820077, 0.3561541919023432, 0.17051069033522143, 0.3697690492387635, 0.15788856358961303, 0.22295607340016904, 0.16601156779622814, 0.09163091952468012, 0.09657837745549024, 0.1068322868321301, 0.1526843867287427, 0.12940112832648576, 0.15799894673394177, 0.09139531932314848, 0.2750124975675424, 0.1299720726432349, 0.24378202093658322, 0.11111582109851538, 0.16363479499594885, 0.20605277339867342, 0.2081304839881948, 0.08329715647048118, 0.1302268064259981, 0.09351346613323812, 0.09741919187537773, 0.23540273167617107, 0.3048416578198233, 0.18632405833409532, 0.20132348723284765, 0.1487338837223821, 0.1841132322998083, 0.1742555276796674, 0.14528091060420117, 0.10775229999852863, 0.13009349705577605, 0.14402141972051824, 0.13809641073452572, 0.3259832796248456, 0.10270383041631549, 0.13283028990770626, 0.1333904213289375, 0.09916906746065313, 0.19541932066529932, 0.26572836651812093, 0.3750489364081211, 0.08531725349490253, 0.33267289161640407, 0.22068332137211744, 0.1054454070283681, 0.1451006116170418, 0.17002787208845718, 0.37080142782378284, 0.2672398673700247, 0.14747430873812373, 0.10847370597849149, 0.15706189232823428, 0.2999709748560375, 0.4202238526288736, 0.2368733443198072, 0.10140512684161639, 0.13568793160229944, 0.29461422762127165, 0.1623065173149124, 0.15135984539347214, 0.08203252969805563, 0.1364537335133017, 0.20499255394775087, 0.21236113639683962, 0.09838177888589895, 0.11850806156670061, 0.1413928232727345, 0.21464921059535455, 0.3555951207491793, 0.3235240440493806, 0.18168113495133978, 0.3799224586697186, 0.1100783767649699, 0.41442020201971624, 0.3626116536960478, 0.14397393666134245, 0.22308234818309405, 0.1380129875140115, 0.22557071298562822, 0.13317637776911498, 0.11421567197147951, 0.156201517089735, 0.11910095883189807, 0.10942712763094734, 0.22466972209913522, 0.16026205767263368, 0.12840675164465257, 0.12285297296844044, 0.19139466491697077, 0.12003171616187808, 0.11889868458842828, 0.23196385388660792, 0.22397046186329042, 0.13536376106954612, 0.12584434150728532, 0.28538195934522576, 0.10597682312179216, 0.33491227132212675, 0.16114920653017475, 0.10486254947536265, 0.17459175956970513, 0.26722137712275945, 0.14605114624957072, 0.14732354836183226, 0.3541983470413805, 0.13918977022839552, 0.2837804241089711, 0.11822132307664611, 0.31963169355272625, 0.15523241775006183, 0.2930524886006305, 0.10800954321898638, 0.11159276924335325, 0.29232510760365404, 0.1666549819171059, 0.18407349015977398, 0.20170997515881456, 0.11704798849043209, 0.09851668488018198, 0.14344169178784863, 0.34628734546142775, 0.1763073811775997, 0.27014127378902203, 0.08870505274420491, 0.16078135215955341, 0.10290142535687934, 0.15823898162247577, 0.08974496699263393, 0.2608900931358092, 0.2863615791350808, 0.2981199984690201, 0.15501832026177054, 0.18283721191472435, 0.5062057488495489, 0.13074970866891275, 0.17918589508379465, 0.18105177132872932, 0.14769768946320172, 0.17204545742164762, 0.1185306837965055, 0.29743032981870016, 0.09913506063251745, 0.22561810269153804, 0.19266186400121244, 0.17465244253085374, 0.10358562097676004, 0.25419623785214296, 0.18789068713612722, 0.24549257336812866, 0.28925673830957055, 0.49804319310719175, 0.16106016958618635, 0.19539332493194225, 0.21213803506795229, 0.1099564415137, 0.2086354727445693, 0.3373295389649245, 0.10697037458827477, 0.14298033812056804, 0.17934843887491764, 0.26352748818121935, 0.30947716690891325, 0.09281195695876696, 0.1411237285459499, 0.16904200621891682, 0.1044568067566853, 0.13105336156606243, 0.2280453112410289, 0.18086143115127623, 0.1907662675636973, 0.2567212521928019, 0.194499179241679, 0.1358823536792075, 0.11829815719338341, 0.4349993051812495, 0.4275779929438576, 0.09211178618363067, 0.10190334394128939, 0.13534626747973108, 0.4220110141803549, 0.10354603739897389, 0.10038037953688438, 0.10602321902166133, 0.10686527239137285, 0.16552087962155346, 0.0852813876601418, 0.08694027450760242, 0.2650409037977105, 0.15668986813679384, 0.22570526092812984, 0.1559208161263935, 0.4770698400351276, 0.11292912452030131, 0.11314903156287857, 0.13162887867603423, 0.11130159883021287, 0.4196195069054217, 0.17494368308527236, 0.40266387756011496, 0.07805354367511529, 0.14697972813275625, 0.10570841843707693, 0.18288894519476454, 0.12145237121421655, 0.12322161208232477, 0.1982377026404012, 0.24708995373287274, 0.5992042630512019, 0.10049433291191688, 0.17451221988223076, 0.13898003917549787, 0.21080659079644345, 0.11041837942308359, 0.26730277785316936, 0.23315173480487897, 0.1300333994943614, 0.1224189242701488, 0.1282738220240665, 0.38006177149885323, 0.28134522383751026, 0.3317283741884271, 0.15902482921452438, 0.3396149322135154, 0.1499156140872367, 0.16202780340145764, 0.10244156127844983, 0.12751016416231858, 0.2329047278476207, 0.17283794951342651, 0.2698728714609807, 0.14605937407153127, 0.22708253630538802, 0.5079643594465005, 0.26572836651812093, 0.13879974735708792, 0.11594365650881355, 0.16618230356208497, 0.17097909668559746, 0.29327819374497627, 0.13987229242392477, 0.2824474603709871, 0.17376086387823297, 0.21762523845511345, 0.10297124859942977, 0.10100929431166598, 0.09275544294660662, 0.23646516171359305, 0.22655300224959884, 0.516266233161901, 0.20366425998941876, 0.45071432277301615, 0.1254176239471528, 0.17015210251644153, 0.2949195200432984, 0.10449541874112797, 0.08640213082040436, 0.16680091758050994, 0.23365934070837835, 0.27984400090016825, 0.19433807890661509, 0.07924097378109321, 0.256919185283627, 0.17629471366408306, 0.10292795851279464, 0.10877294423467854, 0.47694656249197626, 0.23157990898682673, 0.10005487997324543, 0.17092250086698577, 0.1121947132757109, 0.4823210313482519, 0.16397381277886938, 0.1838801518382188, 0.2833694740130464, 0.35912119697068834, 0.31380662906518847, 0.4288825032111903, 0.09451957544207519, 0.1537521515132844, 0.47454643390258056, 0.1857673695589874, 0.24585503032390538, 0.16823326840354483, 0.22413929594973406, 0.1516169177085763, 0.23112031836490018, 0.28192173510503377, 0.14312732133573408, 0.37065234628181415, 0.16514087241696704, 0.07984785323008307, 0.14120173397584274, 0.13834119968734637, 0.2944308846103895, 0.2410496769387186, 0.11564255373937771, 0.5764448173791661, 0.07810016556162899, 0.3097168801951733, 0.42398262940987164, 0.09278423750935388, 0.1540534140019961, 0.41442020201971624, 0.4135998853987443, 0.16694348643863893, 0.38284206465850645, 0.17127844970320652, 0.2804439309058081, 0.16209832430878177, 0.20035028063432442, 0.22135332669572538, 0.12486481478885851, 0.08562075288825419, 0.15374851260450068, 0.4864480859551052, 0.13599851062567606, 0.1967771373492038, 0.2824474603709871, 0.2583854152790797, 0.18401985134418294, 0.36935887244227567, 0.1417566753535878, 0.25829610993447466, 0.14804473794734693, 0.28495502693174185, 0.1410271067017985, 0.4572391049149258, 0.2239292521990116, 0.155301025558858, 0.17468279124900507, 0.17287469279623735, 0.4105205353925584, 0.10750771865196503, 0.15554938288750939, 0.09932657346485607, 0.15715661821327206, 0.3586421013770097, 0.13797256396550908, 0.2193454523799662, 0.141056918767581, 0.09408897655035581, 0.32778680652138104, 0.13937141413208726, 0.09917293615916009, 0.1838801518382188, 0.1770164192515628, 0.581573341970609, 0.16114920653017475, 0.2013781577402897, 0.1935551818915672, 0.1367701595973865, 0.2206421365557955, 0.13868207212092945, 0.2342333280667082, 0.12588767093750292, 0.12469768936927611, 0.1433700673742187, 0.24193823896676803, 0.15668986813679384, 0.17721384234464688, 0.16022067526219802, 0.2686108260722871, 0.08768971139747869, 0.3744980545396318, 0.12644986508716877, 0.37311883218935255, 0.3006931877650201, 0.32475786684498886, 0.5676103904224539, 0.12910790458305393, 0.09776755547764025, 0.18519582426316084, 0.14228516858978166, 0.22616827097557712, 0.4746162024194521, 0.2703281981872639, 0.31799769088257196, 0.10066831425687435, 0.22429808583039074, 0.10937118116396921, 0.1598021192338903, 0.3544797359724909, 0.1939635713361775, 0.10146228962032401, 0.07722983359846543, 0.581573341970609, 0.1705184782669015, 0.15634449014671029, 0.1185306837965055, 0.08812995456493344, 0.17940233321302654, 0.2795080995382614, 0.17041541382616665, 0.29991118548955453, 0.21073033260298282, 0.318816635311991, 0.13776204594428504, 0.2624893039151901, 0.3339471334542307, 0.0803746810460646, 0.2267736568109108, 0.41468832613012524, 0.1544711686608701, 0.09147139984091565, 0.23680513795928004, 0.10945583583018789, 0.24143692791058083, 0.32839507069610874, 0.21291693149283292, 0.37323940585552595, 0.12910790458305393, 0.3159112092349187, 0.20423391489131407, 0.12940112832648576, 0.12910283027891167, 0.18984462864343124, 0.42807288955149775, 0.10337911474845551, 0.14067847612510045, 0.28538195934522576, 0.2288416537715638, 0.09718469843550885, 0.17918589508379465, 0.35226501657436776, 0.3474318675965141, 0.2015558893399803, 0.2452822521528113, 0.10711606681465956, 0.22616827097557712, 0.2825047088485866, 0.2772873706954284, 0.2948771996635331, 0.08308352763675649, 0.08635999050463157, 0.12395856051426238, 0.1538997455840675, 0.34227478397706224, 0.21001086995706145, 0.255817160140536, 0.2007823108658557, 0.12951993032651798, 0.127166847806733, 0.15204164001639794, 0.33170382901530115, 0.09100875849994286, 0.22219088892656652, 0.11639478223965823, 0.22353849068070128, 0.24345389856455998, 0.23319349392869554, 0.18121316989581832, 0.10276805261520496, 0.10745113843300516, 0.16524620187080383, 0.20026830450659439, 0.1408033134630473, 0.2833449626712013, 0.12395835243859196, 0.14461664876109268, 0.1508316304416245, 0.1417566753535878, 0.16446270235645877, 0.08764837697375062, 0.26442023175632273, 0.3257837936868866, 0.3213070022305914, 0.12432214250385057, 0.46611505408381887, 0.09523009987056168, 0.16489848619458747, 0.15447737968157896, 0.17618708764215604, 0.1592088587468979, 0.10190129669682889, 0.1224523374409538, 0.2086257656323308, 0.15163185278827185, 0.2535448258578573, 0.11120702789048661, 0.10208502242416474, 0.12705113911945046, 0.17579591979833256, 0.12993266900745667, 0.15647707660469384, 0.44715997692283826, 0.21940834428232897, 0.17254824578947947, 0.3878706389932585, 0.27702291081783287, 0.13652322405295458, 0.1057490397296691, 0.13284615921340012, 0.10609939043564859, 0.08353847207629551, 0.2944308846103895, 0.1390268674552081, 0.20044530242738323, 0.34707899061968406, 0.27935435129932357, 0.1425426648732231, 0.32850876549315006, 0.10731981795921965, 0.1725135390715529, 0.2142254914735425, 0.34529156017529855, 0.16295073161683263, 0.14746073407677296, 0.2813713488096617, 0.15725645449009157, 0.20808869992847734, 0.14233072425890325, 0.3080046264986765, 0.18336123843645502, 0.4823210313482519, 0.149947809998002, 0.1081752433646771, 0.1637404231109772, 0.1925488316170011, 0.15275094068263326, 0.09718469843550885, 0.1841670206743163, 0.1508202905204568, 0.3226591919733774, 0.0991907861507779, 0.4198988579943077, 0.19346010435567726, 0.09232633019083, 0.1484699130366631, 0.4275779929438576, 0.26648435970203405, 0.2000232825852703, 0.17226387782906863, 0.21211388170293027, 0.07380664008452266, 0.15715577300638936, 0.3532189458663939, 0.2675554981271746, 0.10338485208393683, 0.18522497499139487, 0.25619113541343025, 0.09490901507363124, 0.2310512297034732, 0.11850806156670061, 0.0913777066069525, 0.1838801518382188, 0.2399535761670323, 0.14434330638191448, 0.21577432025621376, 0.18948763375197172, 0.18508588231554046, 0.15049224174621256, 0.348610509672373, 0.2866319333367715, 0.27966849107163283, 0.5486283854488866, 0.2563826921192748, 0.22977322048908566, 0.2558278514378086, 0.13757370854130363, 0.150198321328682, 0.14667381856133263, 0.1655655445349413, 0.15386888050210673, 0.1002389911420655, 0.2940786738164651, 0.13330396340234102, 0.095353460624896, 0.42795967024153264, 0.17220706683268958, 0.16587238182677758, 0.10305944728521317, 0.2984564993391228, 0.13692445756451407, 0.1694085835418452, 0.3869026322218285, 0.09003212939138412, 0.08790383508514957, 0.20022111714436225, 0.19569380028545713, 0.22739091233834224, 0.13362684249003157, 0.19709186128852674, 0.11148485133248243, 0.20605277339867342, 0.13310004412371784, 0.22786357882733407, 0.16641345603586608, 0.19464662051183035, 0.2796196772113044, 0.3689123317084946, 0.09819946421874991, 0.1379283777388543, 0.08183468578535369, 0.10529549553879246, 0.42561161486544064, 0.25216481397894136, 0.332965992007588, 0.2014493219923497, 0.20142737235224237, 0.15966131139441103, 0.3313932080335883, 0.19744915493927065, 0.09093929614732295, 0.14641059911158144, 0.1594682872214346, 0.21108654073920857, 0.2429485291036813, 0.13469825906465388, 0.17421169186212918, 0.2351173731088308, 0.5496342499375625, 0.1703875446556059, 0.14667381856133263, 0.22195173403982965, 0.17467142626991494, 0.08464361411171564, 0.30658309137045, 0.23129411689181148, 0.19468051243670323, 0.271780037235607, 0.294266356413627, 0.09333909371089187, 0.2693225671509693, 0.08655960141417127, 0.11728769508684465, 0.1361019815055702, 0.1840238279569943, 0.1801758889302422, 0.3636712341657808, 0.1451006116170418, 0.355472125598141, 0.19076773946719783, 0.44821797000437574, 0.26304828427557575, 0.29372609583542925, 0.20787174919938792, 0.1054454070283681, 0.19164339436593275, 0.2880157254526639, 0.15785960733666715, 0.3556623954891565, 0.4746162024194521, 0.21651617943920948, 0.24540033606710923, 0.11334512843464999, 0.1039859762042111, 0.2733972782387217, 0.17588899745218797, 0.08007134948543052, 0.2177400111134246, 0.10964869437162862, 0.15771327106454044, 0.1482951172484825, 0.15507838556248837, 0.2595726366490183, 0.3302652889564966, 0.2647128041795909, 0.14655386428200143, 0.1263025151942224, 0.5496342499375625, 0.08066459356363193, 0.07637464716176577, 0.27573472443950103, 0.35491448115475976, 0.09709112922864174, 0.3250460070530031, 0.3153712968559577, 0.08167897021003309, 0.09545226186705878, 0.09168894959979834, 0.12665062615290149, 0.23157990898682673, 0.11316059908838948, 0.15756657049330214, 0.3396149322135154, 0.1369237767210502, 0.12664044783571285, 0.12993266900745667, 0.2089581813731207, 0.08314984318336059, 0.5386394814686629, 0.32359410765193075, 0.09067612166539539, 0.09468696464633697, 0.13489738936774473, 0.08655960141417127, 0.1310265931271097, 0.3589879305755459, 0.08082161114422931, 0.16026205767263368, 0.143900790136254, 0.12106928852220403, 0.37323940585552595, 0.1889182009357782, 0.34221557144323206, 0.10414812656701622, 0.22203005958543603, 0.09023720907473634, 0.15426085971841003, 0.5079643594465005, 0.295206810878853, 0.09576002483151752, 0.13141811746572876, 0.18949064626727727, 0.4726550495681338, 0.09959982435683616, 0.1833004092592993, 0.17266910682945363, 0.1623243741279086, 0.35228629208593204, 0.17480180099937223, 0.38747217676747703, 0.1125557430073872, 0.13126092938147985, 0.09926336914176216, 0.14370290721137838, 0.08949677867480459, 0.1476167091472778, 0.19569380028545713, 0.17078540274201917, 0.16661684307373031, 0.5911986789310528, 0.2013781577402897, 0.11572516625420787, 0.13791407629022434, 0.23516112785243434, 0.16380995332611803, 0.11473880881228331, 0.2514852689028675, 0.11827520639141696, 0.1311373405675797, 0.17154109655473446, 0.21017516302884034, 0.13964717662615625, 0.23939780994391516, 0.13441292507990962, 0.12926712052588718, 0.16549008170608392, 0.11284505495047041, 0.23899790770411347, 0.3388087229888611, 0.2899602633559631, 0.13392767663971633, 0.12000327381804683, 0.12283733776946247, 0.11968592682949875, 0.3303597588352889, 0.44363727433966377, 0.21864178837272447, 0.10457788933924261, 0.17283042969039186, 0.1394748187675655, 0.31278014697340745, 0.2485136860626652, 0.13265486505535268, 0.07962607555828617, 0.09232633019083, 0.19535001855064274, 0.16023212658221644, 0.2305748461355929, 0.5676103904224539, 0.5992042630512019, 0.34098204392191567, 0.07935810608299239, 0.29659524083760463, 0.2460513729981262, 0.48256236450899664, 0.07407925855377702, 0.18701241343802125, 0.21930154014351272, 0.2857653532087972, 0.1537556083367633, 0.08864160020366799, 0.401980044409984, 0.16549008170608392, 0.1193474492403268, 0.11308049003686715, 0.19070512942838574, 0.08487624330677, 0.272571562414876, 0.15247515568136608, 0.13317637776911498, 0.37311883218935255, 0.21211388170293027, 0.21652201157203602, 0.2435306880145468, 0.27033775323048614, 0.08807054702724693, 0.10787750926432758, 0.22559549161339432, 0.40996158462506826, 0.25808849661648453, 0.106737092560952, 0.09212354182594037, 0.23418938371266168, 0.45071432277301615, 0.11357108803679036, 0.2361956931907559, 0.38284206465850645, 0.1490205321495017, 0.24272806110840275, 0.11442857488013246, 0.11772011741755369, 0.13776204594428504, 0.18595794293496298, 0.2196978521994028, 0.14348455457916326, 0.18031588435432197, 0.2530523631029254, 0.22430721394097572, 0.24242144939552907, 0.1403524370933477, 0.11031690769744956, 0.20141395967206824, 0.228445401028403, 0.4425022974195137, 0.19682169220906892, 0.32510863751658475, 0.26629571663296686, 0.10290142535687934, 0.28538195934522576, 0.22413058093929844, 0.1552411404016095, 0.09980660999731407, 0.08620148841173796, 0.23939780994391516, 0.2464448215780562, 0.10723399344653038, 0.24949714289135003, 0.2558278514378086, 0.25999251664510165, 0.1803800859265751, 0.10399056804980156, 0.11112633801942794, 0.1417566753535878, 0.2705458813515276, 0.19464662051183035, 0.16832047152814616, 0.10308084114155952, 0.20413170782014692, 0.08807054702724693, 0.18727790755742127, 0.2137500179024682, 0.2938039980420641, 0.137979809714732, 0.07394232599456174, 0.139739433820878, 0.13144732079555965, 0.2501646482470187, 0.24885906268142433, 0.11236226160365476, 0.13274936598138515, 0.11516178111074504, 0.11319089527834468, 0.38147991675355725, 0.12472487488286739, 0.10425415361202249, 0.21586464296516183, 0.5386394814686629, 0.3448515624745258, 0.25672346583631445, 0.16623029920548665, 0.15364031608741793, 0.1311336560184782, 0.12261548308461884, 0.14819551117946708, 0.0929889775893909, 0.15100319240844284, 0.18718680806171836, 0.09214527833440889, 0.11297870081100625, 0.16370037925818393, 0.26346568155582517, 0.18765428192885092, 0.1516169177085763, 0.15526793664444807, 0.19691273925002428, 0.1870043926890674, 0.18771659504273916, 0.19963045925727363, 0.16845779050223314, 0.1919636774800855, 0.20085035337810506, 0.42184829187333883, 0.16321044656125036, 0.5204764260920854, 0.5007265828309193, 0.23431877205023544, 0.09864958531605758, 0.1560194360329498, 0.1175114024020063, 0.24988423127992895, 0.10935145388663883, 0.10540182816226916, 0.25294426843301104, 0.17138213011279463, 0.11423861298247114, 0.14114665226471987, 0.17668673316875985, 0.38006177149885323, 0.3459322520765109, 0.2657555707460084, 0.24894711608148223, 0.12620887392408867, 0.16363479499594885, 0.11671314335807745, 0.09720642249585996, 0.1417566753535878, 0.1100783767649699, 0.21110641849633738, 0.16246246383968604, 0.13544400322897024, 0.36704147133229426, 0.22068332137211744, 0.30244768146975315, 0.28039449146631445, 0.18931308957265067, 0.1728735084201577, 0.3106393732552686, 0.11100208665698429, 0.07730702368629205, 0.10438711978337502, 0.15706189232823428, 0.3257837936868866, 0.31131277176836103, 0.10698743669161229, 0.13502840434009855, 0.34204868578515746, 0.15565446793207333, 0.1403820012080676, 0.4127642569699383, 0.0907612520498421, 0.33850157508212114, 0.47477885186369395, 0.31529502596461456, 0.28929510147345905, 0.20189085403408974, 0.23390395963928542, 0.20863547736419935, 0.08997278151064343, 0.4220110141803549, 0.285922673250451, 0.17210191574372874, 0.11674581099923803, 0.08158744294476605, 0.19782196613481065, 0.08322025319086726, 0.2403791519516788, 0.105358512241887, 0.5386394814686629, 0.1875824563004759, 0.1451310070426217, 0.12719337920993593, 0.08045479950355511, 0.09379856332389354, 0.07817944001586198, 0.1502870209245121, 0.12751016416231858, 0.24949714289135003, 0.26243753400282743, 0.29280098596708076, 0.14048487816063893, 0.10511990442355522, 0.1623414322781574, 0.1649774252412042, 0.19745596736658066, 0.09051303299062417, 0.10269190148676571, 0.21367389427661213, 0.1429601185447163, 0.17222911656303128, 0.22659289686724982, 0.10905162969164181, 0.4951519286692458, 0.18659239757875642, 0.18250516413746778, 0.2522731978370499, 0.08048919471135337, 0.13413836474513124, 0.12731271268436897, 0.17215440902367513, 0.14480841703587616, 0.09392826475525139, 0.3114986033942644, 0.1591344822695099, 0.2985417254712803, 0.3015735818238021, 0.22739091233834224, 0.08780395055433134, 0.3561541919023432, 0.12640170902591094, 0.08601273103333364, 0.46917717929536035, 0.17504928951283147, 0.13125434970033895, 0.23517775730656165, 0.22049338099660643, 0.09610622041458249, 0.2446124611256856, 0.09251964792459191, 0.174155016256955, 0.17376086387823297, 0.26626369330345445, 0.19126881471318097, 0.26871243691879715, 0.17695846255375303, 0.08941293412090583, 0.2776820370701776, 0.23947079923307585, 0.20857543405233656, 0.21637593873607275, 0.08837019662787984, 0.22240679971829388, 0.07217234425502976, 0.23933506997835038, 0.14788345571498873, 0.3609038683997968, 0.09008942654756891, 0.12028702254889893, 0.3373295389649245, 0.24242144939552907, 0.3746178448388544, 0.1482906363894838, 0.31544537239220605, 0.20707405679723415, 0.2133035521867412, 0.12019960198147839, 0.09820455957532431, 0.2603389540019931, 0.1116692211781732, 0.10558754191161387, 0.1726578399262311, 0.17520479254502144, 0.211110659694248, 0.13686044314775894, 0.13341378627522466, 0.20631590112892867, 0.09730451605512441, 0.13534626747973108, 0.10297124859942977, 0.21216568432071273, 0.11266533488665245, 0.42349926069713334, 0.26945547810737763, 0.1632367385691342, 0.15266254483933597, 0.23611996439770574, 0.10617172522609522, 0.11862581608543347, 0.24692930986243902, 0.19035719739833978, 0.13904280436897584, 0.2014757118530353, 0.21238990718385706, 0.3481218414011921, 0.3603028611467009, 0.2208551900175127, 0.17058457799726054, 0.17918589508379465, 0.2440850946272825, 0.1454794362941009, 0.18701877926169022, 0.0869945889606575, 0.12203467791707234, 0.1232211534749361, 0.09718860398445725, 0.2616610139381995, 0.14205155211234863, 0.3602160866754837, 0.11845032980046925, 0.18070819231860638, 0.3145823127607381, 0.3718073230240259, 0.08698342510376583, 0.1627153219738723, 0.1231545344709704, 0.5676103904224539, 0.38121927953858353, 0.07405944489748639, 0.1061346823926363, 0.4211560996575999, 0.26262196353373435, 0.17440559124509425, 0.13220020496643814, 0.09456172738795972, 0.11639478223965823, 0.1100783767649699, 0.26550323506929974, 0.09779766097961676, 0.26550323506929974, 0.16113694846199555, 0.24403379791122679, 0.1898531233087975, 0.13316477643093852, 0.2498731422121365, 0.25864095235037643, 0.12620887392408867, 0.13947574821405412, 0.11725066459492822, 0.11495446017002722, 0.12457216472097032, 0.20435918082516588, 0.11659083849228874, 0.09092249626722915, 0.4179858656109286, 0.08276375349640583, 0.3102146890560151, 0.25755870416581933, 0.13878777210919252, 0.17008417855765995, 0.28192173510503377, 0.09162839208246171, 0.16316713207541628, 0.14107453475907852, 0.13122073574885165, 0.10685902434895589, 0.22320608179301463, 0.3561541919023432, 0.3563458598934735, 0.2279520566680649, 0.142388480876474, 0.19086018840535382, 0.20980478272162956, 0.26502858350589703, 0.3299966368685384, 0.22336434278224346, 0.24242144939552907, 0.21735173076095798, 0.11349197205780243, 0.2127687264389007, 0.13947574821405412, 0.1637763953529512, 0.14171237177872759, 0.22303270606740488, 0.07919288850999821, 0.13904280436897584, 0.1783273385158952, 0.24912668791009504, 0.1677966994732731, 0.1253924528796463, 0.09192798400104878, 0.3574942451186762, 0.133793459738786, 0.13846651643169647, 0.1385129933829285, 0.20835516314616917, 0.09025617709482092, 0.1397461748142301, 0.12106928852220403, 0.2044942281962898, 0.1254902078718721, 0.20311581709594947, 0.4545765786201892, 0.1207880119696864, 0.2143600781428386, 0.12864805455395747, 0.18273643420707553, 0.15202695098064795, 0.11153160339143146, 0.1361168847788148, 0.0829532332413645, 0.22591240756759765, 0.16560061651140906, 0.1921827904095009, 0.15281741229348578, 0.3627561789694509, 0.2951823476351516, 0.2479224292045381, 0.17271887961850924, 0.4214200822667379, 0.08708472452541047, 0.1427480447147977, 0.08045479950355511, 0.15513414778127088, 0.1576505254168633, 0.09829743539807387, 0.124398397762628, 0.10740215391644636, 0.1004467368432291, 0.20605277339867342, 0.21873069629855862, 0.08356734309038918, 0.18314005629315766, 0.11717949745940723, 0.14137511429078786, 0.2143600781428386, 0.17028589597005406, 0.14113043881118828, 0.22888717121770502, 0.11619947843176459, 0.22049338099660643, 0.3786503283268564, 0.2518795039519311, 0.14171237177872759, 0.09164292460337259, 0.31028572651141567, 0.1592088587468979, 0.10800954321898638, 0.08830556040008142, 0.14270926297296543, 0.13687348370307095, 0.17715673246336608, 0.2744472981496168, 0.15563655844269841, 0.11033522722101287, 0.16871087852740088, 0.21432370232208814, 0.15633754951105613, 0.17165315852778598, 0.16478442438860094, 0.14287041574419249, 0.5538905794661377, 0.14896400202656984, 0.16397381277886938, 0.1303343565368301, 0.20143058045658763, 0.3044603798615576, 0.20568724128284244, 0.14357748286723437, 0.36658871044970864, 0.15442937336165707, 0.25861376013349263, 0.18991843577176334, 0.13126092938147985, 0.16845779050223314, 0.15173185641429612, 0.09367934571399845, 0.3571371188848233, 0.24440042942029536, 0.09630317167583742, 0.19324845870952975, 0.13219869905821385, 0.15377305727022153, 0.4648934396739465, 0.2845209904760744, 0.14469056924035675, 0.08845335616230116, 0.29181677614874224, 0.1943947302088987, 0.18985989479152582, 0.2344628152512652, 0.3304127498475118, 0.2398125492804338, 0.16440249936067305, 0.5512092554702412, 0.43404199953769934, 0.49804319310719175, 0.25793133160036724, 0.5676103904224539, 0.364642361186223, 0.2487297779892165, 0.16028015170416507, 0.24640034163078214, 0.1402071332891484, 0.33312404637789594, 0.19146255983777086, 0.17199284609535137, 0.16152881348931028, 0.11434777804192263, 0.3307510694635067, 0.17048382618598057, 0.2926527683179763, 0.2945671963694236, 0.3864988916444829, 0.192465684676965, 0.21170863121106057, 0.5062057488495489, 0.2086257656323308, 0.20144787784501875, 0.23753944952145412, 0.2058229004232262, 0.16963958359389344, 0.0932974615382821, 0.20241492938153036, 0.1382405229767219, 0.2982496118034891, 0.15002030479114029, 0.13001033974717677, 0.20121548538041162, 0.24462815756336245, 0.12176372462197463, 0.21990556394722718, 0.28192173510503377, 0.21624382092014705, 0.10209143066660406, 0.13083521624089015, 0.10873597879276393, 0.11151118766402349, 0.1332572606595831, 0.10747804130871105, 0.28975987133130454, 0.10438711978337502, 0.20311581709594947, 0.2806990629939265, 0.15691568477517934, 0.2036471365357449, 0.09246386212981064, 0.2948771996635331, 0.17499147240499255, 0.2938039980420641, 0.15573812120884833, 0.10651282360728008, 0.18033235123172517, 0.28975987133130454, 0.08494662046788708, 0.07606812186897005, 0.17975247667019875, 0.35607911362900774, 0.09406773119146529, 0.10029834108135574, 0.1828730339767451, 0.15571219903232453, 0.1393392914141591, 0.2505113699659543, 0.13362411014148348, 0.07779334333458872, 0.4879795919033028, 0.38288035849463875, 0.08916562210065516, 0.2625246838049315, 0.16457948808393577, 0.1641019289066647, 0.18456658995633837, 0.17069973083924522, 0.23563828765842135, 0.19223666468405604, 0.12736790818017818, 0.15381456159915827, 0.12905470709823413, 0.14163472089040569, 0.07923787973929741, 0.26713232498452555, 0.31028572651141567, 0.1402523789883074, 0.3563412955320864, 0.2080637686312259, 0.12906401491406608, 0.1528726308621603, 0.20017119640307046, 0.2620125714834167, 0.5079643594465005, 0.364642361186223, 0.1812317854550834, 0.22661858869473028, 0.09301292439510139, 0.2191748499750129, 0.14357748286723437, 0.1193170066424536, 0.2618491883636542, 0.47694656249197626, 0.1380920402988064, 0.09397566818024253, 0.28418396262434165, 0.268833718728047, 0.15392824154293996, 0.34593363978055913, 0.11681369151948345, 0.32849866584685167, 0.0946630269281055, 0.09243446809359127, 0.18425801583068255, 0.5676103904224539, 0.16160813793903767, 0.17078540274201917, 0.09386934270330273, 0.18997667979913466, 0.13516677491761317, 0.22248108416173792, 0.10905162969164181, 0.22135332669572538, 0.27986770466184346, 0.14067847612510045, 0.23755251433465244, 0.0729463768473165, 0.21432370232208814, 0.09685964541755591, 0.3153712968559577, 0.0958318264095, 0.20009818234021082, 0.13707210348804977, 0.36312938298641245, 0.1288834124227207, 0.33416179938949603, 0.136710930471734, 0.11308004829128515, 0.3103298854036304, 0.1054454070283681, 0.4879795919033028, 0.19652258490482885, 0.11802024602268717, 0.34928754566456005, 0.16798025378663967, 0.17981236373297552, 0.22303270606740488, 0.2730629860774182, 0.17714896409494527, 0.44635136608926645, 0.32256574536647775, 0.13757303215357822, 0.11935219089632386, 0.1719970187017361, 0.15422670915734427, 0.09120532775655853, 0.41364762167394253, 0.29032399297341177, 0.10656736434959187, 0.18403474212535847, 0.23339924137063164, 0.12872561145849692, 0.17985093698773513, 0.428938048363785, 0.10881244560829241, 0.1145191271112018, 0.15187431014953273, 0.2520678572919818, 0.2545642524826269, 0.09329389288685726, 0.0883160627400469, 0.13132260578725288, 0.23915968676979693, 0.14273879461947458, 0.5062057488495489, 0.16697851812414172, 0.08939466922174412, 0.2184728796329656, 0.23789653625533305, 0.21552707426476056, 0.38049015685212767, 0.11012634710889024, 0.1698240519355579, 0.16613110284199925, 0.38013008394321696, 0.43282852265692007, 0.23417673932606906, 0.12019045214197087, 0.09162198152382536, 0.13216926069983473, 0.14734688053173373, 0.23205716542258986, 0.1491367563300569, 0.11691752314352533, 0.1783273385158952, 0.2485885324572826, 0.07767603203290542, 0.26325841912947767, 0.11654227026148169, 0.1090271259302053, 0.25011600341198037, 0.18600866242421452, 0.2889719195079178, 0.27405679247170855, 0.29265002243783933, 0.2728380370607878, 0.21054792503894174, 0.13312971285960903, 0.29243303045715185, 0.21269136457112783, 0.49804319310719175, 0.21821581731646558, 0.09617205733544176, 0.10501602532081025, 0.3112723951982825, 0.34227478397706224, 0.17745607893590198, 0.19087569264872997, 0.12891463059928027, 0.12584434150728532, 0.1767761240858703, 0.15548211938671838, 0.3852167521121649, 0.23045273838125624, 0.42084100190161533, 0.26716294162930004, 0.13228095976401993, 0.129699708379325, 0.32256574536647775, 0.08516114639287822, 0.16204592164201204, 0.2899602633559631, 0.24302636688841672, 0.1872108211783572, 0.3561541919023432, 0.13164813616071905, 0.12242904909008513, 0.13448709144674625, 0.21291693149283292, 0.5676103904224539, 0.26474858695430054, 0.1439492723599783, 0.14198063787185553, 0.15060204161043148, 0.16370037925818393, 0.1029351938040256, 0.23909701514473924, 0.15917935820728876, 0.3507887219783732, 0.1497624213341718, 0.14358228980468027, 0.45355097462155597, 0.27937160429006436, 0.3295875908694729, 0.36312938298641245, 0.2017129016835303, 0.4202696532526442, 0.29490205418963783, 0.10698743669161229, 0.1748180068310953, 0.18372896003446393, 0.11048029535972295, 0.3378525969972792, 0.10796497585761938, 0.15208819461958747, 0.10232657172770532, 0.11308792086002298, 0.19679220651196458, 0.279197546783847, 0.37323940585552595, 0.28961570523297925, 0.13970998303583176, 0.08936396895084583, 0.291027020875775, 0.35904458446213694, 0.19238093427879255, 0.11867212145836503, 0.15805264402792163, 0.28802873839029136, 0.08296850485609834, 0.21018925514827203, 0.30314976250798364, 0.46515295853577077, 0.26262196353373435, 0.204074799062787, 0.20099062767039996, 0.1802935229785248, 0.11073774438430041, 0.10433901766110222, 0.23987961704886843, 0.3467391650037226, 0.4139985031646452, 0.24642013100377516, 0.17048382618598057, 0.1312215171611601, 0.2990516006292591, 0.13934720411617538, 0.22565886301732577, 0.17197629525295233, 0.2897706534874757, 0.22409475069429918, 0.14599992479488383, 0.3270493236470508, 0.16203009746390917, 0.30810809575249, 0.10868523815573386, 0.3681761499313138, 0.1617288532111124, 0.12191902489996997, 0.12384503350022032, 0.3143103387395004, 0.09392278023382068, 0.09517526612330003, 0.12016431434193231, 0.08480504566179628, 0.12736790818017818, 0.24396117553166277, 0.08529320200675115, 0.18131385584003132, 0.18159724590840165, 0.20970838977871523, 0.18782420779203277, 0.08481940731517112, 0.31048123395201277, 0.43273522317485413, 0.2604488459933413, 0.13606157516803308, 0.12561779081034866, 0.5992042630512019, 0.2763866817081692, 0.4892774922528369, 0.22036356890849287, 0.2614476366037361, 0.391696405211911, 0.21211388170293027, 0.18064633073082048, 0.18807540436062367, 0.14357748286723437, 0.24124254455566896, 0.07380664008452266, 0.20160513642263297, 0.2625294417424274, 0.21179764456947603, 0.37905199499894093, 0.299905585028839, 0.23240398612610919, 0.30529888277065204, 0.17767291152091239, 0.2909503245460676, 0.3048129573369175, 0.09233904933730554, 0.08102299895632857, 0.2277461305340531, 0.1651768364855506, 0.0889400667884243, 0.17378953622923216, 0.3255423192677011, 0.5202572756107444, 0.11973883386011387, 0.09032382548194508, 0.27014809011549307, 0.23810924793010663, 0.1300838290524462, 0.5202572756107444, 0.11991301073290815, 0.1110479983465211, 0.10518696054659459, 0.5019355205051724, 0.14436448633487164, 0.35189598491963964, 0.1708998924404008, 0.3210541886569467, 0.10854732228026226, 0.35639386501677545, 0.0887008990649041, 0.20784925075354457, 0.1900495388485379, 0.11546771842952858, 0.19529059839662263, 0.2355725749585354, 0.13476707664956628, 0.1130999974752174, 0.10213652456505781, 0.22538489547386303, 0.14594380668061294, 0.17030520949944156, 0.19053206542940915, 0.1421056066403605, 0.5461101581248391, 0.34203096565638136, 0.10057923030093112, 0.08474940088588029, 0.34637095374846927, 0.1012689413870581, 0.14438571698708996, 0.10283027921316934, 0.1830080182156828, 0.17099935071360495, 0.2112734170145521, 0.0897381250941342, 0.2603124255780154, 0.14651987252366536, 0.20239200976389135, 0.09463227230389692, 0.15767005800027317, 0.3513840147542218, 0.32384127588190487, 0.10726958810790622, 0.1520718187270363, 0.21579912932861248, 0.20977366848010953, 0.20778971951699143, 0.11232433676064695, 0.123534701672385, 0.4662130911348499, 0.23585986199163161, 0.14029053187240667, 0.07717535468195927, 0.28121671029753703, 0.2627915465245006, 0.33458662861487865, 0.10319493255839021, 0.10803303148598772, 0.1635122590915055, 0.0962399229270879, 0.0762801181796223, 0.1456923623969988, 0.11063731953176055, 0.3281200183785999, 0.5785852543034328, 0.20448747100489345, 0.12927631790200542, 0.3780622608704243, 0.13942886309256053, 0.3838510872180214, 0.2713157238492154, 0.08755771905156065, 0.14259282668181017, 0.14711676412968383, 0.0865160668378064, 0.14615954281466031, 0.25040883009324955, 0.08492904416875063, 0.15230159109637637, 0.11575893072484796, 0.29690663531610695, 0.1700615738971361, 0.20381764287993015, 0.13952264133904238, 0.08447222283232918, 0.153494183692278, 0.4136691882607381, 0.11358717849203101, 0.3218335010982691, 0.19543623990889566, 0.37347456893584063, 0.2703105140677417, 0.2047325615757508, 0.11772649826973071, 0.20525554671885782, 0.34408179034980046, 0.25225870755321983, 0.16450526472799498, 0.3259298494583881, 0.4325896098585712, 0.06919096153913327, 0.3374564973062245, 0.2123708376633733, 0.17065533133468708, 0.13623463222920568, 0.12069277766777001, 0.1212626924700918, 0.08375367336515853, 0.13569982330920796, 0.20943699187050085, 0.17740994093687285, 0.20726716902304418, 0.462051370921907, 0.2812178343984208, 0.09114239325692539, 0.23270094918678233, 0.08695187973316179, 0.23517648638686556, 0.1426789788127754, 0.4662130911348499, 0.29852495887428554, 0.17497925605188577, 0.2122160435741973, 0.088740213579736, 0.2103520569792675, 0.15153353167184408, 0.08222993556396548, 0.17471246183810205, 0.4136691882607381, 0.21351161066474408, 0.4296989907923629, 0.14036712835694687, 0.08957652438285221, 0.12992046187002018, 0.33595482760459044, 0.08098982689482136, 0.20123979550337506, 0.12296323623004288, 0.5453758527794639, 0.10730097790511098, 0.10486729965041834, 0.10013005046527663, 0.5785852543034328, 0.5709913227556516, 0.11349959651564065, 0.11107294872841848, 0.4733739277247498, 0.07844025485227914, 0.5258463159164031, 0.15779319371325054, 0.1110479983465211, 0.10625723237670825, 0.09220139480808323, 0.38247160667022334, 0.1144642496441863, 0.10577187753011327, 0.1248289216670779, 0.22362221326129553, 0.16481175491539796, 0.2810080945154176, 0.4087481360947289, 0.08843415766025661, 0.07607367068720225, 0.06798863272411385, 0.22228786531682942, 0.27948762737720934, 0.11082192871546939, 0.09310903985001613, 0.12032562518466626, 0.17228006467818163, 0.13772733061120382, 0.09188473128957045, 0.2319995060412898, 0.11641529628057833, 0.13520662033124795, 0.09331612723603724, 0.10537993155967955, 0.2838874074736874, 0.15015956951079806, 0.08524416481669916, 0.08375367336515853, 0.3201921633133745, 0.28352570513128117, 0.2909503245460676, 0.07916065087889397, 0.11708540682225639, 0.16019618193520305, 0.08287282234708616, 0.3908864973987853, 0.5135945481201033, 0.12369653031102305, 0.21476325826008472, 0.13988804492584128, 0.1653594630929322, 0.0787352099325862, 0.20181376057396763, 0.15472495111310972, 0.11042787469777053, 0.3982975171148465, 0.33560655168022496, 0.12856058971347153, 0.09017323864954961, 0.12229298095633671, 0.08447222283232918, 0.5530682996709185, 0.16095671809024042, 0.1600635317387226, 0.1218473439624332, 0.280877049173333, 0.4056171815001533, 0.16715246802337552, 0.1251312120231867, 0.1254513392087595, 0.2752331210589524, 0.09857331697360223, 0.21304236206011382, 0.19268469196780044, 0.1305852949277368, 0.08260579146490551, 0.2475301151563803, 0.32201195862172854, 0.11748533676821823, 0.4162685552082604, 0.1214051396725431, 0.14710135255336892, 0.2911663324568697, 0.1023128069612279, 0.27860187292425626, 0.1326851905017583, 0.20214544630683345, 0.3670465362250004, 0.1251312120231867, 0.26476456759645084, 0.11656701569502455, 0.15648799583916514, 0.190441665581111, 0.17996675387709452, 0.3099606208324628, 0.1110479983465211, 0.315637359753456, 0.27431118010924654, 0.2587827181787773, 0.08310847081559111, 0.21247154159079312, 0.34636410386301764, 0.2657880623642168, 0.23368546974147092, 0.1878271935046411, 0.08797998232586979, 0.1692096824406171, 0.23334483644680262, 0.11763864730447791, 0.2294777243572, 0.34682334625937766, 0.2120340147006621, 0.1194210091655727, 0.35335174226946564, 0.28824899394377906, 0.1110479983465211, 0.08879928413173603, 0.11082192871546939, 0.1916715823303984, 0.18945085958732952, 0.19059817642400484, 0.1945932291356633, 0.12037279987311458, 0.2230261524201219, 0.08492904416875063, 0.22434954271331847, 0.16169372181467678, 0.14283615551921144, 0.2999327991615462, 0.14293630882585426, 0.2705702918776627, 0.16091449046519304, 0.13272465154896373, 0.3139376716768238, 0.6044248284870323, 0.47420533407055193, 0.1344163481022361, 0.20720311355497106, 0.2122608015005193, 0.5453758527794639, 0.13453115845273267, 0.16290908549397143, 0.12006093506864346, 0.18637476166821382, 0.39271754759030636, 0.3017114893305141, 0.17898074411907258, 0.2594775389358579, 0.30928455362420876, 0.08879928413173603, 0.1302934978668223, 0.10931345737109079, 0.19912154066831533, 0.1697626446659388, 0.2386625671469741, 0.11332123849485636, 0.4426717129797487, 0.1676656496329701, 0.09182319951971298, 0.14337252937857942, 0.27260974130940757, 0.19224346589380728, 0.2114248517887336, 0.08492904416875063, 0.2927794307375385, 0.1777326710301481, 0.2454810436899134, 0.43192456158096754, 0.37303434735165814, 0.22314791736503115, 0.19786821537023117, 0.11352722562176058, 0.15064375087891677, 0.1703676044424653, 0.19419962981477157, 0.1277228251580807, 0.10331974854584522, 0.22794101928840094, 0.26203068345717667, 0.26407563826000635, 0.1626222391455011, 0.11664028479762778, 0.317002412692679, 0.3982975171148465, 0.13693834573506078, 0.21006507649942252, 0.2816547318960911, 0.09156080451863963, 0.2258142799604208, 0.21915481416288016, 0.1800607999104063, 0.08361639887463798, 0.18107687190073446, 0.15581556246800377, 0.08341582676654241, 0.07846599815340666, 0.11768800189125306, 0.16299266462326664, 0.22844270669733574, 0.10803303148598772, 0.3646855560265846, 0.18412026997055236, 0.11701102201373434, 0.14076120443145246, 0.2062672922459194, 0.5455714257313076, 0.22228786531682942, 0.3709982814716248, 0.11211136211458186, 0.27014809011549307, 0.2143149150964792, 0.07933079096668633, 0.23993021582529028, 0.09913941616522237, 0.23993021582529028, 0.24855808427940082, 0.14796715724807458, 0.12306165628097296, 0.10886105534700137, 0.31629532665656446, 0.4189096298024993, 0.36649585668941675, 0.3023289881368179, 0.1903873258378245, 0.12299221519667597, 0.12433922192972545, 0.10584571234842942, 0.23282407533268706, 0.08474940088588029, 0.21235196874991688, 0.06957625948206139, 0.5211559433460067, 0.21751967143301368, 0.1867288754183162, 0.3920552338500101, 0.14106882069857854, 0.35576990656496926, 0.09914662127646409, 0.18819865151940526, 0.2519255014013719, 0.27911326641009393, 0.30185503695909577, 0.2790306587614985, 0.2292240238825523, 0.149161247858492, 0.154425410975859, 0.14208954444439997, 0.0861141078729737, 0.22116365112771422, 0.24804926762387505, 0.20576573082742775, 0.23364481201113216, 0.0970708548609999, 0.09460424951340281, 0.4126380635253935, 0.22092500322454658, 0.11966225969026696, 0.16284392401489373, 0.16775473168785482, 0.1184845515882054, 0.29466329145542836, 0.1556068036641836, 0.14224122367690095, 0.18301099136063448, 0.14283615551921144, 0.27228588529232745, 0.10378026237478039, 0.08479175535569151, 0.11654230515963301, 0.2797592279060234, 0.1261687902788, 0.13316539526795354, 0.46477066162948516, 0.34256536197567555, 0.30363054562216724, 0.07500905177007036, 0.08330090882957153, 0.18246540425912408, 0.15302534836540024, 0.3055190259528481, 0.06436809835094144, 0.3101576916889069, 0.2839317049738393, 0.1163756866674832, 0.18991533177625491, 0.18123027336331737, 0.5779786544039938, 0.08950097221821265, 0.4517802258582312, 0.25070834991603635, 0.1951688392535981, 0.1472100645647433, 0.08487230835440987, 0.17912584393465694, 0.11163842647650456, 0.12848098176983305, 0.1269415355859304, 0.5102377950669242, 0.22301508849033708, 0.12793628051956404, 0.09795073575137234, 0.1872349213406229, 0.14763496760577813, 0.1553388219915479, 0.08447222283232918, 0.4214031960121529, 0.17829776777422293, 0.12499849604744685, 0.18224952721869328, 0.2944935253578239, 0.17030520949944156, 0.38063421739081876, 0.1701100733361434, 0.1100148195937786, 0.2305434704908996, 0.12124125292460908, 0.33042410690998464, 0.08636363097583809, 0.3807590909572394, 0.11480752928141416, 0.0746299302294698, 0.3738411284794173, 0.238347548260162, 0.1901060305604008, 0.10342863433287376, 0.1900792451187654, 0.267681871312125, 0.10783148260188971, 0.09022675123250959, 0.3108787703441564, 0.09650841401113835, 0.11851381787957685, 0.31413050608487736, 0.19117969610192648, 0.18224952721869328, 0.1541113565665307, 0.11664028479762778, 0.11056994352660848, 0.518326175510073, 0.14585997685565602, 0.34284713568594916, 0.15036754631938395, 0.30252693582920415, 0.0853939412841622, 0.22265569404754232, 0.33049996667264603, 0.09416459813339391, 0.1839741913975152, 0.11562719274118251, 0.21761311936797173, 0.2622476998228925, 0.5104707254901059, 0.4087481360947289, 0.23206797956075986, 0.13795014823648216, 0.23063013365499388, 0.31115167814666805, 0.09676166160647397, 0.26252636595139867, 0.12652218699334242, 0.3407253677046083, 0.2251154861242797, 0.2267987082673256, 0.23161167807262348, 0.3361743524024037, 0.36370266953431757, 0.3139566562239639, 0.1309689323763815, 0.21014725114173227, 0.1731532565682905, 0.10739735369083529, 0.264436845697543, 0.11907574090565691, 0.09640763317589693, 0.22106169101091072, 0.29697498298181324, 0.1803999106010813, 0.11821895131805246, 0.1110479983465211, 0.29885382820253764, 0.11447702504415141, 0.23982437905003107, 0.12884671694364225, 0.1221710953398966, 0.5082739354320726, 0.161942693395582, 0.4994546357306522, 0.4395725327411784, 0.30080694000960284, 0.10138399631763265, 0.0937926010009867, 0.37538517526235166, 0.1690351203247621, 0.11708540682225639, 0.42225177389743235, 0.11312993596678317, 0.24897322539448746, 0.1791443601981357, 0.156739295425941, 0.14387327476256245, 0.354009604853626, 0.27739721663107175, 0.4671902565546951, 0.24885674189966586, 0.2207655894836414, 0.07895239893126106, 0.1196966263364051, 0.10342863433287376, 0.12499849604744685, 0.25275368561253037, 0.3436441932479628, 0.39833017851191005, 0.07820094534930326, 0.12056845296866499, 0.08879928413173603, 0.08449766054911378, 0.1254147101633003, 0.2168001450112898, 0.11922723376746006, 0.20103024659748825, 0.09396926616155032, 0.17782414378635208, 0.10378026237478039, 0.12854210032921218, 0.2292240238825523, 0.20085860660382396, 0.13355217569415748, 0.21974155356517142, 0.1177885094640919, 0.20982388234448307, 0.14746333022473393, 0.24986049966851884, 0.2557982274534558, 0.19265829620556227, 0.32583485551173075, 0.43704196160551506, 0.23358342714971103, 0.18269173491689136, 0.1564118208440254, 0.1689951888325346, 0.16036697448370527, 0.19941429664337973, 0.2648904390925776, 0.23596118733675173, 0.2464396131297012, 0.22843872553519104, 0.14127716739841506, 0.337547398875297, 0.06436809835094144, 0.22844270669733574, 0.28348820918613044, 0.16844633321926633, 0.11434129871395166, 0.2956130711353288, 0.20119236164592663, 0.08449642811281678, 0.0886147396813222, 0.33709610504747106, 0.14951640903439126, 0.2122160435741973, 0.15096926700062646, 0.09152015962841632, 0.1688741198465344, 0.21990946472620646, 0.11306461282763401, 0.14304075423695053, 0.0679740222888025, 0.47396844377319614, 0.1211988373538391, 0.11263226699705528, 0.08115310185576122, 0.5177943602795674, 0.14811454932240475, 0.11827474206940736, 0.22222029206990246, 0.259901736738942, 0.16949434552242695, 0.2122160435741973, 0.13897863566589988, 0.09394363687802014, 0.12716871180207584, 0.1810665537576545, 0.10574993336721587, 0.13873838109650258, 0.12716871180207584, 0.11211449721279135, 0.0919380729355807, 0.25421156548623897, 0.1110479983465211, 0.264436845697543, 0.22844270669733574, 0.5793349199146001, 0.09623273078845085, 0.2887644644058178, 0.14597541850569662, 0.29186270787897856, 0.12105461553381149, 0.23548783264209278, 0.0886147396813222, 0.2753927441214768, 0.09888715188594177, 0.12189518468191668, 0.1206879309792524, 0.16092291749647647, 0.2119528187237584, 0.09417806657172587, 0.15528331865478198, 0.06919096153913327, 0.2742757611126857, 0.2960070140469567, 0.2830849163560276, 0.149311104632985, 0.14750574660775553, 0.3939530995810622, 0.13388500231301026, 0.17254106334147884, 0.08492904416875063, 0.5647555592050139, 0.314575374316482, 0.10587375801389295, 0.0807234267388824, 0.08443209052795765, 0.17765655740863182, 0.16642048564667003, 0.19095404245943207, 0.12339510792913358, 0.14710135255336892, 0.0865160668378064, 0.10135723328382716, 0.1831493233504313, 0.1453385920105838, 0.17742823640914046, 0.07102977061778301, 0.11181252847145037, 0.21216065181003851, 0.48176119226610953, 0.518326175510073, 0.27185841979257536, 0.15686946568126975, 0.09377638173098006, 0.11134857143802525, 0.1430336335387362, 0.10416246413011629, 0.26449298895293366, 0.12590396889528147, 0.12890050604371467, 0.19044017962736243, 0.19144387974901075, 0.08492904416875063, 0.14853516776211487, 0.08910979014312635, 0.5632709567485739, 0.17077505921974298, 0.12143338634877227, 0.1138570259422057, 0.09254393762467322, 0.2842701256428784, 0.1421386602232208, 0.12488359431154107, 0.1581559958936468, 0.40278772573170546, 0.2197425288909032, 0.5594578422841958, 0.17162250584156663, 0.39018595203171236, 0.11263196611417203, 0.06737035282184338, 0.1439310319108485, 0.33784290337160644, 0.09527686535282749, 0.46076428470096853, 0.38088815643740237, 0.19129764251768322, 0.16181001721884875, 0.18691672548855803, 0.36501639597791186, 0.10595862849521097, 0.30928455362420876, 0.36303633352212555, 0.08588184935117299, 0.25570940211149434, 0.11907574090565691, 0.10959116115562721, 0.42951981124594296, 0.0774722168833185, 0.09640763317589693, 0.10045581477987517, 0.5600708006274663, 0.1711845555859448, 0.10803303148598772, 0.18807351144272252, 0.21014725114173227, 0.2835850585754114, 0.0838104395786201, 0.36762582592774823, 0.07808757284672455, 0.10387542940988621, 0.1809760560744314, 0.11820230948433848, 0.1392354004837297, 0.09527868540149771, 0.17734483512279395, 0.4452192533857697, 0.3175573368999548, 0.1110479983465211, 0.2920602317096238, 0.091546170061298, 0.09036373298914509, 0.42632087311623645, 0.2501687369151075, 0.166390579323245, 0.23556035246218066, 0.07763903398692143, 0.24636883993201902, 0.2663526781573041, 0.13901280314883357, 0.20110070394164956, 0.1547876613989017, 0.3823405572934259, 0.38247160667022334, 0.1724719678310625, 0.09590640650947534, 0.28875581127425914, 0.13162256171009593, 0.08415029841810412, 0.19888603898647697, 0.16474428095770807, 0.33070471924675715, 0.5350326324585454, 0.5608284023311119, 0.2302018561282866, 0.2909503245460676, 0.21031311193977484, 0.26182437495389443, 0.21582508653304894, 0.16395640356230778, 0.07294247037903287, 0.22612799731713945, 0.22595150489970942, 0.23886534357895917, 0.11434129871395166, 0.39576591204559636, 0.20576573082742775, 0.07721525456151541, 0.5194501605223674, 0.30928455362420876, 0.08476900592421542, 0.2606800086949517, 0.08417431463425859, 0.12273481968469764, 0.14238840889624335, 0.2996941506009557, 0.22956557325101834, 0.08950097221821265, 0.12652218699334242, 0.30689221499498454, 0.09100174769112092, 0.48176119226610953, 0.155899778846668, 0.204591998602859, 0.13208143872276387, 0.2211478625907116, 0.2708347861271673, 0.07474787822854427, 0.11313715255258208, 0.4456070599608027, 0.24289672825725175, 0.2357813711046829, 0.2550889515519177, 0.34104287752798174, 0.1006607592350235, 0.31346482887050303, 0.1896746618635504, 0.4135860314679122, 0.101976115169638, 0.16230935436595537, 0.2063372535773904, 0.1380083520018891, 0.15326994513398054, 0.38230516526138236, 0.1363049375950295, 0.09322733336362529, 0.09806421593747963, 0.09362863489132596, 0.21341723243628197, 0.122881280430002, 0.22701816308043135, 0.11468644919779535, 0.12721186945303464, 0.2547279083696898, 0.08724494140828198, 0.5793349199146001, 0.2015759462884808, 0.11700874773059235, 0.11643885947397382, 0.40267569626299954, 0.15887330202543173, 0.3236731421629337, 0.28398409238718336, 0.14358572897716593, 0.08724494140828198, 0.14911923271980201, 0.17958548029689803, 0.2202898552094129, 0.3748481512548362, 0.08474940088588029, 0.13951219098901094, 0.16422791666599998, 0.21991625699325812, 0.19008704551246483, 0.4448920769879428, 0.11397715644214514, 0.13003769851157448, 0.22680353484930668, 0.21560973566231784, 0.14301792529939858, 0.2880032982116318, 0.07442780116151254, 0.15153353167184408, 0.1600635317387226, 0.1110479983465211, 0.5455714257313076, 0.5719376312428094, 0.34723945987327814, 0.07674036264625193, 0.14310215475366642, 0.17438220967341864, 0.5350326324585454, 0.2294777243572, 0.24452173899212143, 0.586233764739287, 0.08850058757029101, 0.11659251649813472, 0.19479218916954916, 0.5177273258733287, 0.33566357904648086, 0.30767710838807444, 0.15438108360009845, 0.1456338092233745, 0.1898211501363648, 0.36303633352212555, 0.1403981855971947, 0.37355275309280894, 0.08977500768282523, 0.19653912229389167, 0.18821839731104129, 0.23816607363786738, 0.12500363386107655, 0.18807351144272252, 0.176819344430741, 0.20122677978576714, 0.15488198126825806, 0.22086886429892563, 0.2193666854801024, 0.11403773665174156, 0.21014725114173227, 0.0927471095453464, 0.3364658439609651, 0.26476778700117776, 0.14092269291575651, 0.19287704208835946, 0.24741561040839288, 0.5453758527794639, 0.1782792265998234, 0.11163842647650456, 0.10629955648549966, 0.1670753576719381, 0.08724494140828198, 0.25086828842313846, 0.10460854796450403, 0.1493996745212826, 0.2421977985037309, 0.07595401853317199, 0.3040423938132617, 0.19053206542940915, 0.42513513007394577, 0.3142458011994348, 0.18170302598449592, 0.2305434704908996, 0.0733072241152045, 0.09162727731913455, 0.08457177605310415, 0.3642800597599709, 0.28986799543653213, 0.11071502051804244, 0.10283343361248685, 0.24627690094839064, 0.3491189194642488, 0.2454810436899134, 0.1018102730070977, 0.31763164397761867, 0.11930236960752107, 0.17419042134575055, 0.0937786478994595, 0.24221922487684813, 0.26137683343018114, 0.11824598856240509, 0.12830171865397547, 0.2091413202505625, 0.4693397732978997, 0.3282390855142981, 0.1264843010892787, 0.08443209052795765, 0.14912240500911425, 0.16284392401489373, 0.09864152971133176, 0.23796079132855258, 0.42951981124594296, 0.14087008655720362, 0.28716988493999607, 0.3398121567465333, 0.2607540184763342, 0.22250295423623095, 0.08630527046604099, 0.331038361722049, 0.17404768648026317, 0.08734420864230903, 0.08146841817146537, 0.18293535099180092, 0.2242961421454654, 0.23660663050715294, 0.2763112474083947, 0.3406401291001445, 0.08474940088588029, 0.5002234751945368, 0.21776237151959457, 0.09162727731913455, 0.2417890606871433, 0.25755786636255096, 0.21359654859581642, 0.11797326402932365, 0.12401540773138761, 0.1573214673273799, 0.12181726066038152, 0.3384013549586766, 0.1385072546505485, 0.11708540682225639, 0.3366518930121008, 0.21401623342487003, 0.1392764967609455, 0.3377844933921341, 0.14216382020803106, 0.1890720513647805, 0.08968693284317203, 0.12565080731450795, 0.23548783264209278, 0.09480211387929652, 0.08492904416875063, 0.34666884707360385, 0.3139566562239639, 0.08457177605310415, 0.14438571698708996, 0.1386720795658014, 0.10633703012796027, 0.11968576438104042, 0.18581866799251873, 0.18693794923379206, 0.25578840548215626, 0.09047332959384936, 0.18833710404928886, 0.237718132826433, 0.35443526965843636, 0.18607566345375529, 0.1284476513544512, 0.23605856180262594, 0.4614331689002311, 0.2455915937517425, 0.16968912304795938, 0.14255574984863717, 0.09673924948889853, 0.21237128680545106, 0.18830630301811294, 0.16850588577162898, 0.28343753598890353, 0.3654772120008179, 0.10591729884738305, 0.3530054314190656, 0.2176987566041647, 0.16082881449903497, 0.11211136211458186, 0.1642278480141779, 0.11659251649813472, 0.4056171815001533, 0.1110479983465211, 0.09903905664888876, 0.5015462661565061, 0.10860156011088724, 0.40015199963196935, 0.26769695704036583, 0.24541208578473006, 0.45814681067770247, 0.3693640360009616, 0.26203068345717667, 0.2838033567240365, 0.586233764739287, 0.22956557325101834, 0.11005466841547633, 0.14279014758932, 0.12339510792913358, 0.37964448825639296, 0.06919096153913327, 0.11265321012623435, 0.586233764739287, 0.24561127544261258, 0.2514120575642206, 0.126048750101534, 0.1240652623874751, 0.2416310316476251, 0.2025623707755632, 0.24643142422864403, 0.2850135541584918, 0.21141524953203217, 0.21247154159079312, 0.25034246424053036, 0.14641903520322083, 0.10849733444437083, 0.2357445064154825, 0.28247130670103343, 0.2242812346889071, 0.17867771862949877, 0.12299221519667597, 0.08474940088588029, 0.23718078524723304, 0.2913339444323644, 0.24015048280912338, 0.27342157686985247, 0.167434460851244, 0.096259799890555, 0.17931781367216845, 0.4026763723417732, 0.10522945861892884, 0.46631382011890876, 0.18202371724979372, 0.12824690285261556, 0.15637421986311317, 0.09374724887511249, 0.10448802577697575, 0.08965055967498811, 0.1400450320267826, 0.17363168794604342, 0.11362411666739777, 0.20107496060597116, 0.20966727947634778, 0.207927738591918, 0.11782431467073187, 0.10891523605414276, 0.24061821495522098, 0.32423805219857227, 0.12070817228754809, 0.2604044499429287, 0.1957969090997504, 0.14980830252247637, 0.17069182546577602, 0.1848752346188474, 0.15113951377416024, 0.28200398372545527, 0.4583611994987346, 0.187696738541973, 0.06436809835094144, 0.26203068345717667, 0.27760725859116614, 0.1698292593345997, 0.34284713568594916, 0.31011463656202054, 0.18807351144272252, 0.15256481997496862, 0.5019355205051724, 0.25621150300809176, 0.20024262299589057, 0.34756065129634334, 0.09543462488161185, 0.2713108052647871, 0.11560624765316738, 0.15703141090854827, 0.08115310185576122, 0.2250193566559304, 0.4301436323856844, 0.3648953689138061, 0.2889854065910469, 0.3738411284794173, 0.2981826548494488, 0.32499727424919456, 0.07437395640556242, 0.1973461269844305, 0.1023128069612279, 0.11480752928141416, 0.12389231042249758, 0.13447983467552338, 0.4889806490205583, 0.16199417979049602, 0.23920294416066082, 0.32078615955276996, 0.12310940374394926, 0.20448747100489345, 0.2221037114881411, 0.15324653042321776, 0.1110479983465211, 0.327557662841999, 0.11418720747299235, 0.09530949939046043, 0.19285864031295974, 0.23639388485405677, 0.12651861485164417, 0.09768031404160378, 0.4184351144642214, 0.21304236206011382, 0.15186750977666896, 0.29575670759772504, 0.12067178682233144, 0.0759126477313717, 0.11151816897364919, 0.18825390373852538, 0.11211136211458186, 0.09551055338348481, 0.17523226920460427, 0.27437943633060524, 0.0971347471394804, 0.18817279324491445, 0.5337160894057508, 0.21990946472620646, 0.17717396892517112, 0.3880928582798946, 0.21194451490494184, 0.24129319971479857, 0.21605320317434645, 0.23307675055942412, 0.11665850750572958, 0.19980745007843828, 0.17635578145039896, 0.18263524883773527, 0.3882970853467324, 0.1012022470906955, 0.11882385539350951, 0.10721195000557582, 0.1603393684259229, 0.1327034682968503, 0.08399137631740525, 0.5343350523503251, 0.17740994093687285, 0.22261328500228336, 0.5091159433734349, 0.5202572756107444, 0.17408017611974355, 0.43086175838781776, 0.17041047716435476, 0.1196966263364051, 0.28033619387202097, 0.2739367381411687, 0.29206723266113443, 0.23893812544561183, 0.11705410843769609, 0.5608284023311119, 0.33844409460537755, 0.15475931767709725, 0.22927452245395752, 0.24924098819135612, 0.3660677048770736, 0.18430156622325358, 0.2722663708416719, 0.1898211501363648, 0.17438220967341864, 0.07123707736240274, 0.11198509368166992, 0.09509921827602835, 0.2594676016274259, 0.40617392488984666, 0.10619652167762458, 0.22707230511075294, 0.1535925473557862, 0.23056920865501151, 0.13358159896687438, 0.08102299895632857, 0.1982178371913232, 0.4644284643024115, 0.2062248209606063, 0.1302934978668223, 0.0848989416079669, 0.24182742248040637, 0.1821345395957634, 0.27527340384810306, 0.09624202386499392, 0.5608284023311119, 0.2557182058019122, 0.06919096153913327, 0.13260552402777426, 0.12650478556104533, 0.14255574984863717, 0.16178317618253446, 0.2678732749576995, 0.22595150489970942, 0.08067996136832535, 0.155899778846668, 0.38568103567151973, 0.17053059805320894, 0.10989986467900784, 0.19764250715926024, 0.16110835736573398, 0.12344359184304757, 0.26114991096416185, 0.1110479983465211, 0.12183822112221503, 0.13807596761492902, 0.1212626924700918, 0.1391399411219285, 0.11384874675144573, 0.31450516725077005, 0.08449766054911378, 0.14811454932240475, 0.06436809835094144, 0.07004765572857534, 0.3541950361701777, 0.1860577974565687, 0.09167280949339592, 0.11232787028055023, 0.1810755847313846, 0.23465997650978337, 0.18549451346400456, 0.11921485425014021, 0.14613700533376703, 0.12082746149810429, 0.15078155624390815, 0.3184914486201035, 0.18430156622325358, 0.27431118010924654, 0.14671970712292884, 0.15109196262527705, 0.09148389429537647, 0.29147571849492915, 0.17526408157942808, 0.17558913031226167, 0.2909503245460676, 0.1167900054075033, 0.16530427203005202, 0.09224394612094032, 0.20359385332451688, 0.1251312120231867, 0.44237259114365707, 0.4264457293796243, 0.08990560201487771, 0.13099465323545592, 0.12254114407278915, 0.1369557109079324, 0.18008636350105833, 0.2665683685821831, 0.16777147428224307, 0.28055819154165074, 0.48446825390349435, 0.47598085694225617, 0.39271754759030636, 0.2981826548494488, 0.1033364866357792, 0.13795975738927907, 0.11080414731699403, 0.12166163440158415, 0.24084935085739284, 0.11966225969026696, 0.1077703904382551, 0.10971019359840475, 0.14878679871861553, 0.3407253677046083, 0.11110012970546686, 0.15022160393061534, 0.13551383261527966, 0.149161247858492, 0.1435768547112748, 0.08930276279768806, 0.08443209052795765, 0.08755771905156065, 0.1457671355703116, 0.15897473849192753, 0.07123707736240274, 0.21327605401339833, 0.12889677039638386, 0.3497224584316405, 0.28982505982820556, 0.06436809835094144, 0.2332835064063277, 0.32157701008045547, 0.15389011388907892, 0.1768149025081476, 0.11936550700594713, 0.08287282234708616, 0.17069182546577602, 0.08845930083780103, 0.375859661278824, 0.07609851466120743, 0.22362210441866043, 0.19867582608894874, 0.11119109407586242, 0.0658712919932315, 0.10753384222747775, 0.27646329503067746, 0.2863423992447277, 0.12464344418208015, 0.2992304482015485, 0.22042861989688747, 0.47598085694225617, 0.2177353348700559, 0.28541344987596584, 0.09623273078845085, 0.27760725859116614, 0.25664847287265813, 0.36116782161839706, 0.3036822818256913, 0.17834997523964802, 0.13895704253364702, 0.10199723425542973, 0.10629955648549966, 0.09576086065638804, 0.43213547059983387, 0.0897381250941342, 0.10552147488206805, 0.07567561362616397, 0.2017809500938818, 0.2437326648411814, 0.10314515126985742, 0.5893831353584723, 0.1198189901737285, 0.270406281120563, 0.15069031898691831, 0.12409248158842183, 0.1889498112972157, 0.10803303148598772, 0.10860515263215671, 0.19053206542940915, 0.08831912084053757, 0.2122160435741973, 0.24475005886402423, 0.17386909577059162, 0.12320110402022676, 0.10460854796450403, 0.0852134062158543, 0.11288232416519792, 0.2735846739770662, 0.2753986131160576, 0.2023550525450763, 0.3092248140616011, 0.19308967934461826, 0.33560655168022496, 0.1042124734223867, 0.19795583342378703, 0.10775404691093629, 0.2645223208872251, 0.152861817153827, 0.12536114355405287, 0.13753615677848244, 0.15732612028183032, 0.4991273606482142, 0.22538489547386303, 0.18618386680544882, 0.09640763317589693, 0.1644436140646595, 0.2528733691021848, 0.10129248367263048, 0.17799529302383973, 0.1549487879187953, 0.19053206542940915, 0.1260830784976367, 0.19584801081018152, 0.4408318533230895, 0.37406947198139395, 0.3307806116069009, 0.33623596062303895, 0.36303633352212555, 0.3954795128297354, 0.2909503245460676, 0.13187156750811818, 0.4143101832153147, 0.2994673416290922, 0.23133156371455713, 0.25025303065091375, 0.1680594296196896, 0.4087481360947289, 0.2817811002439849, 0.39050500167660734, 0.2361012778285643, 0.35811883114925597, 0.06745549775951508, 0.20927778432968208, 0.15837643975525256, 0.133247865142662, 0.33651994879648306, 0.4087481360947289, 0.35957715626513115, 0.5006868996080002, 0.1872349213406229, 0.10443220199442635, 0.09134325130781859, 0.17939924581821928, 0.518326175510073, 0.19688065650175782, 0.1604276980532544, 0.47026626634159463, 0.06289128101645691, 0.19456846333459152, 0.09536094250466448, 0.17856496658737203, 0.13979056002627988, 0.25244056479995347, 0.19075154368193334, 0.34658656880794575, 0.2777985620527351, 0.2000247384220498, 0.5709913227556516, 0.34003452179246907, 0.1215866574014048, 0.2942398639046531, 0.17160525848878516, 0.12510041113856493, 0.5600708006274663, 0.4087481360947289, 0.12376874436111186, 0.12515907529184891, 0.5608284023311119, 0.08864243356868068, 0.1110479983465211, 0.3307806116069009, 0.24770571464402216, 0.11575075752838876, 0.47598085694225617, 0.08639188012439279, 0.20965888358692383, 0.15713870284283527, 0.11082192871546939, 0.10768459075597442, 0.10768459075597442, 0.19946038553022988, 0.30989021680589673, 0.37866256892538, 0.23136680155444234, 0.254057638054187, 0.15567789792852277, 0.41444982469812625, 0.3814647224459115, 0.14501489941124446, 0.10730097790511098, 0.07497981480074697, 0.2638922155912748, 0.39271754759030636, 0.19752033352321408, 0.16875963694719484, 0.1357366974368787, 0.08994999672087642, 0.09217077955953609, 0.08699480732359183, 0.10213652456505781, 0.10088322395375944, 0.1648776998571421, 0.20122677978576714, 0.170262276504245, 0.23337347245852444, 0.1370674235088326, 0.2594676016274259, 0.23029929030456636, 0.13419104538848706, 0.1710074406205559, 0.34746093560903996, 0.20099610783025407, 0.5261727060556455, 0.19292789337516025, 0.20181660358227574, 0.23239252922356343, 0.18380094447986575, 0.41444982469812625, 0.1281912678205276, 0.1603393684259229, 0.2860821672278306, 0.19258006368820885, 0.11375766915153306, 0.081813182338373, 0.1425675337337355, 0.23431637542017283, 0.22809753912193542, 0.22676955181712263, 0.17663529342782214, 0.3076625196975126, 0.12753764491462963, 0.262072606492668, 0.12396821912805968, 0.17768795014560626, 0.1516062630885915, 0.15877299621054733, 0.12274858099901746, 0.32851268334357653, 0.25923407936716236, 0.33143141255731046, 0.14010446209828809, 0.11005466841547633, 0.09747027583666232, 0.15059217264702998, 0.2939438639847479, 0.23813815246546916, 0.12092855062912607, 0.101326008663202, 0.10365585714509008, 0.11075648546396301, 0.27364951932795006, 0.16393164976001753, 0.27872522736677724, 0.11973883386011387, 0.23589938123186813, 0.19830927940234494, 0.10251302225565764, 0.235645459749374, 0.11705410843769609, 0.17569960258275663, 0.12225508774559102, 0.13582044402831303, 0.22228786531682942, 0.22301508849033708, 0.165503607507018, 0.2027372491059043, 0.1253771082824258, 0.11080037952705651, 0.11664028479762778, 0.2601383901840606, 0.10993973756607163, 0.42951981124594296, 0.14057340543343322, 0.11562719274118251, 0.2541921717953306, 0.21983297272786084, 0.07633620273908999, 0.14132132213537948, 0.11552451699091676, 0.3182957895481374, 0.13731511437185775, 0.24002861754029142, 0.18843731059171606, 0.15186750977666896, 0.401127199055498, 0.12561566794281398, 0.1135772524782768, 0.13487673520718965, 0.23942639617910652, 0.28033619387202097, 0.1941457057598766, 0.3011839781495423, 0.08686781919643641, 0.06436809835094144, 0.11638459996406657, 0.25059127342134585, 0.10860938793888489, 0.1927825817463156, 0.22301508849033708, 0.47405392678135105, 0.3385336571831506, 0.23245514912845283, 0.2392006109769825, 0.21237827045857616, 0.1898211501363648, 0.19890248274420583, 0.11575893072484796, 0.1251312120231867, 0.5337160894057508, 0.08668446346537756, 0.21834927854925898, 0.42445200672048167, 0.07785002130494548, 0.49557523718038027, 0.17955556350481677, 0.10126673695385296, 0.5194501605223674, 0.1622720797803718, 0.13431932171348654, 0.11808678459555769, 0.15458135169063572, 0.12949928332918959, 0.331470348472471, 0.14811214122079647, 0.20169599914075265, 0.11454301022317519, 0.2436128828855309, 0.07633620273908999, 0.20751574898783268, 0.1719140882682313, 0.0865160668378064, 0.4420399031822346, 0.11119109407586242, 0.13901002103443202, 0.18565583668235663, 0.19881014042268275, 0.12299221519667597, 0.21801684134556615, 0.09764948702465479, 0.11626978213426319, 0.12775917081421384, 0.08524416481669916, 0.21745944710891735, 0.20521544077651172, 0.11993661701155528, 0.11883727375847264, 0.17790303076933825, 0.2720457017824879, 0.19937369702812874, 0.343810303444052, 0.1328478752968565, 0.0767911449735554, 0.2081827563751843, 0.10577187753011327, 0.4039447063442276, 0.08638015411471038, 0.1110479983465211, 0.19072691999480215, 0.5378577652980179, 0.21340353308248633, 0.10721195000557582, 0.13558920886903805, 0.2359419528724919, 0.17871273238455843, 0.08154568852379415, 0.2610026176576049, 0.23556035246218066, 0.3568569252343599, 0.09838935884678071, 0.10210721479240403, 0.21007880462123016, 0.2270946622403886, 0.09509921827602835, 0.24901553004492136, 0.1413281769178485, 0.19122098526591463, 0.4060709503896788, 0.11434129871395166, 0.22345209285708328, 0.13439720310901537, 0.1282711074116423, 0.12299221519667597, 0.0886147396813222, 0.10450445578788377, 0.15915226473822341, 0.4448920769879428, 0.10895848981974013, 0.11352722562176058, 0.17408017611974355, 0.15975560970675734, 0.19459401363931447, 0.4229935086104768, 0.3237384677260814, 0.20202277354959797, 0.1581741106221851, 0.12606054072620124, 0.36183614880300813, 0.14254193831664141, 0.1673312695192754, 0.14435613594340724, 0.1110479983465211, 0.25302835343588925, 0.13733876283509894, 0.1224578780598264, 0.4991273606482142, 0.06436809835094144, 0.28499751232897397, 0.117788357088503, 0.5453758527794639, 0.27160635081940854, 0.23774048915685284, 0.17438220967341864, 0.22799731563556616, 0.21204364342415893, 0.1438102372816476, 0.12299221519667597, 0.26203068345717667, 0.13901002103443202, 0.4507595927484574, 0.13985918722123591, 0.12067178682233144, 0.1821783206860061, 0.07889856726308148, 0.21881498751942707, 0.06919096153913327, 0.3971967434761847, 0.4942275650755074, 0.3026272730683715, 0.41444982469812625, 0.1699952120929378, 0.1810755847313846, 0.19021712298379578, 0.07846504276521597, 0.2155251767832185, 0.19759444275226262, 0.22704771589009234, 0.10029811885397433, 0.10362856355217162, 0.18705444828287843, 0.11821198248570484, 0.1498477145160126, 0.10992734800657677, 0.11082192871546939, 0.17242507424606465, 0.17996675387709452, 0.200052217232288, 0.10602745289110715, 0.2395447225657804, 0.40772934461078647, 0.2259882758126728, 0.14017661909442347, 0.22441091194175444, 0.21465635182263543, 0.10898087945794535, 0.36560592893926513, 0.3485743446463046, 0.28352570513128117, 0.19112230226324337, 0.12931291608351897, 0.22079517890171255, 0.08923957694013733, 0.5600708006274663, 0.19955918817401166, 0.06624088796844094, 0.2906155553602224, 0.113509060422969, 0.3744595010719717, 0.14029053187240667, 0.22209872414064424, 0.1453511297862707, 0.10330790427392678, 0.2084651753586034, 0.47598085694225617, 0.1355928386761903, 0.17672881399041432, 0.2692082477551473, 0.37327338058847903, 0.6044248284870323, 0.2844070165173477, 0.29901211217812906, 0.12913144314873007, 0.23533178465569884, 0.25884998903206385, 0.08581293694051065, 0.11453153670042267, 0.1028621652901208, 0.08755771905156065, 0.08639188012439279, 0.25452034621372377, 0.5179993316238553, 0.14398407783948264, 0.1631345898528473, 0.3697410547843608, 0.24326668165286516, 0.21160644431676337, 0.1229131567331339, 0.13973190262984836, 0.11532824733978346, 0.2734591577070776, 0.20971438910793505, 0.18123165849327263, 0.2777414794683668, 0.27412541964954706, 0.21854270356239275, 0.07069554940761769, 0.12717230498683701, 0.18072226665306598, 0.10803303148598772, 0.07497981480074697, 0.12067178682233144, 0.06436809835094144, 0.09377913277974874, 0.18558630102877655, 0.48762725089006337, 0.08474940088588029, 0.1398956944667339, 0.1956534839504463, 0.1717671908778765, 0.15338926856967844, 0.2413018622522993, 0.1802915913298309, 0.17411173042137446, 0.06737035282184338, 0.17442952334270878, 0.12721186945303464, 0.09863372695075658, 0.1753955018006766, 0.09640763317589693, 0.07506852414171539, 0.19747320544330726, 0.15938484171112313, 0.1524834064896787, 0.23527893714288078, 0.07969229913498088, 0.06651926485567188, 0.2739367381411687, 0.2094622384739335, 0.09362863489132596, 0.11099121728103428, 0.34532992625003983, 0.19856308049330365, 0.2621621991292333, 0.1993481273891781, 0.22226570510966345, 0.1110479983465211, 0.14283615551921144, 0.36738003763197485, 0.2584104934903177, 0.11023944689936137, 0.11643885947397382, 0.22219727670916617, 0.07281473839478113, 0.2809717735687412, 0.3406792943502569, 0.234251882992061, 0.3201821308523251, 0.15804182862740707, 0.07294247037903287, 0.09566801854645199, 0.2629521369193691, 0.2239542870737893, 0.2909503245460676, 0.09470440955224492, 0.09509921827602835, 0.2085036039116477, 0.1228164169754946, 0.20125259165869594, 0.14555474878120409, 0.5719376312428094, 0.2331148779206256, 0.42215944471918815, 0.0882125862697114, 0.27116559529543577, 0.2409488635280713, 0.11575893072484796, 0.17053059805320894, 0.08747067629754635, 0.2265085690621826, 0.2792049064479697, 0.14555474878120409, 0.15846867245971558, 0.34353729689039497, 0.18765393417186746, 0.17661448566321533, 0.1909510943451572, 0.1489343361258454, 0.1779799349887539, 0.08238227438616699, 0.13733876283509894, 0.07305821578547267, 0.2287147421352877, 0.09310903985001613, 0.4207748956879074, 0.42732834247854634, 0.1877136947795289, 0.11382712194180174, 0.11211136211458186, 0.17406166363780734, 0.11708540682225639, 0.0807234267388824, 0.286356128219928, 0.18453006748374262, 0.1612366239132032, 0.309369872898272, 0.11724789059361312, 0.1913188980350963, 0.1547144740751309, 0.5446300298309754, 0.5446300298309754, 0.2909503245460676, 0.09167280949339592, 0.11494544810069243, 0.297479006866103, 0.13238334342999217, 0.1579151873883233, 0.3742411868964013, 0.27221795449428665, 0.17155652430192508, 0.1329103918513246, 0.15788175696198214, 0.09308816298264837, 0.15284583691781098, 0.13856352103648029, 0.13338303284420586, 0.4951276747203492, 0.15913393289212566, 0.08970661535047672, 0.3579286553822469, 0.1703676044424653, 0.08340089900270178, 0.1672744443073906, 0.1110479983465211, 0.09114239325692539, 0.11708540682225639, 0.10307213161691998, 0.07771213875070945, 0.12989913432806668, 0.08411421369394752, 0.10330790427392678, 0.23941416850902514, 0.08055959758049443, 0.17829776777422293, 0.14597541850569662, 0.5709913227556516, 0.3142458011994348, 0.1929367259177212, 0.2640194580559678, 0.3416394897584436, 0.18081369329109667, 0.10870934474401682, 0.11349959651564065, 0.1120658586919799, 0.10497141375658979, 0.4566758040592171, 0.5177943602795674, 0.21344585091842935, 0.19688065650175782, 0.17744671818260607, 0.5453758527794639, 0.08492904416875063, 0.2985267472034313, 0.11654230515963301, 0.28400141820367913, 0.413706733524387, 0.37232661142478357, 0.41757866566417273, 0.34008726215596335, 0.08816937913114446, 0.2956130711353288, 0.39704149081995277, 0.42951981124594296, 0.1469655405913107, 0.1279834012085956, 0.16566082805393517, 0.10982085558036087, 0.155196521402618, 0.17242507424606465, 0.3034350694401779, 0.3065053480700645, 0.16453489907578478, 0.3411791688072738, 0.14255574984863717, 0.20918112439686937, 0.0765452902940216, 0.19183164397987307, 0.1746709380161899, 0.3416394897584436, 0.46428955154782187, 0.4052676125883527, 0.18073593869760976, 0.18801119015561293, 0.12032562518466626, 0.22219945492132337, 0.16996091250618944, 0.11824598856240509, 0.08447222283232918, 0.08933121156474673, 0.16208186890854961, 0.25635994545956203, 0.10336588832936766, 0.13832776937292987, 0.11775769291272592, 0.1680594296196896, 0.11928840184061483, 0.29397946086776333, 0.2037512173030755, 0.07978825803657201, 0.4436357911255053, 0.20632843406816231, 0.16940771957294468, 0.4098913141213904, 0.09416459813339391, 0.2913369031984773, 0.09509921827602835, 0.11606308613699275, 0.11708540682225639, 0.18198061297110377, 0.4566758040592171, 0.23020305804074992, 0.25650028545741366, 0.2806826598710494, 0.08312604413913463, 0.21272344527241627, 0.12067178682233144, 0.23996251428612997, 0.16284392401489373, 0.3330022205016254, 0.16451721034045688, 0.21622375196400484, 0.13436759500647324, 0.39018595203171236, 0.20443911673844833, 0.196717746738975, 0.08730724492396148, 0.09778418080359982, 0.09380951551351716, 0.09781721627687417, 0.25884998903206385, 0.08695303205216087, 0.13225658558371103, 0.07500905177007036, 0.12186785798018196, 0.41444982469812625, 0.30073939737918987, 0.09114239325692539, 0.18293535099180092, 0.25275368561253037, 0.3908864973987853, 0.306298883258802, 0.1699952120929378, 0.4031996869968199, 0.2874579620055342, 0.3908864973987853, 0.16271673536711487, 0.3491189194642488, 0.12427951695675944, 0.25349060492270603, 0.07633620273908999, 0.28600432364799305, 0.24332139517709567, 0.12083190507410084, 0.48762725089006337, 0.08957652438285221, 0.22400868672982885, 0.08928460498922731, 0.1006607592350235, 0.19038370236454408, 0.11572384078101175, 0.3491189194642488, 0.0830991595252151, 0.10378026237478039, 0.19537512964848905, 0.21578222347562784, 0.15529216492964765, 0.1890440306656559, 0.5258819170472417, 0.27228588529232745, 0.265479702643777, 0.14861253580736958, 0.1662543703841923, 0.2853768491121216, 0.12753764491462963, 0.28038052039123296, 0.20321049332957153, 0.11824598856240509, 0.10934011486357754, 0.34039290046398135, 0.08457177605310415, 0.19933722229883974, 0.19537165571355586, 0.20878800204289572, 0.08970661535047672, 0.5202572756107444, 0.21854270356239275, 0.10288593092716325, 0.20563599961279333, 0.13914288368396416, 0.4813453580893035, 0.18123165849327263, 0.43192456158096754, 0.24497530988232863, 0.12320110402022676, 0.21784417716211438, 0.09517249947098434, 0.2113763973874446, 0.3192993879600136, 0.11316977055416522, 0.14339399307650716, 0.31450516725077005, 0.23125351613093362, 0.08678228351491599, 0.10862452896246585, 0.24353253383989168, 0.08307303961834732, 0.113509060422969, 0.23845086717878605, 0.08950097221821265, 0.16477525971965348, 0.29173263880687017, 0.12561566794281398, 0.14006583545087758, 0.15261765295191965, 0.2944733709312905, 0.1601699439630091, 0.12774649544969385, 0.15765358560867093, 0.09377638173098006, 0.15916503051299755, 0.14961288934173128, 0.09279436942068553, 0.08474940088588029, 0.13917596670027765, 0.08100365453553991, 0.15085786587869343, 0.27350570432985477, 0.09895049498415633, 0.1893339069106733, 0.5600708006274663, 0.33011655409414636, 0.23543812832228025, 0.08715352599048524, 0.12166163440158415, 0.12890324136732048, 0.2765263258824375, 0.3491189194642488, 0.3139566562239639, 0.32512770455907297, 0.12464344418208015, 0.28366975573936487, 0.11251937138843725, 0.11580514734018431, 0.334031415071933, 0.06624088796844094, 0.39132920719842623, 0.12660009024463623, 0.08953776692415398, 0.10577187753011327, 0.26992016398517116, 0.20316776829640265, 0.3151847073808403, 0.25733604445154656, 0.12989913432806668, 0.08474940088588029, 0.14381744790890072, 0.30558345146606863, 0.112099523674565, 0.09297451870305531, 0.12149252050363901, 0.06737035282184338, 0.10740908614667045, 0.4201377130030144, 0.11266439917644701, 0.23125351613093362, 0.3848419750635537, 0.1328834193678159, 0.1482299810338086, 0.13388500231301026, 0.23257452787680633, 0.4328872228655452, 0.1740581774827916, 0.17953890819544016, 0.26203068345717667, 0.13109471499146638, 0.11266439917644701, 0.3742967759187577, 0.10409028716337777, 0.14607142347511148, 0.11460666516395224, 0.1852539359724265, 0.0679740222888025, 0.288319340382422, 0.19010352653091578, 0.19092234778460512, 0.10368407908558047, 0.13680011960213442, 0.3185705274658925, 0.16500810135162622, 0.12681260729569066, 0.3262131812159503, 0.47473526026038565, 0.08347776178496338, 0.2916674760505229, 0.5070248557779418, 0.32227530113891156, 0.23278001454321215, 0.3171531311390674, 0.2692688371978274, 0.1392531478948749, 0.1703676044424653, 0.30462708125227406, 0.2955570814264317, 0.1982178371913232, 0.25312920247346143, 0.2938753106698743, 0.11643885947397382, 0.09040485864349783, 0.16648931055198798, 0.07497981480074697, 0.2216886874196593, 0.3533893949400154, 0.11942671721439227, 0.21574721431558797, 0.08483265107352232, 0.2727627908977963, 0.12974836155081093, 0.1977006715763762, 0.09068126374013777, 0.10904309881263125, 0.10967993058719423, 0.08734420864230903, 0.22078046252096428, 0.3548779542962877, 0.21441473511239234, 0.1121270435630679, 0.10846188555290852, 0.08879928413173603, 0.17438220967341864, 0.19294589172865034, 0.07542412313630703, 0.3660677048770736, 0.12873966059389932, 0.40829659787423184, 0.10212517658965829, 0.1572892779177859, 0.0937786478994595, 0.23214104602342234, 0.11103871393043534, 0.2472229977689174, 0.2836646564679097, 0.21233982902675588, 0.20820297401690038, 0.08492904416875063, 0.19323363836389149, 0.20479950123359217, 0.08347776178496338, 0.10898087945794535, 0.13734560183208644, 0.31417021431190817, 0.14154276112476663, 0.0897381250941342, 0.5112033944570482, 0.3906615691151442, 0.14811454932240475, 0.21047635058584982, 0.11082192871546939, 0.21014725114173227, 0.07771213875070945, 0.4903720922076896, 0.11080414731699403, 0.19053206542940915, 0.2292240238825523, 0.17006463380083411, 0.17771383304105476, 0.18090541585233946, 0.09416459813339391, 0.30179782078557127, 0.11211136211458186, 0.2605690440149158, 0.2390204005667322, 0.24109333016520534, 0.14321652203327856, 0.33611647467591693, 0.07820094534930326, 0.12087549196785921, 0.10686777287212978, 0.1110479983465211, 0.31014776562719726, 0.20148417697812263, 0.13817579685031925, 0.0679740222888025, 0.2888971697537349, 0.2258873814100432, 0.1738599766195076, 0.0957181485438207, 0.10518696054659459, 0.16304764275083145, 0.09286262057833256, 0.4006737458444592, 0.17345584895391752, 0.43544052909152775, 0.149580512908153, 0.2842701256428784, 0.06919096153913327, 0.13123380319206251, 0.20447877825481062, 0.3151847073808403, 0.28173037381040356, 0.13445777197054426, 0.07345048213655882, 0.16309797730141792, 0.0807234267388824, 0.14355367616542714, 0.12652218699334242, 0.49442679819207835, 0.5258463159164031, 0.4994546357306522, 0.33752018332423817, 0.24836627368749456, 0.18383977726010242, 0.24654543831063525, 0.113509060422969, 0.44178756343135334, 0.17234627794307353, 0.1110479983465211, 0.09072786255446648, 0.2603590513769276, 0.2790047955928613, 0.4564413869993017, 0.5167855686391446, 0.1446104849936352, 0.3660677048770736, 0.10138399631763265, 0.4031072495281026, 0.17832529591111157, 0.08457177605310415, 0.16178725105081423, 0.11973480325090922, 0.12056845296866499, 0.21857885411816194, 0.16148805388315626, 0.17052385489468141, 0.48595936529707723, 0.1251312120231867, 0.13946050387756667, 0.21500577187424297, 0.5530682996709185, 0.10815195566200352, 0.1559558892221762, 0.08694367036528974, 0.22301508849033708, 0.19257376898882628, 0.1256805619790946, 0.105533369003931, 0.22339260529124583, 0.32851845150233966, 0.20350335583266918, 0.17232578535574397, 0.3135207022206111, 0.21776237151959457, 0.1709146782458623, 0.3775299244411907, 0.1100148195937786, 0.07500905177007036, 0.0980800747616556, 0.23120268067742544, 0.20173443677699487, 0.32334271396959025, 0.42951981124594296, 0.35831652133764774, 0.07846599815340666, 0.08686781919643641, 0.4301436323856844, 0.10458170010777802, 0.12143338634877227, 0.11937546148196403, 0.12913144314873007, 0.1691814895646897, 0.21275769269024064, 0.21173848474562634, 0.2104594275081102, 0.06737035282184338, 0.3053829996151199, 0.33070471924675715, 0.18316169506812882, 0.41487912187255066, 0.3088834622656794, 0.12727171350644337, 0.2769115331536669, 0.16299266462326664, 0.3696227294501459, 0.07004765572857534, 0.09188473128957045, 0.2423870264757848, 0.26457732931747785, 0.3367863440040464, 0.09277570984786379, 0.07927693219279465, 0.07102977061778301, 0.32880256404308217, 0.10753384222747775, 0.24163927069290478, 0.19771973556956288, 0.5194501605223674, 0.1848752346188474, 0.16716695958782654, 0.07916065087889397, 0.15268135076390463, 0.06737035282184338, 0.12499703909774465, 0.2020544407590852, 0.20163622715154486, 0.14273059555685572, 0.11966225969026696, 0.3743869444132617, 0.07933079096668633, 0.12056845296866499, 0.0886147396813222, 0.22994887304510045, 0.16995442457572238, 0.20978618420634815, 0.39432417163326033, 0.2573383868895237, 0.2327776011363563, 0.15877299621054733, 0.09795073575137234, 0.07506852414171539, 0.14001430728411587, 0.11211136211458186, 0.13293547564895358, 0.21007880462123016, 0.0807234267388824, 0.11572384078101175, 0.17186528457266786, 0.31091272446030005, 0.28082958350481535, 0.1107780271790992, 0.12495541443038542, 0.2523274695513728, 0.08642641779405771, 0.17372890173783276, 0.5453758527794639, 0.3742967759187577, 0.07607367068720225, 0.15064375087891677, 0.088740213579736, 0.1810755847313846, 0.26297874273192445, 0.2559733890630384, 0.2838874074736874, 0.1110479983465211, 0.16663948084472893, 0.14370179644820474, 0.5343350523503251, 0.0973202444381734, 0.14689281200201582, 0.11907574090565691, 0.48238147619546523, 0.18852742283688523, 0.44269311383780036, 0.22086915783171712, 0.15575093729769315, 0.24290068088003433, 0.2319531488228111, 0.3433142734830717, 0.1370674235088326, 0.1997399188533577, 0.16939680914271146, 0.13558920886903805, 0.3112319095887141, 0.11552451699091676, 0.13870731031680972, 0.10283067389221472, 0.18958505689677166, 0.06919096153913327, 0.22363344144373887, 0.2475301151563803, 0.10574993336721587, 0.16268019905461137, 0.2999724723201271, 0.12440828401729383, 0.09196868249808503, 0.13619275060729005, 0.13263724094490842, 0.1326851905017583, 0.2938753106698743, 0.14453064160570162, 0.17750209124966893, 0.1804920816138273, 0.1620025950400482, 0.105533369003931, 0.3037433041516288, 0.09997417055695326, 0.18359648735746045, 0.11552451699091676, 0.10629955648549966, 0.18867347805611268, 0.23206804100755127, 0.2835154070789951, 0.27184529947767977, 0.27775644979552666, 0.3729080931632033, 0.5793349199146001, 0.18233325898083053, 0.2816890664929137, 0.3869241786593525, 0.18081816556438654, 0.24319998951455749, 0.35957715626513115, 0.23201562417743443, 0.14003507810655874, 0.18115793195334015, 0.19806459060675843, 0.5470025649510345, 0.18268430626160598, 0.18506141438089108, 0.17757825277909875, 0.10989986467900784, 0.23105411318723934, 0.130240884543251, 0.26482487115480374, 0.10518696054659459, 0.25021377337942124, 0.09147557287047926, 0.10436880659078904, 0.13955852596013432, 0.2268983574503913, 0.11442950136867536, 0.07943204053640203, 0.09351024166445666, 0.12325819081522069, 0.1617348329831674, 0.22149328427602355, 0.2254792042971786, 0.13259355812843662, 0.13007942786956905, 0.10424869279316754, 0.3166295979543754, 0.20984302752330516, 0.5600708006274663, 0.09774839744442412, 0.24222382819671767, 0.10415918181257922, 0.19932914116742653, 0.24578025507716358, 0.5363810225896524, 0.1226433114032091, 0.29158799795650286, 0.34903408661202107, 0.19157326592476592, 0.11562719274118251, 0.11575893072484796, 0.3771457408637164, 0.17717396892517112, 0.08933121156474673, 0.2532069670669084, 0.28170583138970734, 0.1251312120231867, 0.1241303512831606, 0.3828222513623718, 0.3201921633133745, 0.10367776141748053, 0.11774404228999967, 0.07281473839478113, 0.17115516594372918, 0.31945790913120936, 0.5453758527794639, 0.2881012055417823, 0.08449766054911378, 0.08041328690683447, 0.21141360302465334, 0.22285430683082372, 0.20198592446652486, 0.13951219098901094, 0.2635575193882342, 0.16513585494973013, 0.19193284812075273, 0.1403417404573928, 0.4127016626523572, 0.13733876283509894, 0.4296989907923629, 0.18024415067541757, 0.18072772712929333, 0.11572384078101175, 0.10244936476769105, 0.12870603033975953, 0.12992046187002018, 0.10380393547393629, 0.19231154835479272, 0.1420638430433824, 0.26971319140645633, 0.19108947115627953, 0.21441473511239234, 0.06324388200062911, 0.17610633313417953, 0.1392531478948749, 0.2076292493216055, 0.5453758527794639, 0.14857655710348447, 0.2453059099893494, 0.3184914486201035, 0.18588788575456025, 0.19036157406402107, 0.09857331697360223, 0.11643885947397382, 0.11708540682225639, 0.27007095978281775, 0.3736199923022465, 0.2114349674436941, 0.2651654798974266, 0.1509866239416657, 0.20762683067648993, 0.3810481850865667, 0.21868983527520353, 0.4028299140069433, 0.4592279931855969, 0.14837778849215355, 0.30545826017189964, 0.15620165053226215, 0.22840334831367443, 0.3307806116069009, 0.5179993316238553, 0.18368739447264118, 0.16633369217919058, 0.09468669340115247, 0.15738550945801233, 0.3632801963666877, 0.21215873003985122, 0.18508418750720385, 0.22071909862479136, 0.18503340155948497, 0.09147557287047926, 0.1389374781156082, 0.14225677108542498, 0.11434129871395166, 0.2889676101553981, 0.3031233245546803, 0.3906615691151442, 0.22257433156459436, 0.10910823286560051, 0.1110479983465211, 0.14294228001539686, 0.19671433027879437, 0.10961873224759404, 0.4404872770928658, 0.16121196232362914, 0.07054662080001685, 0.22506732303278462, 0.08881541760207318, 0.11710682376035411, 0.0948288522255862, 0.09893489169468134, 0.1498477145160126, 0.1632688689637999, 0.24878394250871375, 0.2142701985527653, 0.20891941500365951, 0.24091913148968414, 0.14362789502931972, 0.25064630875494065, 0.2003954420908138, 0.28869041007250645, 0.11109257042831673, 0.30281797101360985, 0.12107544357080555, 0.2651730846500287, 0.12274518722626147, 0.09121367515214959, 0.28007084468695337, 0.2435239419551956, 0.0973503683627905, 0.09121367515214959, 0.1768149025081476, 0.08102299895632857, 0.14117735276575602, 0.09114239325692539, 0.24392845572998384, 0.11572384078101175, 0.15458135169063572, 0.07916913565827069, 0.20169599914075265, 0.16251888633043018, 0.36367913323319645, 0.3462007602327878, 0.14597541850569662, 0.1469089543964059, 0.11819422249001009, 0.2098305093063238, 0.19000859730726535, 0.10985519539319026, 0.28821853039840784, 0.1221710953398966, 0.3343485042633427, 0.22733719824414828, 0.17951297825261048, 0.07837874118999875, 0.13733876283509894, 0.39823317673278935, 0.2428895460015231, 0.3383258044239145, 0.3707849057417805, 0.13569982330920796, 0.08951785506340874, 0.13696504075691668, 0.17768795014560626, 0.32657308933295875, 0.0782840445330886, 0.21204364342415893, 0.3255423192677011, 0.15538030546646164, 0.09696217688389895, 0.37821404914910783, 0.2722663708416719, 0.11572384078101175, 0.15706568016318806, 0.10518696054659459, 0.14603034304884638, 0.3763865863329385, 0.17583151491380014, 0.1539706785021198, 0.4318404378604836, 0.2790768477348546, 0.3889122549930737, 0.1696088368986973, 0.19120143183366767, 0.17408017611974355, 0.16968912304795938, 0.17789832444947581, 0.47473526026038565, 0.16985295496674546, 0.5785852543034328, 0.28588116684953097, 0.16630099688578864, 0.11572384078101175, 0.08483265107352232, 0.3709778351758527, 0.1469089543964059, 0.10138399631763265, 0.19574292809418992, 0.2657720407316098, 0.24976966012572813, 0.1628890195883394, 0.5015462661565061, 0.24436452359937938, 0.10980314323040034, 0.25262630097263233, 0.34969754854704943, 0.1520718187270363, 0.09317582165705203, 0.37905199499894093, 0.08260579146490551, 0.11211136211458186, 0.08457340840345964, 0.3206665574375419, 0.07721525456151541, 0.2269532510167153, 0.2211295865603101, 0.13558920886903805, 0.07328507023345346, 0.08953776692415398, 0.10591729884738305, 0.24947119016970418, 0.08552536992610356, 0.19224346589380728, 0.14597541850569662, 0.35004342374012, 0.20818735279981115, 0.2295344902838529, 0.08474940088588029, 0.240410641742454, 0.3820272465496888, 0.24097535886719493, 0.17155652430192508, 0.13897863566589988, 0.09416459813339391, 0.17327983490484644, 0.086812282442694, 0.1862549588835631, 0.3649070743414219, 0.13795975738927907, 0.46477066162948516, 0.13827762384008127, 0.4421628386416522, 0.107189531292901, 0.15013948131028293, 0.1285692975031025, 0.3050061593036022, 0.3735902749681048, 0.20448747100489345, 0.13901002103443202, 0.5006328488910127, 0.3654772120008179, 0.42951981124594296, 0.1362235647200956, 0.09266475761122246, 0.14733841847790627, 0.18073593869760976, 0.3807590909572394, 0.22305461067300625, 0.0996095084150572, 0.21867579216375796, 0.16034255314015175, 0.1996460650903912, 0.11082192871546939, 0.1694796144121544, 0.1559558892221762, 0.11768558590079947, 0.31910762108296387, 0.3973707241276884, 0.30403145158079725, 0.09082230486267995, 0.3780622608704243, 0.17443186223783044, 0.22228786531682942, 0.5530682996709185, 0.10283277751182902, 0.11434129871395166, 0.35223329615968874, 0.38064853939345933, 0.4554817226205843, 0.12286565064142503, 0.06624088796844094, 0.19795583342378703, 0.15059217264702998, 0.1292726795100833, 0.14310215475366642, 0.5337160894057508, 0.15121907387797223, 0.24227179506858626, 0.20852425288082796, 0.2035155558315376, 0.07305821578547267, 0.16271673536711487, 0.2687743069229292, 0.09909564500685376, 0.17471246183810205, 0.07808757284672455, 0.07079826141796598, 0.31688902643975264, 0.2989479996640455, 0.21875075035003225, 0.2645223208872251, 0.13305766744193456, 0.2063879269739322, 0.24947119016970418, 0.242513254329448, 0.15051058506041487, 0.10248227958445627, 0.19905353392264724, 0.11739079830359962, 0.18564496970331654, 0.2097975317945242, 0.11995535647209522, 0.23815415319002317, 0.45594848386191306, 0.16284392401489373, 0.10753384222747775, 0.27997617289387816, 0.15809804497261712, 0.15432182690995447, 0.14050143075822963, 0.0792792950936768, 0.2906155553602224, 0.3331558031827007, 0.19017880095628298, 0.47688842044501895, 0.07069554940761769, 0.19886690050782985, 0.10629955648549966, 0.12416763233246199, 0.16309797730141792, 0.06436809835094144, 0.17767291152091239, 0.2325529982277638, 0.1212626924700918, 0.259222625498779, 0.12274747715262523, 0.12721186945303464, 0.35512935385221356, 0.21192632158594443, 0.26743024332971105, 0.3142458011994348, 0.23941416850902514, 0.3324141933486871, 0.22911015615145527, 0.5179993316238553, 0.23572787650831886, 0.24875024636396245, 0.21204364342415893, 0.11684737921782988, 0.3185770532030769, 0.10860938793888489, 0.10135723328382716, 0.09792044620339567, 0.18024415067541757, 0.15434517696170724, 0.10904309881263125, 0.41037359077169333, 0.08511523883270866, 0.2996287562733832, 0.09579995808645413, 0.3469609904235506, 0.11943973196469798, 0.14370179644820474, 0.18453006748374262, 0.11211449721279135, 0.26661472221905247, 0.1149769446588442, 0.2387235598977317, 0.18688584305241246, 0.18863751306129695, 0.46622849558546164, 0.33571555999139535, 0.26203068345717667, 0.43507884732396523, 0.1241303512831606, 0.0931713448773739, 0.18897642382511762, 0.19209116604410287, 0.3277952171345854, 0.13750926502130384, 0.3704306198006918, 0.2334288521434026, 0.14316113707024042, 0.16723407932022394, 0.3250691542023962, 0.5449546790459044, 0.07305821578547267, 0.22888325848650146, 0.12058054829476647, 0.1408904386133117, 0.2911418784844118, 0.22844270669733574, 0.1528887510347888, 0.25410398525226213, 0.586233764739287, 0.24286173215673804, 0.09396598671816664, 0.24910694650527132, 0.06436809835094144, 0.38405720675893157, 0.17682764203811704, 0.1604281947609431, 0.06737035282184338, 0.5453758527794639, 0.25013085037419436, 0.408755740387069, 0.317002412692679, 0.28054169152203523, 0.23785048311034718, 0.23542516055806584, 0.1943169712113821, 0.3139566562239639, 0.22223525942780933, 0.4918294309082034, 0.259222625498779, 0.09576046127945548, 0.11572906351948202, 0.3744595010719717, 0.08446094070424356, 0.10000434050403449, 0.08639188012439279, 0.42699312670612766, 0.13795975738927907, 0.14559739476079955, 0.14050143075822963, 0.16280366091247148, 0.23116491595543123, 0.15482842185711165, 0.12060461562741402, 0.15715449100511314, 0.3552699765963639, 0.3459987105097223, 0.11636057128703284, 0.11028538970783205, 0.34192615971173457, 0.08457177605310415, 0.3194138606362769, 0.09806421593747963, 0.3395960335341993, 0.18807351144272252, 0.3192993879600136, 0.48942959653903795, 0.3574986738835122, 0.08737269215467855, 0.34933607123476346, 0.19949514065553403, 0.1812271400807546, 0.19933722229883974, 0.1110479983465211, 0.5435969417758639, 0.25150132143566023, 0.07608660417116973, 0.2909503245460676, 0.09292337766236829, 0.3142458011994348, 0.10433005145949202, 0.09279436942068553, 0.13733876283509894, 0.2628406878694636, 0.24093317357426128, 0.14127716739841506, 0.17069182546577602, 0.1478409503580262, 0.1110479983465211, 0.23068233767844806, 0.11785927158157894, 0.36303633352212555, 0.15256635281275288, 0.11225089223536293, 0.2105532397443634, 0.3736199923022465, 0.5461101581248391, 0.19660833838536865, 0.21834292767264846, 0.48700523516150046, 0.177550324927527, 0.2324580867361894, 0.1110479983465211, 0.08546117686853173, 0.1344646565418024, 0.36284015418498977, 0.3065717814338632, 0.5202572756107444, 0.2675017975422095, 0.11956698444604133, 0.14029053187240667, 0.2187564069091861, 0.11082192871546939, 0.10754504063773847, 0.27293353577766216, 0.32720252214012296, 0.12316126555723603, 0.15915226473822341, 0.11468644919779535, 0.15059217264702998, 0.4149811790442947, 0.1369557109079324, 0.10025481033936175, 0.27160635081940854, 0.17522009567042024, 0.13897863566589988, 0.18104245653691536, 0.1792333479194887, 0.28547168368162923, 0.2765059208891486, 0.35167379491647693, 0.2021886072402424, 0.09416459813339391, 0.16596854445225817, 0.2416597435659623, 0.16661003178045766, 0.11005466841547633, 0.11082192871546939, 0.3277952171345854, 0.10000434050403449, 0.11893807379469166, 0.1704937809110208, 0.37905199499894093, 0.14796715724807458, 0.09640763317589693, 0.19088546718979887, 0.1575024008159749, 0.2678116508386533, 0.24481823237926884, 0.47473526026038565, 0.12065607515834406, 0.1699952120929378, 0.2046211110189158, 0.3403622658134296, 0.2035155558315376, 0.10891934617871059, 0.11349959651564065, 0.07654757854553353, 0.1110479983465211, 0.08686781919643641, 0.17847759164632815, 0.12728181862968996, 0.17142228634996776, 0.17267671555272093, 0.3768736542452058, 0.13319989793570972, 0.2954659644162057, 0.06919096153913327, 0.49791213789294547, 0.2202646124474838, 0.586233764739287, 0.19485122714800512, 0.25225274988980056, 0.21900807822398477, 0.38711717697279785, 0.10518696054659459, 0.4657602199250315, 0.2401293647255545, 0.146437392840109, 0.14283615551921144, 0.26850042340659136, 0.28215453397044155, 0.20317503792032754, 0.13171228711919208, 0.2131084505004401, 0.24964439654005952, 0.4404816986467107, 0.12023144965040038, 0.2742757611126857, 0.28484958143804606, 0.4513104070497663, 0.11321132324224023, 0.29198769053894424, 0.12573087146329961, 0.20148417697812263, 0.11708540682225639, 0.12652218699334242, 0.2621621991292333, 0.1762876928324445, 0.15334012517201917, 0.2429811549838849, 0.22142033724832394, 0.32668701499262753, 0.4823089038248482, 0.1696625038923331, 0.22068867680651072, 0.12339510792913358, 0.08115152743585756, 0.08957652438285221, 0.32944716682254854, 0.23183712889414212, 0.15703141090854827, 0.3596801501297327, 0.3703970131377695, 0.12097763454135539, 0.1653594630929322, 0.14811454932240475, 0.21716898735602255, 0.37228210953219953, 0.1357366974368787, 0.16119453210613285, 0.16864764059199916, 0.08497337984900115, 0.09806891840237503, 0.1821345395957634, 0.17931781367216845, 0.3654772120008179, 0.14677860897989622, 0.24897322539448746, 0.26854536678881247, 0.21716245454216304, 0.3112319095887141, 0.3130213148294703, 0.2386625671469741, 0.12842986386923064, 0.11468644919779535, 0.1110479983465211, 0.3998880843748329, 0.2863831887075403, 0.07717535468195927, 0.37763443907598254, 0.149580512908153, 0.20681527211958647, 0.22583640868817562, 0.22223525942780933, 0.12368296545106099, 0.11732912050316209, 0.0920886196557669, 0.3210541886569467, 0.30841227011520583, 0.17729394698488812, 0.13171228711919208, 0.261221727860681, 0.1555270640915799, 0.2902619743455225, 0.2519802065152231, 0.21084374347241278, 0.22104985043589895, 0.13291467650259578, 0.22595150489970942, 0.2650627897726861, 0.09574782916605606, 0.33808444236364693, 0.2588434673243251, 0.08802840111815355, 0.11910105250183102, 0.17074071016960848, 0.09576086065638804, 0.13745749694524395, 0.24759398111815617, 0.07884481728264166, 0.08492904416875063, 0.13008930824006867, 0.12252675139485569, 0.1167900054075033, 0.2097014698470307, 0.12663355111179758, 0.09771997151844257, 0.08961140611290286, 0.08492904416875063, 0.09696217688389895, 0.29574306765527714, 0.35255117413738424, 0.14030371037214745, 0.11226578273773867, 0.25277428778440325, 0.08524416481669916, 0.13031623263109163, 0.14689281200201582, 0.09396598671816664, 0.17734483512279395, 0.1486258862746834, 0.15718099877211322, 0.25797321002429774, 0.2799070614645159, 0.1482842835653474, 0.3064742748623725, 0.3514957453189041, 0.29481934580645225, 0.10460854796450403, 0.11989100078640211, 0.2645717631832433, 0.08173828073987689, 0.10870934474401682, 0.11397715644214514, 0.26510119734647475, 0.3091936797158306, 0.17583660585575356, 0.5785852543034328, 0.22213798265929902, 0.37680234149252123, 0.10867323946491761, 0.12207144972827415, 0.15550698029526147, 0.305393671310215, 0.1110479983465211, 0.1107780271790992, 0.09114239325692539, 0.40708599113167937, 0.11349959651564065, 0.5608284023311119, 0.19122858401267695, 0.14377849704937964, 0.16758887158559393, 0.1131012406553725, 0.2916450243315323, 0.29581448288111917, 0.22459526548783984, 0.1182102455036343, 0.23609543942460265, 0.11542801368889938, 0.464524554665199, 0.16299266462326664, 0.12203655160302092, 0.19551518328378673, 0.14783650083461303, 0.24037186264112104, 0.30075561501912046, 0.3825388996412861, 0.13392257267669624, 0.15418916906948707, 0.3533893949400154, 0.09220139480808323, 0.1633547162733561, 0.09331612723603724, 0.10955443197349247, 0.0878210574465695, 0.25401715616773274, 0.23383187399190533, 0.33413074095019324, 0.17393931611328803, 0.1641185991060608, 0.1867288754183162, 0.16044373353261554, 0.08928460498922731, 0.10629955648549966, 0.1114113055050653, 0.5258463159164031, 0.09331612723603724, 0.4404872770928658, 0.07717535468195927, 0.4296475424513477, 0.14006583545087758, 0.09061001553208746, 0.11684866191378929, 0.08330090882957153, 0.343810303444052, 0.11261389548100349, 0.1110479983465211, 0.17332895621061828, 0.3431946764965211, 0.07690487819229053, 0.2614632254633868, 0.13807761796659734, 0.1120123513765497, 0.13453115845273267, 0.23002597714330128, 0.2540390070270402, 0.2920602317096238, 0.29045876761042, 0.22312550948569093, 0.2010456262386625, 0.1600635317387226, 0.11358717849203101, 0.1762346265796589, 0.15302534836540024, 0.15727874274803882, 0.23165980469081873, 0.21601282127700877, 0.2565601315902645, 0.0947582107719726, 0.32152758371479123, 0.21509564458943756, 0.5194501605223674, 0.2062672922459194, 0.16170345045949505, 0.1241303512831606, 0.16880888124568633, 0.2947760632779812, 0.41444982469812625, 0.12716871180207584, 0.23674046313595973, 0.3513840147542218, 0.30841227011520583, 0.10924483382719509, 0.3654772120008179, 0.1323962212342255, 0.09109699631676116, 0.1205266878826533, 0.36826521200075024, 0.12207144972827415, 0.07771213875070945, 0.1251312120231867, 0.16097417531718244, 0.11839454180545879, 0.1110479983465211, 0.09579636160907089, 0.4453499189894368, 0.2203831221592983, 0.1829497934668575, 0.12629444353996486, 0.3287350238614814, 0.3654772120008179, 0.36738003763197485, 0.08711650474131144, 0.4048482459522363, 0.10802396851144773, 0.2601383901840606, 0.105861830068932, 0.11708540682225639, 0.2322734506278908, 0.1353922454519608, 0.2425257483213903, 0.2587776976127567, 0.07978825803657201, 0.2835850585754114, 0.09017530785231172, 0.08492904416875063, 0.16178725105081423, 0.07595401853317199, 0.07891903922679241, 0.17898157259348516, 0.3026153294792186, 0.21622236333009953, 0.20058959202956453, 0.1304193612276774, 0.20786058388750928, 0.5530682996709185, 0.0679740222888025, 0.23125351613093362, 0.16284392401489373, 0.5455714257313076, 0.10803303148598772, 0.26971319140645633, 0.09310903985001613, 0.28102767427614994, 0.24897322539448746, 0.07895239893126106, 0.21246208876878264, 0.3943179747042661, 0.14657423869299674, 0.09153367610781343, 0.21215873003985122, 0.0853939412841622, 0.16995442457572238, 0.35141160468697213, 0.09590640650947534, 0.12561566794281398, 0.3643067934086368, 0.2194637658591447, 0.2169380565674406, 0.27574859545173663, 0.13205498272984034, 0.1299692589443999, 0.3404803621202157, 0.19459401363931447, 0.15404623805890252, 0.14568010812866494, 0.3315577269363337, 0.43086175838781776, 0.12107724946292424, 0.20901946869335358, 0.0807234267388824, 0.1955776294576156, 0.11434129871395166, 0.16620913405189122, 0.07664964128805161, 0.2313706596714055, 0.1421619467494695, 0.38314768075548433, 0.1110479983465211, 0.13019875621751592, 0.2889854065910469, 0.11266439917644701, 0.36303633352212555, 0.162022955459787, 0.337238759043066, 0.0973202444381734, 0.16633369217919058, 0.3533893949400154, 0.19257376898882628, 0.2220790325823916, 0.19688215969156095, 0.2535378749489873, 0.22257433156459436, 0.35445377892659535, 0.22301508849033708, 0.5378577652980179, 0.1392531478948749, 0.08598032718563849, 0.37702637908432035, 0.2200071456427535, 0.14154125241498106, 0.07472416938680167, 0.13690359787605844, 0.31272568202596746, 0.196717746738975, 0.1664253871396906, 0.21968874815689568, 0.2525571173488024, 0.20636990613538614, 0.24739737078760873, 0.27184529947767977, 0.1267954903086163, 0.2997824792837322, 0.13017621541636848, 0.1110479983465211, 0.13077541121213213, 0.09114239325692539, 0.5719376312428094, 0.28973142919262335, 0.12989913432806668, 0.21160219314117473, 0.33595482760459044, 0.13558920886903805, 0.20502609309760653, 0.18813938572390929, 0.34606766448533904, 0.09086019982845563, 0.15529216492964765, 0.21272344527241627, 0.23993021582529028, 0.36303633352212555, 0.08772130036046688, 0.13897863566589988, 0.08864243356868068, 0.38784410242940703, 0.41338694155645145, 0.24419159780778066, 0.5015462661565061, 0.07296565849385143, 0.21179764456947603, 0.1327034682968503, 0.1156116336203718, 0.37925891017965657, 0.20529002890134, 0.3748930993326102, 0.2163800356111169, 0.2017741945213795, 0.26137683343018114, 0.17266492134451844, 0.5066335863702051, 0.11572384078101175, 0.28247130670103343, 0.1847367063069143, 0.13304424485064822, 0.21492104584940003, 0.07942583601841785, 0.13601296503865024, 0.09748821762958336, 0.111223472147694, 0.41444982469812625, 0.41315784799411337, 0.16846051985929134, 0.2681767934217903, 0.13623390548463382, 0.14003507810655874, 0.17832781357659663, 0.15577046920924909, 0.16555145400422414, 0.07857715402076737, 0.22149328427602355, 0.08538671513748368, 0.10617139094608125, 0.08071260116015037, 0.23933878119851718, 0.07607367068720225, 0.12281197162563513, 0.3660677048770736, 0.11305603177931041, 0.15302534836540024, 0.5608284023311119, 0.11562719274118251, 0.09816579684018649, 0.2863194153681932, 0.12289465875969248, 0.14622776664063078, 0.3139566562239639, 0.12299221519667597, 0.16555051932548107, 0.18955954976334125, 0.0881737755794529, 0.34196760344666116, 0.11817624832852545, 0.1110479983465211, 0.10625723237670825, 0.07942583601841785, 0.11833411196325229, 0.28321619873808207, 0.13750926502130384, 0.2838874074736874, 0.10540167283274983, 0.17923597765136165, 0.09115267829657268, 0.20510455159520105, 0.3733535924741398, 0.20891941500365951, 0.11170537449764775, 0.2775199706354803, 0.11427044098449243, 0.5021045986965478, 0.1114113055050653, 0.18879669525705903, 0.19258926001337834, 0.2353107642608272, 0.18378822247535545, 0.176819344430741, 0.18113547144775455, 0.34305788585256786, 0.18889764161753822, 0.30541661540354637, 0.1309689323763815, 0.4703480289586643, 0.4600284273374091, 0.10795291368861791, 0.2015759462884808, 0.36268813201731853, 0.2277386277525142, 0.0897381250941342, 0.1892415139238257, 0.26642325989075405, 0.09279436942068553, 0.36905530058465, 0.21215873003985122, 0.21122717210610634, 0.20191849596470862, 0.1212626924700918, 0.24974246954699894, 0.29692291408605226, 0.42349914209272177, 0.2717107150287805, 0.19663847381971156, 0.0924918780727925, 0.09792044620339567, 0.23833697850469282, 0.10000448960199082, 0.10896335725709104, 0.2612483680307487, 0.11710682376035411, 0.11572384078101175, 0.08617374272968154, 0.23598558868801117, 0.19543623990889566, 0.11082192871546939, 0.266398705039233, 0.33654239362925226, 0.19920145252791918, 0.2767223580345317, 0.23183502866238145, 0.16066898533041157, 0.13832776937292987, 0.2935244447869683, 0.14733841847790627, 0.29268249905851484, 0.12294293022793862, 0.41444982469812625, 0.11040187871099785, 0.15890350993660554, 0.3192993879600136, 0.15648799583916514, 0.13937326966359448, 0.08652749820822829, 0.09217077955953609, 0.5275593725123419, 0.3536302787959787, 0.28161201838421035, 0.4113179936286165, 0.10418118089719754, 0.12098704046659807, 0.1110479983465211, 0.11921485425014021, 0.216968050250642, 0.1395559819231075, 0.1739837096466518, 0.1770843954474446, 0.1548312356225076, 0.42951981124594296, 0.14255574984863717, 0.08950097221821265, 0.13733876283509894, 0.2545557491396049, 0.13951219098901094, 0.253307863152822, 0.13733876283509894, 0.2803198942986502, 0.15064375087891677, 0.12401577243161475, 0.1246184548387682, 0.21560973566231784, 0.09640763317589693, 0.10554873176639973, 0.3603491697514871, 0.5124035632230084, 0.14073067137244588, 0.08724494140828198, 0.19017880095628298, 0.14564969334289737, 0.17703497958054995, 0.11488451482089222, 0.1699952120929378, 0.2895207244985118, 0.5463337712176942, 0.195682285460144, 0.20286876303776943, 0.21247154159079312, 0.2935244447869683, 0.1292726795100833, 0.5119549054536157, 0.18069795362788224, 0.3002592717080898, 0.16273057403415597, 0.07846504276521597, 0.14431119235965403, 0.21204324160529572, 0.34305889277190493, 0.13807761796659734, 0.17711161955080504, 0.1689048197795731, 0.4136691882607381, 0.37702637908432035, 0.13748605479493792, 0.2676702922348167, 0.31962988294006917, 0.21225550044617963, 0.5211559433460067, 0.1362235647200956, 0.4301436323856844, 0.20982388234448307, 0.12049134212428789, 0.1327034682968503, 0.13172565229917688, 0.1554902232033178, 0.2332835064063277, 0.16454480416097814, 0.12867212043418952, 0.2857936204847827, 0.1892811404348538, 0.17393931611328803, 0.20448747100489345, 0.0900616772764401, 0.10629955648549966, 0.09103817201355721, 0.24186283058386546, 0.22360881870437108, 0.14238840889624335, 0.16283110231354891, 0.17958739224233997, 0.20394607844936466, 0.34862518772714, 0.2568426342267173, 0.2051928123255866, 0.16545906401964605, 0.14279014758932, 0.30502584986481784, 0.11083416369035437, 0.14127716739841506, 0.19795583342378703, 0.21379880040809776, 0.07884481728264166, 0.0807234267388824, 0.2909503245460676, 0.2181515010230276, 0.22804592121543654, 0.22701816308043135, 0.09640763317589693, 0.17646872420731494, 0.10467363416340335, 0.20448747100489345, 0.1426789788127754, 0.11874674430687412, 0.27547662312184334, 0.19328504558285572, 0.586233764739287, 0.11213198476558106, 0.10574993336721587, 0.08770623217151612, 0.31281543090938624, 0.2052181678168082, 0.3654772120008179, 0.1151481025628891, 0.32763318652923085, 0.1447207255930182, 0.19053206542940915, 0.20315287629835396, 0.08654572624667702, 0.3614604062431833, 0.11795597215185283, 0.11079025791106874, 0.42719810027174926, 0.24670844871417222, 0.1349819593157733, 0.19308967934461826, 0.11836454336505531, 0.22486162339215315, 0.09640087141716595, 0.12200267430695864, 0.3143093362676829, 0.2220340338619872, 0.3125012994669914, 0.23528604553791907, 0.16229081560203282, 0.17099935071360495, 0.13839880984558048, 0.23695216211478665, 0.25429693773768636, 0.2490422678566123, 0.08639188012439279, 0.1110479983465211, 0.07294247037903287, 0.08933121156474673, 0.1384110079305711, 0.16585536685766916, 0.28403677505951985, 0.11684866191378929, 0.10810863961825679, 0.38063421739081876, 0.2538855956981542, 0.08744042765834652, 0.21592644777293374, 0.10342863433287376, 0.14669184889703238, 0.1251312120231867, 0.12189819770116006, 0.27116559529543577, 0.5177943602795674, 0.10849942104156145, 0.20221192834856805, 0.16885955321983634, 0.0897381250941342, 0.10537993155967955, 0.07748638511534871, 0.12652218699334242, 0.44446755420580836, 0.5102377950669242, 0.38516795546154253, 0.1251312120231867, 0.14279014758932, 0.5461101581248391, 0.155899778846668, 0.18140211383616456, 0.1110479983465211, 0.09498640211706982, 0.19784169583086075, 0.10777388854455269, 0.12369942680058792, 0.27788003827173247, 0.09416459813339391, 0.2020580433786236, 0.2796804716296976, 0.2945452774366602, 0.11063731953176055, 0.26203068345717667, 0.08683709466078882, 0.1709454416408983, 0.2015750146322662, 0.4087481360947289, 0.20359385332451688, 0.2336198863681194, 0.25623369180092204, 0.07771213875070945, 0.37887364143195534, 0.1196966263364051, 0.4818151713690395, 0.32656532865528226, 0.28986799543653213, 0.12600969550033145, 0.0955193526845859, 0.11580220086245746, 0.1953458644204546, 0.5019355205051724, 0.08852444208618565, 0.10884578158079955, 0.1023128069612279, 0.17408017611974355, 0.08695303205216087, 0.11110012970546686, 0.09623273078845085, 0.1916715823303984, 0.08773381602253066, 0.19880051266862178, 0.1421619467494695, 0.28517386066977546, 0.25085584602402095, 0.09227644996836935, 0.16863784865983625, 0.5446300298309754, 0.1071680812753241, 0.17052385489468141, 0.20726716902304418, 0.34658656880794575, 0.15461085928566207, 0.4266281600722581, 0.19846457393129205, 0.27431118010924654, 0.14729785624056244, 0.21150153495233617, 0.10505564588974323, 0.2195455135185054, 0.11542801368889938, 0.2846497667523446, 0.1243450573432625, 0.06624088796844094, 0.2051073788987618, 0.13155925739827898, 0.1600635317387226, 0.4572043646238146, 0.13083336792637748, 0.4852194772725562, 0.22226570510966345, 0.13733876283509894, 0.36087767064500903, 0.1196966263364051, 0.10753384222747775, 0.096783853175571, 0.31318719150199353, 0.14960217961428918, 0.347081061246549, 0.1697419456856504, 0.3062309636525968, 0.10467363416340335, 0.3888030794086547, 0.11552451699091676, 0.2048561074855228, 0.4399444375565492, 0.2023550525450763, 0.22079833727058565, 0.23772254359986747, 0.16704054240913577, 0.19114247384989225, 0.2610428217029025, 0.13127203068730794, 0.11514455613201784, 0.1782272029360054, 0.23014279310482505, 0.12254114407278915, 0.3265918922039417, 0.1421995741904436, 0.3543519686754179, 0.09103697095530013, 0.3016156486086938, 0.09795073575137234, 0.42951981124594296, 0.3954795128297354, 0.30639785715001655, 0.11966225969026696, 0.34005739955130554, 0.12175735788729922, 0.2458143277775341, 0.12274518722626147, 0.07328507023345346, 0.18917741488012077, 0.10619652167762458, 0.5709913227556516, 0.304620422105841, 0.15153353167184408, 0.2879196962964295, 0.2922794544546654, 0.24922808996504048, 0.08492904416875063, 0.1900005340698827, 0.09153367610781343, 0.11833411196325229, 0.1167900054075033, 0.2150703452869178, 0.17367305372815753, 0.16426502875847662, 0.1096464548685128, 0.09640763317589693, 0.2586000019017367, 0.10799010057876554, 0.08310847081559111, 0.20982388234448307, 0.2205347817133851, 0.1561825141979195, 0.24246276840407655, 0.1588044316472019, 0.09103817201355721, 0.09509921827602835, 0.09826589410051645, 0.16852698827855142, 0.12731251460174192, 0.4405717790741348, 0.10768459075597442, 0.1723495078609761, 0.09737721888916806, 0.2923549895327347, 0.09008356042794696, 0.08914587359294361, 0.26691921590601475, 0.145788682893606, 0.14060587526862572, 0.11907574090565691, 0.25042848765882814, 0.24290068088003433, 0.2204072133769692, 0.12696968439853798, 0.2947426766886416, 0.30184674488243035, 0.35335174226946564, 0.0999628851161131, 0.2200358899856729, 0.08538671513748368, 0.12173454699093753, 0.26621321724912167, 0.18794145268733356, 0.15363364930791273, 0.15696389406912362, 0.19272412582109297, 0.1469777095379175, 0.16678595382054548, 0.20045085008965763, 0.10803303148598772, 0.25599551738111026, 0.30415222285978344, 0.27221795449428665, 0.10676999247410875, 0.18212779793958814, 0.08524416481669916, 0.1762346265796589, 0.11379902311271092, 0.2202627591188959, 0.23946762454777396, 0.09159874462651058, 0.11313715255258208, 0.23128795163637617, 0.16025111651004356, 0.20456669292766114, 0.19056985748324015, 0.21178702206096145, 0.10367776141748053, 0.2603590513769276, 0.19981704833386085, 0.09297451870305531, 0.19795583342378703, 0.1249661376186561, 0.2614063160642028, 0.10997949954962385, 0.23556035246218066, 0.12385151435305823, 0.13215376463990922, 0.5350326324585454, 0.5337160894057508, 0.0679740222888025, 0.0848989416079669, 0.4031072495281026, 0.19663573427857978, 0.12958285665192767, 0.23125351613093362, 0.09702463634038928, 0.15312598658243326, 0.1110479983465211, 0.11335696603291509, 0.0794403916613158, 0.4263172051690078, 0.28282837631915814, 0.30565621160811846, 0.13554409832775352, 0.13112538445956298, 0.08931077853697247, 0.21809372687258494, 0.18166445622525648, 0.21605320317434645, 0.27969184504891587, 0.20741361819041812, 0.36303633352212555, 0.34003452179246907, 0.2533354273498119, 0.25755786636255096, 0.09559220425241115, 0.16253168822012573, 0.14668224526900542, 0.27374635617189735, 0.17744406636823676, 0.5719376312428094, 0.22301508849033708, 0.22252485174690295, 0.06722933802438556, 0.06624088796844094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:280: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Definir los hiperparámetros\n",
    "parametros = {\n",
    "    'criterion': 'friedman_mse',\n",
    "    'learning_rate': 0.2,\n",
    "    'loss': 'deviance',\n",
    "    'max_depth': 5,\n",
    "    'max_features': 'log2',\n",
    "    'min_samples_leaf': 0.1,\n",
    "    'min_samples_split': 0.13636363636363638,\n",
    "    'n_estimators': 10,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Crear el clasificador\n",
    "clf = GradientBoostingClassifier(**parametros)\n",
    "\n",
    "# Definir los datos X e y\n",
    "X = x_training_features_no_outliers\n",
    "y = y_training_features_no_outliers[\"h1n1_vaccine\"]\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Listas para almacenar resultados\n",
    "roc_auc_scores = []\n",
    "predicted_probs = []\n",
    "\n",
    "# Iterar sobre las divisiones\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir probabilidades\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    predicted_probs.extend(y_prob)\n",
    "    \n",
    "    # Calcular ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "# Calcular el promedio de ROC AUC\n",
    "avg_roc_auc = np.mean(roc_auc_scores)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f'ROC AUC promedio: {avg_roc_auc}')\n",
    "\n",
    "# Imprimir las probabilidades continuas\n",
    "print('Probabilidades Continuas:')\n",
    "print(predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"0.814992324109784\n",
    "{'criterion': 'friedman_mse', 'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 5, \n",
    "'max_features': 'log2', 'min_samples_leaf': 0.1, 'min_samples_split': 0.13636363636363638, \n",
    "'n_estimators': 10, 'subsample': 1.0}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08a6ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\AppData\\Local\\Temp\\ipykernel_18088\\3915030757.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 3ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 1s 3ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 1ms/step\n",
      "167/167 [==============================] - 3s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 1s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 1s 3ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "167/167 [==============================] - 1s 3ms/step\n",
      "167/167 [==============================] - 1s 3ms/step\n",
      "167/167 [==============================] - 0s 2ms/step\n",
      "835/835 [==============================] - 2s 2ms/step\n",
      "835/835 [==============================] - 2s 2ms/step\n",
      "Mejor Puntuación de AUC-ROC: 0.827020927892077\n",
      "Mejores Parámetros: {'model__activation': 'relu', 'model__hidden_units': 16, 'model__optimizer': 'adam'}\n",
      "ROC AUC Score: 0.8414209942611456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Definir una función para construir el modelo\n",
    "def build_model(optimizer='adam', activation='relu', hidden_units=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=x_training_features.shape[1], activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Capa de salida para clasificación binaria\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Crear un clasificador Keras para usar con GridSearchCV\n",
    "model = KerasClassifier(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Definir el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Definir los parámetros para grid search\n",
    "parametros = {\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__hidden_units': [16, 32, 64]\n",
    "}\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=skf, scoring='roc_auc')\n",
    "\n",
    "# Realizar la búsqueda de parámetros\n",
    "grid_result = grid_search.fit(x_training_features, y1)\n",
    "\n",
    "# Obtener las predicciones y probabilidades continuas\n",
    "y_pred = grid_result.predict(x_training_features)\n",
    "y_prob = grid_result.predict_proba(x_training_features)[:, 1]  # Tomamos solo la columna correspondiente a la clase positiva\n",
    "\n",
    "# Calcular el ROC AUC Score\n",
    "roc_auc = roc_auc_score(y1, y_prob)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Mejor Puntuación de AUC-ROC:\", grid_result.best_score_)\n",
    "print(\"Mejores Parámetros:\", grid_result.best_params_)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82c5dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96333206, 0.03666794],\n",
       "       [0.4924345 , 0.5075655 ],\n",
       "       [0.97783417, 0.02216581],\n",
       "       ...,\n",
       "       [0.89312464, 0.10687538],\n",
       "       [0.9833312 , 0.01666879],\n",
       "       [0.81215596, 0.18784407]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Mejor Puntuación de AUC-ROC: 0.827020927892077\n",
    "Mejores Parámetros: {'model__activation': 'relu', 'model__hidden_units': 16, 'model__optimizer': 'adam'}\n",
    "ROC AUC Score: 0.8414209942611456\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Definir el clasificador base (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Crear el clasificador Bagging\n",
    "bagging_clf = BaggingClassifier(base_classifier, random_state=42)\n",
    "\n",
    "# Definir el pipeline con la estandarización\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', bagging_clf)\n",
    "])\n",
    "\n",
    "# Definir los parámetros para grid search\n",
    "parametros = {\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_samples': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=skf, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "# Definir los datos X e y\n",
    "X = x_training_features\n",
    "y = y1\n",
    "\n",
    "# Realizar la búsqueda de parámetros\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Obtener las mejores configuraciones\n",
    "best_estimator = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Calcular el ROC AUC Score\n",
    "y_prob = best_estimator.predict_proba(X)[:, 1]\n",
    "roc_auc = roc_auc_score(y, y_prob)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Mejores Parámetros:\", best_params)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "377ad8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVC\n",
      "Best Parameters: {'classifier__C': 1, 'classifier__gamma': 0.01, 'classifier__kernel': 'rbf'}\n",
      "ROC AUC Score: 0.8351890748715352\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Best Parameters: {'classifier__C': 0.001, 'classifier__solver': 'lbfgs'}\n",
      "ROC AUC Score: 0.8241473680992861\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Best Parameters: {'classifier__max_depth': None}\n",
      "ROC AUC Score: 0.9999999622930018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define los clasificadores que deseas probar como base\n",
    "classifiers = [\n",
    "    {\n",
    "        'classifier': SVC(probability=True),\n",
    "        'params': {'classifier__C': [1], 'classifier__gamma': [0.01], 'classifier__kernel': ['rbf']}\n",
    "    },\n",
    "    {\n",
    "        'classifier': LogisticRegression(max_iter=1000),\n",
    "        'params': {'classifier__C': [0.001], 'classifier__solver': ['lbfgs']}\n",
    "    },\n",
    "    {\n",
    "        'classifier': DecisionTreeClassifier(),\n",
    "        'params': {'classifier__max_depth': [None]}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Inicializa una lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Itera sobre los clasificadores\n",
    "for clf_info in classifiers:\n",
    "    classifier = clf_info['classifier']\n",
    "    parametros = clf_info['params']\n",
    "    \n",
    "    # Construye el pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Inicializa GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=5, scoring='roc_auc')\n",
    "\n",
    "    # Convierte el DataFrame a un array\n",
    "    X_array = x_training_features.values\n",
    "\n",
    "    # Realiza la búsqueda de parámetros\n",
    "    grid_result = grid_search.fit(X_array, y1)\n",
    "\n",
    "    # Obtiene las mejores configuraciones\n",
    "    best_estimator = grid_result.best_estimator_\n",
    "    best_params = grid_result.best_params_\n",
    "\n",
    "    # Obtiene las probabilidades continuas\n",
    "    y_prob = best_estimator.predict_proba(X_array)[:, 1]\n",
    "\n",
    "    # Calcula el ROC AUC Score\n",
    "    roc_auc = roc_auc_score(y1, y_prob)\n",
    "\n",
    "    # Almacena los resultados\n",
    "    results.append({\n",
    "        'classifier': classifier.__class__.__name__,\n",
    "        'best_params': best_params,\n",
    "        'roc_auc_score': roc_auc,\n",
    "        'y_prob': y_prob  # Añade las probabilidades continuas\n",
    "    })\n",
    "\n",
    "# Imprime los resultados\n",
    "for result in results:\n",
    "    print(f\"Classifier: {result['classifier']}\")\n",
    "    print(f\"Best Parameters: {result['best_params']}\")\n",
    "    print(f\"ROC AUC Score: {result['roc_auc_score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0edc7a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: DecisionTreeClassifier\n",
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 20}\n",
      "ROC AUC Score: 0.830371289415607\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define el clasificador que deseas probar como base\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Inicializa una lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Define los hiperparámetros que deseas probar\n",
    "parametros = {\n",
    "    'classifier__max_depth': [None, 5, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Construye el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Inicializa GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Convierte el DataFrame a un array\n",
    "X_array = x_training_features.values\n",
    "\n",
    "# Realiza la búsqueda de parámetros\n",
    "grid_result = grid_search.fit(X_array, y1)\n",
    "\n",
    "# Obtiene las mejores configuraciones\n",
    "best_estimator = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Obtiene las probabilidades continuas\n",
    "y_prob = best_estimator.predict_proba(X_array)[:, 1]\n",
    "\n",
    "# Calcula el ROC AUC Score\n",
    "roc_auc = roc_auc_score(y1, y_prob)\n",
    "\n",
    "# Almacena los resultados\n",
    "results.append({\n",
    "    'classifier': classifier.__class__.__name__,\n",
    "    'best_params': best_params,\n",
    "    'roc_auc_score': roc_auc,\n",
    "    'y_prob': y_prob  # Añade las probabilidades continuas\n",
    "})\n",
    "\n",
    "# Imprime los resultados\n",
    "for result in results:\n",
    "    print(f\"Classifier: {result['classifier']}\")\n",
    "    print(f\"Best Parameters: {result['best_params']}\")\n",
    "    print(f\"ROC AUC Score: {result['roc_auc_score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Classifier: DecisionTreeClassifier\n",
    "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 20}\n",
    "ROC AUC Score: 0.830371289415607\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c584b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__logistic_regression__C': 0.001, 'classifier__logistic_regression__solver': 'lbfgs', 'classifier__svc__C': 1, 'classifier__svc__gamma': 0.01, 'classifier__svc__kernel': 'rbf'}\n",
      "ROC AUC Score: 0.6536492807742021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define los clasificadores de base que deseas usar\n",
    "classifiers = [\n",
    "    ('svc', SVC(C=1, gamma=0.01, kernel='rbf', probability=True)),\n",
    "    ('logistic_regression', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Define el meta-clasificador\n",
    "meta_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Inicializa el StackingClassifier\n",
    "stacking_classifier = StackingClassifier(estimators=classifiers, final_estimator=meta_classifier)\n",
    "\n",
    "# Construye el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', stacking_classifier)\n",
    "])\n",
    "\n",
    "# Define los hiperparámetros que deseas probar\n",
    "parametros = {\n",
    "    'classifier__svc__C': [1],\n",
    "    'classifier__svc__gamma': [0.01],\n",
    "    'classifier__svc__kernel': ['rbf'],\n",
    "    'classifier__logistic_regression__C': [0.001],\n",
    "    'classifier__logistic_regression__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# Inicializa GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Convierte el DataFrame a un array\n",
    "X_array = x_training_features.values\n",
    "\n",
    "# Realiza la búsqueda de parámetros\n",
    "grid_result = grid_search.fit(X_array, y1)\n",
    "\n",
    "# Obtiene las mejores configuraciones\n",
    "best_estimator = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Obtiene las probabilidades continuas\n",
    "y_prob = best_estimator.predict_proba(X_array)[:, 1]\n",
    "\n",
    "# Calcula el ROC AUC Score\n",
    "roc_auc = roc_auc_score(y1, y_prob)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66bc4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\auror\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__DecisionTreeClassifier__criterion': 'gini', 'classifier__DecisionTreeClassifier__max_depth': 10, 'classifier__DecisionTreeClassifier__max_features': 'auto', 'classifier__DecisionTreeClassifier__min_samples_leaf': 8, 'classifier__DecisionTreeClassifier__min_samples_split': 20, 'classifier__svc__C': 1, 'classifier__svc__gamma': 0.01, 'classifier__svc__kernel': 'rbf'}\n",
      "ROC AUC Score: 0.849216752746716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define los clasificadores de base que deseas usar\n",
    "classifiers = [\n",
    "    ('svc', SVC(C=1, gamma=0.01, kernel='rbf', probability=True)),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier(criterion='gini', max_depth=10, max_features='auto', \n",
    "                                   min_samples_leaf=8, min_samples_split=20))\n",
    "]\n",
    "\n",
    "# Define el meta-clasificador y el estimador\n",
    "meta_classifier = LogisticRegression(C=0.001, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Inicializa el StackingClassifier\n",
    "stacking_classifier = StackingClassifier(estimators=classifiers, final_estimator=meta_classifier)\n",
    "\n",
    "# Construye el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', stacking_classifier)\n",
    "])\n",
    "\n",
    "# Define los hiperparámetros que deseas probar\n",
    "parametros = {\n",
    "    'classifier__svc__C': [1],\n",
    "    'classifier__svc__gamma': [0.01],\n",
    "    'classifier__svc__kernel': ['rbf'],\n",
    "    'classifier__DecisionTreeClassifier__criterion': ['gini'],\n",
    "    'classifier__DecisionTreeClassifier__max_depth': [10],\n",
    "    'classifier__DecisionTreeClassifier__max_features': ['auto'], \n",
    "    'classifier__DecisionTreeClassifier__min_samples_leaf': [8], \n",
    "    'classifier__DecisionTreeClassifier__min_samples_split': [20]\n",
    "}\n",
    "\n",
    "# Inicializa GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=parametros, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Convierte el DataFrame a un array\n",
    "X_array = x_training_features.values\n",
    "\n",
    "# Realiza la búsqueda de parámetros\n",
    "grid_result = grid_search.fit(X_array, y1)\n",
    "\n",
    "# Obtiene las mejores configuraciones\n",
    "best_estimator = grid_result.best_estimator_\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "# Obtiene las probabilidades continuas\n",
    "y_prob = best_estimator.predict_proba(X_array)[:, 1]\n",
    "\n",
    "# Calcula el ROC AUC Score\n",
    "roc_auc = roc_auc_score(y1, y_prob)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best Parameters: {'classifier__DecisionTreeClassifier__criterion': 'gini', 'classifier__DecisionTreeClassifier__max_depth': 10, 'classifier__DecisionTreeClassifier__max_features': 'auto', 'classifier__DecisionTreeClassifier__min_samples_leaf': 8, 'classifier__DecisionTreeClassifier__min_samples_split': 20, 'classifier__svc__C': 1, 'classifier__svc__gamma': 0.01, 'classifier__svc__kernel': 'rbf'}\n",
    "ROC AUC Score: 0.849216752746716\"\"\""
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
